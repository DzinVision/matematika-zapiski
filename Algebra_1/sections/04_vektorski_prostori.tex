\textsc{Definicija:} \emph{Vektorski prostor} na obsegom \OO je Abelova grupa $(V, +)$ skupaj z \emph{zunanjo operacijo}
\begin{align*}
\OO \times V &\to V \\
(\alpha, v) &\mapsto \alpha v
\end{align*}
ki ustreza naslednjim pogojem:
\begin{enumerate}
	\item $(\alpha + \beta) v = \alpha v + \beta v$ \hfill $\forall \alpha, \beta \in \OO, \forall v \in V$
	\item $\alpha(u + v) = \alpha u + \alpha v$ \hfill $\forall \alpha \in \OO, \forall u, v \in V$
	\item $\alpha(\beta v) = (\alpha \beta)v$ \hfill $\forall \alpha, \beta \in \OO, \forall v \in V$
	\item $1v = v$ \hfill $\forall v \in V$
\end{enumerate}
Elemente iz \OO imenujemo \emph{skalarji}, elemente iz $V$ imenujemo \emph{vektorji}, zunanjo operacijo pa imenujemo \emph{mno"zenje z skalarji}.

\textsc{Primer:}
\begin{enumerate}[(1)]
	\item $V = \RR^3, \OO = \RR$ obi"cajen trirazse"zen vektorski prostor
	\item $V = \OO^n$, $\OO$ - obseg
	
	Naj bosta $x$ in $y$ naslednja vektorja:
	\begin{align*}
	x &= (x_1, x_2, \ldots, x_n) \in \OO^n (x_i \in \OO \forall i) \\
	y &= (y_1, y_2, \ldots, y_n) \in \OO^n (y_i \in \OO \forall i)
	\end{align*}
	Operaciji definiramo slede"ce:
	\begin{align*}
	x + y &= (x_1 + y_1, x_2 + y_2, \ldots, x_n + y_n) \in \OO^n \\
	\alpha x &= (\alpha x_1, \alpha x_2, \ldots, \alpha x_n) \in \OO^n
	\end{align*}
	Za ti dve operacijie je $\OO^n$ vektorski prostor na obsegom $\OO$. Ni"celni element je
	\begin{equation*}
	0 = (0, 0, \ldots, 0) \in \OO^n
	\end{equation*}
	Nasprotni element je:
	\begin{equation*}
	-(x_1, x_2, \ldots x_n) = (-x_1, -x_2, \ldots, -x_n) \in \OO^n
	\end{equation*}
	
	\item $M \neq \varnothing$ \qquad $\mathcal{F}(M, \RR) \equiv \RR^M = \{f: M \to \RR\}$
	
	Operaciji definiramo po to"ckah:
	\begin{align*}
	(\alpha f)(t) &= \alpha f(t) && \forall t \in M (\alpha \in \RR) \\
	(f + g)(t) &= f(t) + g(t) && \forall t \in M
	\end{align*}
	$V = \RR^M, \OO = \RR$
	
	$V$ je vekotrski prostor nad $\RR$.
\end{enumerate}
\subsection{Nekaj osnovnih lastnosti vektorskih prostorov}
Naj bo $V$ vektorski prostor nad \OO. Velja:
\begin{enumerate}[(1)]
	\item $0v = 0$ \hfill $\forall v \in V$
	\item $\alpha 0 = 0$ \hfill $\forall \alpha \in \OO$
	\item $\alpha v = 0 \Rightarrow (\alpha = 0 \lor v = 0)$
	\item $(-1)v = -v$ \hfill $\forall v \in V$
\end{enumerate}
\textsc{Dokaz:}
\begin{enumerate}[(1)]
	\item
	\begin{multline*}
		0v = x \in V \Rightarrow \\
		x + x = 0v + 0v = (0 + 0)v = 0v = x  \\
		\Rightarrow x + x = x \Rightarrow x = 0 \\
		\Rightarrow 0v = 0
	\end{multline*}
	\item Podoben dokaz kot za (1).
	\item $\alpha v = 0$. "Ce $\alpha = 0$ optem velja (2). Druga"ce:
	\begin{multline*}
		\alpha \neq 0 \Rightarrow \exists \alpha^{-1} \in \OO \Rightarrow \\
		\Rightarrow \alpha^{-1} (\alpha v) = \alpha^{-1} 0 = 0 \\
		\underbrace{(\alpha^{-1} \alpha)}_1 v = 1v = v \\
		\Rightarrow v = 0
	\end{multline*}
	\item
	\begin{equation*}
	(-1)v + v = (-1)v + 1v = (-1 + 1) v = 0v = 0
	\end{equation*}
\end{enumerate}
%
\subsection{Vektorski podprostor}
\textsc{Definicija:} Naj bo $V$ vektorski prostor nad $\OO$ in $U \subseteq V, U \neq \varnothing$. $U$ je vektorski poprostor vektorskega prostora $V$, kadar velja:
\begin{enumerate}[(1)]
	\item $x, y \in U \Rightarrow x + y \in U$
	\item $x \in U \Rightarrow \alpha x \in U$ \hfill $\forall \alpha \in \OO$
\end{enumerate}
Obe zahtevi lahko zdru"zimo v eno:
\begin{equation*}
(1) \land (2) \iff (x, y \in U \Rightarrow \forall \alpha, \beta \in U: \alpha x + \beta y \in U)
\end{equation*}
$(U, +)$ je podgrupa grupe $(V, +)$.

\textsc{Primeri:}
\begin{enumerate}[(1)]
	\item $V = \RR^3$, $U$ je ravnina skozi $0$ v $\RR^3$
	
	\item 
	\begin{align*}
	V &= \RR^3 \\
	U &= \RR[x]
	\end{align*}
	
	\item 
	\begin{align*}
	V &= \RR[x] \\
	U &= \RR_m[x] = \{p(x) \in \RR[x]: \text{stp}(x) \leq m\}
	\end{align*}
\end{enumerate}
"Ce je $V$ vektorski prostor nad $\OO$ in $U \subseteq V$ podprostor, uporabljamo oznako:
\begin{equation*}
U \leq V
\end{equation*}
Vsak podprostor vsebuje ni"clo:
\begin{equation*}
x \in U \Rightarrow 0x = 0 \in U
\end{equation*}
Nasprotni element je element podprostora:
\begin{equation*}
x, y \in U \Rightarrow x - y = x + (-1) \in U
\end{equation*}
Ker velja $\alpha x \in U$ in $\beta y \in U$, lahko zapi"semo:
\begin{equation*}
\alpha x + \beta y \in U
\end{equation*}
Zapi"semo lahko:
\begin{equation*}
x_1, x_2, \ldots, x_k \in U \Rightarrow \underbrace{\alpha x_1 + \alpha x_2 + \ldots + \alpha x_k}_{\text{\emph{linearna kombinacija vektorjev} $x_1, \ldots, x_k$}} \in U
\end{equation*}
\subsection{Linearna ogrinja"ca}
\textsc{Definicija:} Naj bo $M \in V, M \neq \varnothing$. \emph{Linearno ogrinja"ca mno"zice} $M$ je
\begin{equation*}
\Lin M = \{\alpha_1 x_1 + \ldots +\alpha_k x_k: x_1, \ldots, x_k \in M, \alpha_1, \ldots \alpha_k \in \OO, k \in \NN\}
\end{equation*}
Velja:
\begin{equation*}
M \subseteq U \leq V \Rightarrow \Lin M \subseteq U
\end{equation*}
\dashuline{$\Lin M$ je vektorski podprostor vektorskega prostora $V$ ($\Lin M \leq V$)}
\begin{itemize}
	\item Zaprtost za se"stevanje:
	\begin{gather*}
	\alpha_1 x_1 + \ldots + \alpha_k x_k \in \Lin M \\
	\beta_1 x_1 + \ldots + \beta_n y_n \in \Lin M
	\end{gather*}
	Opazimo, da so po definiciji $\Lin M$ posame"cni "cleni $\alpha_1 x_1, \ldots \alpha_k x_k \in \Lin M$ in $\beta_1 y_1, \ldots, \beta_n y_n \in \Lin M$, torej je tudi vsota vseh "clenov $\in \Lin M$.
	
	\item Zaprtost za mno"zenje s skalarjem:
	\begin{gather*}
		\beta(\alpha_1 x_1 + \ldots + \alpha_k x_k) = (\beta \alpha_1) x_1 + \ldots + (\beta \alpha_k)x_k \in \Lin M \\
		x_1, \ldots, x_k \in M
	\end{gather*}
	\hfill $\square$
\end{itemize}
Iz tega sledi, da je $\Lin M$ najmanj"si vektorski podprostor, ki vsebuje $M$. Simbolno za malo naprednej"se:
\begin{equation*}
M \subseteq U \leq V \Rightarrow \Lin M \subseteq U
\end{equation*}
Za prazno mno"zico velja:
\begin{equation*}
\Lin \varnothing = \{0\}
\end{equation*}
Poglejmo si, kako je s preseki in unijami. Za preseke velja:
\begin{equation*}
V_i \leq V \forall i \in I \Rightarrow \bigcap_{i \in I}V_i \leq V
\end{equation*}
To je o"citno. Zaprtost za se"stevanje velja, ker "ce sta neka dva vektorja $x, y$ v $\bigcap_{i \in I}V_i$, potem se nahajata v vseh $V_i$. Ker so $V_i$ vektorski podprostori, v njih tudi velja zaprtost za se"stevanje. Zato je vsota $x + y$ tudi v vseh $V_i$, torej je tudi v $\bigcap_{i \in I}V_i$. Podobno lahko naredimo za zaprtost za mno"zenje s skalarjem.

Malo ve"c je za videti pri uniji. $V_1, V_2 \leq V \Rightarrow \Lin (V_1 \cup V_2)$ je najmanj"si vektorski podprostor, ki vsebuje $V_1$ in $V_2$. Primer na katerem se lahko predstavljamo, sta dve premici. Unija dveh premic, ki se sekata ni vektorski podrpostor, zato okoli naredimo linearno ogrinja"co. Poglejmo si eno zanimivost:
\begin{gather*}
x \in \Lin (V_1 \cup V_2) \\
x = \underbrace{\alpha_1 x_1 + \ldots \alpha_k x_k}_{\in V_1} + \underbrace{\beta_1 y_1 + \ldots + \beta_n y_n}_{\in V_2} = u + v
\end{gather*}
Torej velja:
\begin{equation*}
x \in \Lin (V_1 \cup V_2) \iff x = u + v, u \in V_1, v \in V_2
\end{equation*}
Zapi"semo:
\begin{equation*}
V_1 + V_2 = \{u + v: u \in V_1, v \in V_2\}
\end{equation*}
Torej velja:
\begin{equation*}
\Lin (V_1 \cup V_2) = V_1 + V_2
\end{equation*}
Analogno naredimo za ve"c sumandov:
\begin{gather*}
	\Lin (V_1 \cup V_2 \cup \ldots \cup V_k) = V_1 + V_2 + \ldots + V_k \\
	V_i \leq V \forall i \\
	V_1 + \ldots + V_k = \{x_1 + \ldots + x_k: x_i \in V_i \forall i\}
\end{gather*}
\textsc{Definicija:} $V_1 + \ldots + V_k$ je \emph{prema} ali \emph{direktna}, kadar za vsak $x \in V_1 + \ldots + V_k$ obstajajo in so z $x$ enoli"cno dolo"ceni taki vektorji $x_i \in V_i (i = 1, \ldots, k)$, da je $x = x_1 + \ldots + x_k$. Ozani"cimo:
\begin{equation*}
V_1 \oplus \ldots \oplus V_k
\end{equation*}
\textsc{Trditev:} Vsota $V_1 + V_2$ vektorskih podprostorov $V_1$ in $V_2$ je direktna natanko takrat, kadar je $V_1 \cap V_2 = \{0\}$.

\textsc{Dokaz:}
\begin{itemize}
	\item[($\Rightarrow$)] Naj bo vsota $V_1 + V_2$ direktna ($V_1 \oplus V_2$). Vzemimo $x \in V_1 \cup V_2$.
	\begin{equation*}
	x = \underbrace{x}_{\in V_1} + \underbrace{0}_{\in V_2} = \underbrace{0}_{\in V_1} + \underbrace{x}_{\in V_2} \Rightarrow x = 0
	\end{equation*}
	$\Rightarrow V_1 \cup V_2 = \{0\}$
	
	\item[($\Leftarrow$)] Naj bo $V_1 \cup V_2 = \{0\}$.
	\begin{align*}
	x &\in V_1 + V_2 \\
	x &= x_1 + x_2, x_1 \in V_1, x_2 \in V_2 \\
	x &= x_1' + x_2', x_1' \in V_1, x_2' \in V_2 \\
	x_1 + x_2 &= x_1' + x_2' \\
	\underbrace{x_1 - x_1'}_{\in V_1} &= \underbrace{x_2 - x_2'}_{\in V_2} = z
	\end{align*}
	\begin{align*}
	&\Rightarrow z \in V_1 \cap V_2 = \{0\} \\
	&\Rightarrow x = 0 \Rightarrow \\
	&\Rightarrow x_1' = x_1 \land x_2' = x_2
	\end{align*}
	\begin{equation*}
	V_1 \oplus V_2
	\end{equation*}
	\hfill $\square$
\end{itemize}

\subsection{Kvocientni vektorski prostor}
Naj bo $U$ vektorski prostor nad $\OO$, $U \leq V$. Definiramo:
\begin{equation*}
v_1 \sim v_2 \iff v_1 - v_2 \in U
\end{equation*}
kjer je $\sim$ ekvivalen"cna relacija. $U$ je Abelova podgrupa Abelove grupe $V$. $V/_U$ je torej Abelova grupa in velja:
\begin{align*}
[x] + [y] &= [x+y] \forall x, y \in V \\
[z] &= z + U \forall z \in V
\end{align*}
V $V/_U$ uvedemo mno"zenje s skalarji:
\begin{equation*}
\alpha [x] := [\alpha x], \alpha \in \OO, x \in V
\end{equation*}
\dashuline{Definicija je dobra} "ce velja:
\begin{align*}
y \sim x &\Rightarrow \alpha x \sim \alpha y \\
y -x \in U &\Rightarrow \underbrace{\alpha y - \alpha x}_{\alpha (y - x) = z} \in U
\end{align*}
Ker je $U$ podprostor zaprt za mno"zenje s skalarjem, vemo:
\begin{equation*}
z \in U \Rightarrow \alpha z \in U \forall \alpha \in \OO
\end{equation*}
\hfill $\square$

Sledi, da je $V/_U$ vektorski prostor nad $\OO$. Elementi so $x + U, x \in V$.

\textsc{Primer:} $U$ premica skozi 0 v $V = \RR^3$. Elementi $V/_U: x + U, x \in \RR^3$ so premice vzporedne premici $U$.
%
\subsection{Linearne preslikave}
So neke vrste homomorfizmi vektorskih prostorov.

\textsc{Definicija:} Naj bosta $V$ in $U$ vektorska prostora nad istim $\OO$. Preslikava $\A : V \to U$ je \emph{linearna} (= homomorfizem vektorskih prostorov), kadar velja:
\begin{enumerate}[(1)]
	\item $\A(x + y) = \A x + \A y$ \hfill $\forall x, y \in V$
	\item $\A(\alpha x) = \alpha \A x$ \hfill $\forall \alpha \in \OO, \forall x \in V$
\end{enumerate}
Pogoju (1) pravimo, da je $\A$ \emph{aditivna}, pogoju (2) pa pravimo, da je $\A$ \emph{homogena}.
\subsubsection*{Nekaj lastnosti:}
\begin{itemize}
	\item $\A0 = 0$ (pride iz Abelove grupe)
	\item $\A (-x) =  -\A x$ (pride iz Abelove grupe) \hfill $\forall x \in V$
	\item $\A(x-y) = \A x - \A y$ \hfill $\forall x, y \in V$
	\item[(3)] $\A(\alpha x + \beta y) = \A(\alpha x) + \A(\beta y) = \alpha \A x + \beta \A y$ \hfill $\forall x, y \in V, \forall \alpha, \beta \in \OO$
	\begin{equation*}
	\A(\alpha x + \beta y) = \alpha \A x + \beta \A y
	\end{equation*}
	Ta lastnost sledi iz pogojev (1) in (2). Iz te lastnosti lahko dobimo nazaj pogoj (1) in (2).
	\begin{equation*}
	((1) \land (2)) \iff (3)
	\end{equation*}
\end{itemize}
\textsc{Splo"sno:}
\begin{equation*}
	\A(\alpha_1 x_1 + \alpha_2 x_2 + \cdots + \alpha_n x_n) = \alpha_1 \A x_1 + \alpha_2 \A x_2 + \cdots + \alpha_n \A x_n
\end{equation*}
%
\textsc{Definicija:} $\A V \to U$ je \emph{izomorfizem} vektorskega prostora, kadar je $\A$ bijektivna in sta $\A$ in $\A^{-1}$ linearni preslikavi. \textbf{Velja:} bijektivna linearna preslikava je izomorfizem vektorskega prostora.

Naj bo $\A: V \to U$ linearna bijekcija. \dashuline{$\A^{-1}: U \to V$ je linearna}

Aditivnost sledi iz dejstva, da je $A$ izomorfizem Abelovih grup $(V, +)$, $(U, +)$.
\begin{equation*}
\A^{-1}(\alpha u) = \A^{-1}(\alpha \A v) = \A^{-1}(\A(\alpha v)) = \alpha v = \alpha \A^{-1} u
\end{equation*}
kjer upo"stevamo, da $\exists v \in V: u = \A v (v = \A^{-1}u)$

$\Rightarrow \A^{-1}$ je homogena \hfill $\square$

\textsc{Primeri:}
\begin{enumerate}[(1)]
	\item $V = U = \RR^3$
	\begin{itemize}
		\item $\A: \RR^3 \to \RR^3$ pravokotna projekcija na ravnino skozi 0.
		\item $\A: \RR^3 \to \RR^3$ zasuk za dolo"cen kot okrog dane osi skozi 0.
	\end{itemize}
	\item $\A: \RR[x] \to \RR[x]$, $\A$ odvajanje.
	\item $\A: \RR[x] \to \RR$, $\A$ je dolo"ceno integriranje.
\end{enumerate}
%
\subsubsection{Slika in jedro linearnih preslikav}
\textsc{Definicija:} Naj bo $\A: V \to U$ linearna preslikava. Definiramo:
\begin{itemize}
	\item $\im \A = \{\A x: x \in V\}$ slika preslikave $\A$
	\item $\ker \A = \{x \in V: \A x = 0\}$ jedro preslikave $\A$
\end{itemize}
\textsc{Velja:} $\im \A \leq U$ in $\ker \A \leq V$

\textsc{Dokaz:} za $\im \A$: \dashuline{$u_1, u_2 \in \im\A \Rightarrow \alpha_1 u_1 + \alpha_2 u_2 \in \im \A$}
\begin{gather*}
\exists x_1, x_2 \in V: u_1 = \A x_1, u_2 = \A x_2 \\
\alpha_1 u_1 + \alpha_2 u_2 = \alpha_1 \A x_1 + \alpha_2 \A x_2 = \A(\alpha_1 x_1 + \alpha_2 x_2) \in \im \A
\end{gather*}
%
\textsc{Definicija:} Naj bo $\A: V \to U$. Velja:
\begin{enumerate}[(1)]
	\item $\A$ je surjektivna $\iff \im \A = U$
	\item $\A$ je injektivna $\iff \ker \A = \{0\}$
\end{enumerate}
\textsc{Dokaz} za (2):
\begin{itemize}
	\item[($\Rightarrow$)] $\A$ je injektivna. Vemo $\A0 = 0$. Zanima nas, za katere $x$ velja $\A x = 0$. Ker je injektivna je $x = 0 \Rightarrow \ker A = \{0\}$.
	\item[($\Leftarrow$)] $\ker \A = \{0\}$ Naj bosta $\A x = \A y$, $x, y \in V$.
	\begin{align*}
	&\Rightarrow \underbrace{\A x - \A y}_{\A(x-y) = 0} = 0 \\
	&\Rightarrow x - y \in \ker \A = \{0\} \\
	&\Rightarrow x - y = 0 \Rightarrow x = y
	\end{align*}
\end{itemize}
\hfill $\square$

\textsc{Izrek:} Naj bo $\A: V \to U$ linearna preslikava. Potem obstaja izomorfizem med vektorskima prostoroma $V/_{\ker \A}$ in $\im \A$. Izomorfizem deluje s predpisom:
\begin{equation*}
\hat{\A}: [x] \mapsto \A x
\end{equation*}

\textsc{Dokaz:}
\begin{itemize}
	\item \dashuline{Predpis je dober} t.j: $[x] = [y] \Rightarrow \A x = \A y$.
	\begin{equation*}
	x \sim y \Rightarrow x - y \in \ker \A \Rightarrow \underbrace{\A(x-y)}_{\A x - \A y = 0} = 0 \Rightarrow \A x = \A y
	\end{equation*}

	\item \dashuline{$\hat{\A}$ je linearna}
	\begin{multline*}
	\hat{\A}(\underbrace{\alpha[x]}_{[\alpha x]} + \underbrace{\beta[y]}_{[\beta y]}) = \\
	=\hat{\A}(\alpha x + \beta y) = \A(\alpha x + \beta y) = \alpha \A x + \beta \A y =\\
	= \alpha \hat{\A}([x]) + \beta \hat{\A}([y])
	\end{multline*}
	
	\item \dashuline{$\hat{\A}$ je surjektivna} -- sledi neposredno iz definicije $\hat{\A}$
	\item \dashuline{$\hat{\A}$ je injektvina}
	\begin{gather*}
	\underbrace{\hat{\A}([x])}_{\A x} = \underbrace{\hat{\A}([y])}_{\A y} \\
	\Rightarrow \A (x-y) = \A x - \A y = 0 \\
	\Rightarrow x - y \in \ker \A \Rightarrow \\
	\Rightarrow x \sim y \Rightarrow [x] = [y]
	\end{gather*}
\end{itemize}
$\Rightarrow \hat{\A}$ je linearne in bijektivna $\Rightarrow \hat{\A}: V/_{\ker \A} \to \im \A$ je izomorfizem vektorskih prostorov. \hfill $\square$

\textsc{Posledici:} Naj bo $\A: V \to U$ linearna preslikava
\begin{enumerate}[(1)]
	\item "Ce je $\A$ surjektivna, je vektorski prostor $V/_{\ker \A}$ izomorfen $U$.
	\item "Ce je $\A$ injektivna, je vektorski prostor $V$ izomorfen vektorskemu prostoru $\im \A$
	\begin{equation*}
	\A \text{ injektivna} \Rightarrow \ker \A = \{0\} \Rightarrow V/_{\{0\}} = V
	\end{equation*}
\end{enumerate}
%
\subsection{Vektorski prostor linearnih preslikav}
$V, U$ naj bosta vektorska prostora nad komutativnim obsegom $\OO$.
\begin{equation*}
\LL(V, U) = \{\A: V \to U; \text{ $\A$ je linearna}\}
\end{equation*}
Ni"celna preslikava 0 je element te mno"zice $0 \in \LL(V, U)$.

V $\LL(V, U)$ uvedemo operavijo $+$ (se"stevanje) po to"ckah:
\begin{align*}
\A, \mathcal{B} &\in \LL(V, U) \\
(\A + \mathcal{B})(x) &= \A x + \mathcal{B} x, \forall x \in V
\end{align*}
Velja $\A + \mathcal{B} \in \LL(V, U)$. Preverimo homogenost (aditivnost za DN):
\begin{equation*}
(\A + \mathcal{B})(\alpha x) = \alpha \A x + \alpha \mathcal{B} x = \alpha (\A x + \mathcal{B} x) = \alpha ((\A + \mathcal{B})x)
\end{equation*}
\textsc{Velja:}
\begin{itemize}
	\item $(\LL(V, U), +)$ je Abelova grupa
	\item $0$ (ni"celna preslikava) je ni"celni element
	\item $\A \in \LL(V, U); -\A = -\A x \forall x \in V$
	\begin{gather*}
		(-A)x = -\A x, \forall x \in V \\
		(\A + (-A))x = \A x + (-\A) x = \A x +(-\A)x = 0 (\in U), \forall x \in V \\
		\Rightarrow \A + (-\A) = 0
	\end{gather*}
\end{itemize}
\textbf{Mno"zenje s skalarji} definiramo po to"ckah:
\begin{gather*}
	(\alpha A)x = \alpha (A x), \forall x \in V, \alpha \in \OO \\
	\A \in \LL(V, U) \Rightarrow \alpha A \in \LL(V, U)
\end{gather*}
$\LL(V, U)$ postane z obema operacijama vektorski prostor nad $\OO$.
%
\textbf{Poseben primer} $U = V$

$\LL(V, V) \equiv \LL(V)$ -- mno"zica vseh endomorfizmov vektorskega prostora $V$. V mno"zico $\LL(V)$ uvedemo "ze mno"zenje (= komponiranje preslikav).
\begin{align*}
\A, \mathcal{B} &\in \LL(V) \\
(\A \mathcal{B})x &= A(Bx), \forall x \in V
\end{align*}
Mno"zenje je operacija na $\LL(V): A, \mathcal{B} \in \LL(V) \Rightarrow \A \mathcal{B} \in \LL(V)$.

$(\LL(V), \cdot)$ je polgrupa (mno"zenje je asociativno) in velja
\begin{itemize}
	\item $\A(\mathcal{B} + \mathcal{C}) = \A \mathcal{B} + \A \mathcal{C}$
	\item $(\mathcal{B} + \mathcal{C}) \A = \mathcal{B} \A + \mathcal{C} \A$
\end{itemize}
$(\LL(V), +, \cdot)$ je kolobar. Velja "se:
\begin{equation*}
(\alpha \A) (\beta \mathcal{B}) = (\alpha \beta) (\A \mathcal{B})
\end{equation*}
Pravimo, da je $\LL(V)$ \emph{algebra} nad $\OO$.

\textsc{Definicija:} $\A$ je \emph{algebra} nad komutativnim obsegom $\OO$, kadar je $\A$ vektorski prostor nad $\OO$, v katerem je dano mno"zenje
\begin{equation*}
\A \times \A \to \A \quad ((a, b) \mapsto ab)
\end{equation*}
ki ustreza pogojem:
\begin{itemize}
	\item $(\A, +, \cdot)$ je kolobar
	\item $(\alpha a) (\beta b) = (\alpha \beta) (ab)$ \hfill $\forall \alpha, \beta \in \OO, \quad \forall a, b, \in \A$
\end{itemize}
\textsc{Primeri:}
\begin{enumerate}[(1)]
	\item $\LL(V)$ je algebra
	\item $(\RR^M) \equiv \mathcal{F}(M, \RR)$ za operacije definirane po to"ckah je algebra
	\item $\RR[x]$ algebra polinomov z realnimi koeficienti, kjer so operacije definirane po to"ckah
\end{enumerate}
$id_V \in \LL(V)$ je enota algebre $\LL(V)$
\begin{equation*}
id_V (x) = x \forall x \in V
\end{equation*}
%
\subsection{Kon"cno razse"zni vektorski prostori}
\textsc{Definicija:} Naj bo $V$ vektorski prostor nad $\OO$ in $M \subseteq V$. $M$ je \emph{ogrodje} vektorskega prostora $V$, kadar velja $\Lin M = V$

$M \neq \varnothing$ je ogrodje vektorskega prostora $V$, kadar za vsak $x \in V$ velja
\begin{equation*}
\exists v_1, \dots v_m \in M, \alpha_1, \ldots, \alpha_m \in \OO: x = \alpha_1 v_1 + \cdots + \alpha_m v_m
\end{equation*}
\textsc{Definicija:} Vektorski prostor $V$ je \emph{kon"cno razse"zen}, kadar ima kak"sno kon"cno ogrodje.
\begin{gather*}
M = \{v_1, \ldots v_m\} \text{ ogrodje v.p. $V$} \\
x \in V \Rightarrow x = \alpha_1v_1 + \cdots + \alpha_m v_m, \quad \alpha_1,\ldots \alpha_m \in \OO
\end{gather*}
Poglejmo si kako je z enoli"snostjo zapisa. Naj bo
\begin{align*}
0 &= 0v_1 + 0v_2 + \cdots + 0v_m \\
0 &= \alpha_1 v_1 + \alpha_2 v_2 + \cdots + \alpha_m v_m
\end{align*}
"Ce je zapis enoli"cen, velja sklep
\begin{equation*}
\alpha_1v_1 + \cdots + \alpha_m v_m = 0 \Rightarrow \alpha_1 = \cdots = \alpha_m = 0
\end{equation*}
Poglejmo si "se, kako je v obratno smer. Naj velja prej"snji sklep
\begin{gather*}
\begin{aligned}
x &= \alpha_1 v_1 + \cdots + \alpha_m v_m \\
x &= \beta_1 v_1 + \cdots + \beta_m v_m
\end{aligned}\\
\begin{aligned}
&\Rightarrow (\alpha_1 - \beta_1)v_1 + \cdots + (\alpha_m - \beta_m)v_m = 0 \\
&\Rightarrow \alpha_1 -\beta_1 = \cdots = \alpha_m - \beta_m = 0 \\
&\Rightarrow \beta_j = \alpha_j \quad \forall j = 1, \ldots, m
\end{aligned}
\end{gather*}
Torej velja enoli"cnost zapisa.

\textsc{Definicija:} Vektorji $v_1, \ldots v_m$ so \emph{linearno neodvisni}, kadar velja sklep
\begin{equation*}
\alpha_1 v_1 + \cdots + \alpha_m v_m = 0 \Rightarrow \alpha_1 = \cdots \alpha_m = 0
\end{equation*}

"Ce je $M = \{v_1, \ldots, v_m\}$ ogrodje vektorskega prostora $V$, potem vsak $x \in V$ lahko zapi"semo v obliki $x = \alpha_1 v_1 + \cdots + \alpha_m v_m$, pri "cemer so $\alpha_1, \ldots, \alpha_m$ enoli"cno dolo"ceni z $x$ natanko takrat, kadar so $v_1, \ldots v_m$ linearno neodvisni.

"Ce so $v_1, \ldots, v_m$ linearno neodvisni, potem so razli"cni ($i \neq j \Rightarrow v_i \neq v_j$). Naj bo $v_1 = v_2$. Zapi"semo lahko:
\begin{equation*}
\underbrace{1}_{\neq 0}v_1 + \underbrace{(-1)}_{\neq 0}v_2 + 0v_3 + \cdots + 0v_m = 0
\end{equation*}
$\Rightarrow$ vektorji niso neodvisni.

\textsc{Definicija:} Naj bo $M \subseteq V$. $M$ je linearno neodvisna, kadar je vsaka njena kon"cna podmno"zica linearno neodvisna.

\textsc{Definicija:} Naj bo $M \subseteq V$. $M$ je \emph{baza} vektorskega prostora $V$, kadar je linearno neodvisna in hkrati ogrodje vektorskega prostora $V$.

\textsc{Primeri:}
\begin{enumerate}[1)]
	\item Baze v $\RR^3$ so oblike $\{\vec{a}, \vec{b}, \vec{c}\}$, kjer so $\vec{a}, \vec{b}, \vec{c} \in \RR^3$ linearno neodvisni.
	\item $V = \OO^n$
	\begin{equation*}
	e_j  (0, \ldots, 0, \underbrace{1}_{\text{$j$-to mesto}}, 0, \ldots, 0) \in \OO^n
	\end{equation*}
	$\{e_1, e_2, \ldots e_n\}$ je \emph{standardna baza} $\OO^n$.
	\begin{equation*}
	x = (\alpha_1, \ldots, \alpha_n) \in \OO^n \Rightarrow x = \alpha_1 e_1 + \cdots + \alpha_n e_n
	\end{equation*}
	
	\item $V = \RR[x]$\\
	\begin{gather*}
		p(x) \in \RR[x] \\
		p(x) = a_0 + a_1 x + \cdots + a_n x^n
	\end{gather*}
	Baza tega prostora je
	\begin{equation*}
	\{p_j(x) = x^j: j = 0, 1, \ldots\} = \{1, x, x^2, x^3, \ldots\}
	\end{equation*}
\end{enumerate}
%
\textsc{Definicija:} Vektorji $v_1, \ldots v_m$ so \emph{linearno odvisni}, kadar niso linearno neodvisni.

Naj bodo $v_1, \ldots v_m$ linearno odvisni ($m > 1$). Potem obstajajo tudi skalarji $\alpha_1, \ldots \alpha_m \in \OO$, da niso vsi enako 0, vendar pa je
\begin{equation*}
\alpha_1 v_1 + \cdots + \alpha_m v_m = 0
\end{equation*}
Recimo, da $\alpha_1 \neq 0$, Potem je
\begin{equation*}
v_1 = \underbrace{(-\alpha_1^{-1} \alpha_2)}_{\beta_2}v_2 + \cdots + \underbrace{(-\alpha_1^{-1} \alpha_m)}_{\beta_m}v_m
\end{equation*}
$v_1$ je linearna kombinacija elemetnov $v_2, \ldots v_m$. 

Potem obstaja tak $j \in \{j, \ldots, m\}$, da je $v_j$ linearna kombinacija vektorjev
\begin{equation*}
v_1, \ldots v_{j-1}, v_{j+1}, \ldots v_m
\end{equation*}
\textbf{Obratno:} "Ce velja prej"snja trditev, potem so $v_1, \ldots v_m$ linearno odvisni
\begin{gather*}
v_1 = \beta_2 v_2 + \cdots + \beta_m v_m \\
1 v_1 + (-\beta_2)v_2 + \cdots + (-\beta_m)v_m = 0
\end{gather*}
%
\textsc{Trditev:} Naj bodo $v_1, \ldots v_m$ linearno odvisni in $v_1 \neq 0$, $m > 1$. Potem obstaja tak $k > 1$, $k \leq m$, da je $v_k$ linearna kombinacija vektorjev $v_1, \ldots v_{k-1}$.

\textsc{Dokaz:} Naj bo $\alpha_1 v_1 + \cdots + \alpha_m v_m = 0$, pri "cemer niso vsi $\alpha_j = 0$.
\begin{gather*}
\exists \alpha_j \neq 0: j > 1 \\
k = \max \{j: \alpha_j \neq 0\} \quad (k > 1) \\
\Rightarrow v_k = \beta_1 v_1 + \cdots + \beta_1{k-1}v_{k-1}
\end{gather*}
\hfill $\square$

\textsc{Trditev:} Naj vektorji $x_1, \ldots, x_m$ tvorijo ogrodje vektorskega prostora $V$. "Ce obstaja $j \in \{1, \ldots, m\}$, da je $x_j$ linearna kombinacija vektorjev $x_i, i \in \{1, \ldots, m\} \setminus \{j\}$, potem vektorji $\{x_i: i \in \{1, \ldots, m\} \setminus \{j\}\}$ sestavljajo ogrodje vektorskega prostora $V$.

\textsc{Dokaz:} Smemo vzeti $j=1$, ker lahko spremenimo indekse.
\begin{gather*}
x_1 = \alpha_2 x_2 + \cdots + \alpha_m x_m\\
v \in V
\end{gather*}
\begin{multline*}
v = \beta_1 x_1 + \cdots + \beta_m x_m = \\
= \beta_1 (\alpha_2 x_2 + \cdots + \alpha_m x_m) + \beta_2 x_2 + \cdots + \beta_m x_m = \\
= (\beta_1 \alpha_2 + \beta_2)x_2 + \cdots + (\beta_1 \alpha_m + \beta_m)x_m
\end{multline*}
Torej $x_2, \ldots, x_m$ sestavljajo ogrodje vektorskega prostora $V$.

\hfill $\square$

\textsc{Trditev:} Iz vsakega kon"cnega ogrodja vektorskega prostora $V \neq \{0\}$, lahko izberemo bazo.

\textsc{Dokaz:} Iz ogrodja postopoma odstanjujemo vektorje, ki so linearna kombinacija drugih. Na koncu ostane baza. (Predpostavimo lahko, da so vektorji v ogrodju razli"cni).

\textsc{Posledica:} Vsak netrivialen kon"cno razse"zen vektorski prostor ima bazo.

\textsc{Trditev:} Naj vektorji $x_1 \ldots x_m$ sestavljajo ogrodje vektorskega prostora $V$, vektorji $y_1, \ldots, y_n$ pa naj bodo linearno neodvisni. Potem je $m \geq n$.

\textsc{Dokaz:} Predpostavimo, da je $n > m$. Imamo dve vrsti vektorjev:
\begin{equation*}
x_1, \ldots , x_m \quad y_1, \ldots, y_n
\end{equation*}
Premaknemo $y_1$ v bazo in dobimo
\begin{equation*}
y_1, x_1, \ldots, x_m
\end{equation*}
To je ogorodje, vektorji $y_1, x_1, \ldots x_m$ pa so linearno odvisni. Torej obstaja tak vektor, ki je linearna kombinacija predhodnih. To je eden od vektorjev $x_1, \ldots x_m$. Tega odstranimo in ostane ogrodje
\begin{equation*}
y_1, x_1', \ldots, x_{m-1}'
\end{equation*}
Postopem ponovimo "se enkrat in dobimo
\begin{equation*}
y_2, y_1, x_1', \ldots, x_{m-1}'
\end{equation*}
Ti vektorji sestavljajo ogrodji in so linearno odvisni. Odstranimo vektor, ki je linearna kombinacija predhotnih. To je eden od vektorjev $x_1', \ldots, x_{m-1}'$, ker so $y_i$ linearno neodvisni. Dobimo ogrodje
\begin{equation*}
y_2, y_1, x_1'', \ldots, x_{m-2}''
\end{equation*}
Postopoma izpodrinemo vse $x$-e in dobimo ogrodje $y_m, y_{m-1}, \ldots, y_1$. Zato je $y_{m+1}$ linearna kombinacija vektorjev $y_1, \ldots, y_m$. $\rightarrow \leftarrow$ ($y_1, \ldots, y_n$ so linearno neodvisni).

\textbf{Sklep:} $m \geq n$ \hfill $\square$

\textbf{Posledica:} Vse baze netrivialnega kon"cno razse"znege vektorksega prostora imajo enako elementov.

\textsc{Definicija:} "Stevilo elementov v bazi kon"cno razse"znega vektorskega prostora imenujemo \emph{razse"znost} ali \emph{dimenzija} tega vektorskega prostora. \textbf{Oznaka:} $\dim V$

\textsc{Dokaz posledice:} $V \neq \{0\}$. Naj bosta
\begin{align*}
X &= \{x_1, \ldots, x_m\} \\
Y &= \{y_1, \ldots, y_n\}
\end{align*}
bazi vektorskega prostora $V$ in velja $x_i \neq x_j \forall i \neq j$ in $y_i \neq y_j \forall i \neq j$. Potem velja:

$X$ je ogrodje, $Y$ niz linearno neodvisnih vektorjev $\Rightarrow m \geq n$\\
$Y$ je ogrodje, $X$ niz linearno neodvisnih vektorjev $\Rightarrow n \geq m$ 

$\Rightarrow m = n$

\textsc{Izrek:} Naj bo $V$ $n$-razse"zen vektorski prostor nad $\OO$ (komutativen), $N \in \NN$. Potem je vektorski prostor $V$ izomorfen vektorskemu prostoru $\OO^n$.

\textsc{Dokaz:} Naj bo $\mathcal{V} = \{v_1, \ldots, v_n\}$ baza $V$ (\emph{urejena}, t.j., dolo"cen vrstni red).
\begin{gather*}
x \in V, x \mapsto (\alpha_1, \ldots, \alpha_n) \in \OO^n \\
x = \alpha_1 v_1 + \cdots + \alpha_n v_n
\end{gather*}
ker je $\{v_1, \ldots, v_n\}$ baza, so $\alpha_1, \ldots, \alpha_n$ enoli"cno dolo"ceni. Zapi"semo lahko preslikavo
\begin{align*}
\Phi_v&: V \to \OO^n \\
\Phi_v (x) &= (\alpha_1, \ldots, \alpha_n)
\end{align*}
$\Phi_v$ je odvisen od vrstenga reda baze in je izomorfen . Zapi"semo lahko tudi preslikavo
\begin{align*}
\Psi_v&: \OO^n \to V \\
\Psi_v (\alpha_1, \ldots, \alpha_n) &= \alpha_1 v_1 + \cdots + \alpha_n v_n
\end{align*}
$\Psi_v$ je inverz preslikave $\Phi_v \Rightarrow \Psi_v, \Phi_v$ sta bijekciji. Zado"s'ca dokazati, da je $\Psi$ linearna. Torej je potrebno dokazati homogenost in aditivnost. Oboje je o"citno, zato nismo napisali dokaza. Lahko ga napi"se"s za vajo doma (ni te"zek, saj je o"citen).

\textsc{Izrek:} Kon"cno razse"zna vektorska prostora nad istim obsegom sta izomorfna natanko takrat, kadar imata enako dimenzijo.

\textsc{Dokaz:} Smemo privzeti, da sta $V, U$ netrivialna. Kot se je izrazil profesor: ,,"ce sta $V$ in $U$ trivialna, je tudi dokaz trivialen.''
\begin{itemize}
	\item[($\Leftarrow$)] $\dim V = \dim U = n \Rightarrow$ obstajata izomorfizma  $\Phi, \Psi$:
	\begin{align*}
	\Phi &: V \to \OO^n \\
	\Psi &: \OO^n \to U
	\end{align*}
	$\Rightarrow \Psi \Phi: V \to U$ je izomorfizem
	
	\item[($\Rightarrow$)] Naj bo $F: V \to U$ izomorfizem vektorskih prostorov in $\dim V = n, n \in \NN$, ter $\{v_1, \ldots, v_n\}$ baza $V$. Trdimo, da je $\{F(v_1), \ldots, F(v_n)\}$ baza $U$.
	\begin{enumerate}
		\item \dashuline{linearna neodvisnost}
		\begin{gather*}
			\alpha_1 F(v_1) + \cdots + \alpha_n F(v_n) = 0 \\
			F(\alpha_1 v_1 + \cdots + \alpha_n v_n) = F(0) \\
			\Rightarrow \alpha_1 v_1 + \cdots + \alpha_n v_n = 0 \Rightarrow \\
			\Rightarrow \alpha_1 = \cdots = \alpha_n = 0
		\end{gather*}
		
		\item \dashuline{$\{F(v_1) , \ldots, F(v_n)\}$ je ogrodje}
		\begin{gather*}
			u \in U \Rightarrow \exists v \in V: F(v) = u \\
			v = \beta_1 v_1 + \cdots + \beta_n v_n \Rightarrow \\
			\Rightarrow u = f(v) = F(\beta_1 v_1 + \cdots + \beta_n v_n) = \\
			= \beta_1 F(v_1) + \cdots + \beta_n F(v_n)
		\end{gather*}
	\end{enumerate}
	\hfill $\square$
\end{itemize}
%
\textsc{Trditev:} Naj bo $V \neq \{0\}$ kon"cno razse"zen vektorski prostor. "Ce so $v_1, \ldots, v_m \in V$ linearno neodvisni, obstaja baza $V$, ki vsebuje $v_1, \ldots, v_m$.

\textsc{Dokaz:} $u_1, \ldots, u_n$ naj tvorijo ogrodje $V$.

$\Rightarrow \{v_1, \ldots, v_m, u_1, \ldots, u_n\}$ je ogrodje $V$. Postopoma iz tega ogrodja odtranjujemo vektorje, ki so linearna kombinacija vektorjev pred njimi. Vsi vektorji $v_1, \ldots, v_m$ ostanejo, ker so linearno neodvisni. Ostane nam baza, ki vsebuje $\{v_1, \ldots, v_n\}$.

\textsc{Trditev:} Naj bo $V$ kon"cno razse"zen vektorski prostor in $U$ njegov vektorski podprostor. Potem je $\dim U \leq \dim V$, pri "cemer velja ena"caj le v primeru $U = V$.

\textsc{Dokaz:} $V \neq \{0\}, \dim V = n \in \NN$.

$U \subseteq V, U \neq \{0\}$

$u_1, \ldots, u_m \in U$ linearno neodvisni v $U$ ($\Rightarrow$ v $V$)., zato je $m \leq n$. Naj bo $m$ maksimalen. Trdimo, da je potem $\{u_1, \ldots, u_m\}$ baza $U$. Zado"s"ca dokaz, da je $\mathcal{U} = \{u_1, \ldots, u_m\}$ ogrodje $U$.

"Ce $\mathcal{U}$ ni ogrodje vektorskega prostora $U$, obstaja tak $u \in U$ da $u$ ni linearna kombinacija vektorjev $u_1, \ldots, u_m$ ($u \notin \Lin \mathcal{U}$). Potem so vektorji $u_1, \ldots, u_m, u$ linearno neodvisni, to pa je protislovje z maksimalnostjo "stevila $m$. Torej je $\mathcal{U}$ ogrodje vektorskega prostora $U$, zato je baza $U$ in $\dim U = m (\leq n)$ "Ce je $\dim U = n$, je $U$ baza $V$, zato $U = V$.

\hfill $\square$

\textsc{Trditev:} Naj bo $V$ kon"cno razse"zen vektorski prostor in $U$ njegov vektorski podprostor. Potem obstaja tak vektorski podprostor $W \subset V$, da velja $V = U \oplus W$

\textsc{Dokaz:} $U = \{0\}, W = V$. Bolj zanimivo je, "ce $U \neq \{0\}, \{u_1, \ldots, u_m\}$ baza $U$. Dopolnimo jo do baze $V$
\begin{equation*}
\{u_1, \ldots u_m, u_{m+1}, \ldots, u_{m+k}\}
\end{equation*}
Postavimo $W = \Lin \{u_{m+1}, \ldots, u_{m+k}\}$. "Ce dopolnimo tako, da ni"c ne dopolnimo potem:
\begin{align*}
	W &= \Lin\{\} = \{0\} \\
	U &= V
\end{align*}
\dashuline{Trdimo, da je $V = U \oplus W$}
\begin{gather*}
v \in V \Rightarrow v = \underbrace{\alpha_1 u_1 + \cdots + \alpha_m u_m}_{x \in U} +\underbrace{\alpha_1{m+1} u_{m+1} + \cdots + \alpha_{m+k} u_{m+k}}_{y \in W} \\
v = x + y, x \in U, y \in W \\
\Rightarrow V = U + W
\end{gather*}
\dashuline{$U \cap W = \{0\}$}
\begin{gather*}
z \in U \cap W \\
z = \beta_1 u_1 + \cdots + \beta_m u_m = \beta_1{m+1} u_{m+1} + \cdots + \beta_{m+k} u_{m+k} \\
\beta_1 u_1 + \cdots + (-\beta_{m+k})u_{m+k} = 0 \\
\Rightarrow \beta_1 = \cdots = \beta_{m+k} = 0 \Rightarrow z = 0
\end{gather*}
$\Rightarrow V = U \oplus W$

\hfill $\square$

Tej trditvi pravimo \emph{trditev o eksistenci direktnega komplementa}.

\textsc{Trditev:} Naj bo $V$ kon"cno razse"zen vektorski prostor in $U, W$ njegova vektorska podprostora. "Ce je $U \cap W = \{0\}$, potem velja $\dim U \oplus W = \dim U + \dim W$.

\textsc{Dokaz:} $U, W$ sta netrivialna, druga"ce je o"citno. Naj bosta
\begin{gather*}
\{u_1, \ldots, u_m\} \text{ baza $U$, $\dim U = m$} \\
\{w_1, \ldots, w_n\} \text{ baza $W$, $\dim W = n$}
\end{gather*}
Trdimo, da je $\{u_1, \ldots, u_m , w_1, \ldots, w_n\}$ baza $U \oplus W$.
\begin{enumerate}
	\item linearna neodvisnost
	\begin{gather*}
	\alpha_1 u_1 + \cdots + \alpha m u_m + \beta_1 w_1 + \cdots + \beta_n w_n = 0 \\
	z = \underbrace{\alpha_1 u_1 + \cdots + \alpha_m u_m}_{\in U} = \underbrace{(-\beta_1)w_1 + \cdots + (-\beta_n)w_n}_{\in W} \\
	z \in U \cap W = \{0\} \Rightarrow z = 0 \\
	\Rightarrow \alpha_1 = \cdots = \alpha_m = 0, \\
	\beta_1 = \cdots = \beta_n = 0
	\end{gather*}
	(1) $\Rightarrow u_1 \cdots u_m, w_1 \cdots w_n$ so razli"cni
	
	\item $\Lin \{u_1, \ldots, u_m, w_1, \ldots, w_n\} = U \oplus W$

	O"citno je, da je $\Lin \{u_1, \ldots, u_m, w_1, \ldots, w_n\} \subseteq U \oplus W$. Dokazati je treba "se obratno smer ($\supseteq$).
	\begin{gather*}
	x \in U \oplus W \Rightarrow \\
	\Rightarrow x = u + 2, u \in U, w \in W \\
	u = \alpha_1 u_1 + \cdots + \alpha_m u_m \\
	w = \beta_1 w_1 + \cdots + \beta_n w_n \\
	\Rightarrow x = \alpha_1 u_1 + \cdots + \alpha_m u_m + \beta_1 w_1 + \cdots + \beta_n w_n
	\end{gather*}
\end{enumerate}
$(1), (2) \Rightarrow \dim U \oplus W = m + n = \dim U + \dim W$

\textsc{Trditev:} Naj bo $V$ kon"cno razse"zen vektorski prostor in $U \leq V, W \leq V$. Ptem velja enakost (= \emph{dimeznisjska formula}):
\begin{equation*}
\dim (U + W) = \dim U + \dim W - \dim (U \cap W)
\end{equation*}
\textsc{Osnovna ideja dokaza:} Vzamemo bazo vektorskega prostora $U \cap W$. V $W$ najdemo vektorje s katerimi raz"sirimo $U \cap W$. Linearno ogrinja"co teh vektorjev ozna"cimo z $Z$. Velja $U + W = U \oplus Z$.

$\Rightarrow \dim (U + W) = \dim U + \dim Z$ in \\
$W = (U \cap W) \oplus  \Rightarrow \dim W = \dim (U \cap W) + \dim Z$

Iz tega sledi zgornja formula.

\textsc{Trditev:} Naj bo $V = U \oplus W, \dim V < \infty$. Potem je vektorski prostor $V/_U$ izomorfen $W$, vektorski prsotor $V/_W$, pa je izomorfen $U$.

\textsc{Dokaz:}
\begin{gather*}
	f: W \to V/_U \\
	f(w) = [w] = w + U
\end{gather*}
\dashuline{$f$ je linearna preslikava}
\begin{equation*}
f (w_1 + w_2) = [w_1 + w_2] = [w_1] + [w_2] = f(w_1) + f(w_2)
\end{equation*}
$\Rightarrow f$ je aditivna. Podobno doka"zemo homogenost.

\dashuline{$f$ je injektvina}
\begin{gather*}
f(w_1) = f(w_2) \Rightarrow \\
\Rightarrow [w_1] = [w_2] \Rightarrow \\
\Rightarrow w_1 \sim w_2 \Rightarrow \\
\Rightarrow w_1 - w_2 \in U \\
w_1 - w_2 \in W \\
\Rightarrow w_1 - w_2 \in U \cap W = \{0\} \Rightarrow w_1 - w_2 = 0 \\
\Rightarrow w_1 = w_2
\end{gather*}
\dashuline{$f$ je surjektivna:}
\begin{gather*}
[v] \in V/_U, v \in V \\
v = u + w, u \in U, w \in W
\end{gather*}
\dashuline{$f(w) = [v]$}
\begin{gather*}
f(w) = w \\
v = u + w \Rightarrow u = v - w \in U \Rightarrow w \sim v
\end{gather*}
\hfill $\square$

Naj bo $V= V_1 \oplus V_2 \Rightarrow V/_{V_1} \cong V_2 \land V/_{V_2} \cong V_1$

\textsc{Trditev:} Naj bo $V$ kon"cno razse"zen vektorski prostor in $U$ njegov vektorski podprostor. Potem je
\begin{equation*}
\dim V/_U = \dim V - \dim U
\end{equation*}
\textsc{Dokaz:} Poi"s"cimo $W \leq V$, da je $V = U \oplus W$. Ker je $V/_U \cong W$, velja $\dim V/_U = \dim W$. Vemo:
\begin{equation*}
\dim V = \dim U + \dim W
\end{equation*}
Zato je
\begin{equation*}
\dim V/_U = \dim V - \dim U
\end{equation*}
%
\subsection{Linearne preslikave na kon"cno razse"znih V.\,P.}
Naj bosta $V, U$ kon"cno razse"zna vektorska prostora nad $\OO$ in naj bo $\mathcal{A} \in \LL (V, U)$ linearna.

Naj bo $\mathcal{V} = \{v_1, \ldots v_n\}$ baza $V$. "Ce poznamo slike $\A v_1, \ldots, \A v_n$, poznamo $\A$:
\begin{gather*}
x \in V, \quad \exists \alpha_1, \ldots, \alpha_n \in \OO: \\
x = \alpha_1 v_1 + \cdots + \alpha_n v_n \\
\Rightarrow \A x = \A(\alpha_1 v_1 + \cdots + \alpha_n v_n) = \alpha_1 \A v_1 + \cdots +  \alpha_n \A v_n
\end{gather*}
\subsubsection{Poseben primer}
\begin{gather*}
V = \OO^n ,\quad U = \OO^m \\
A = \LL(\OO^n, \OO^m) \\
\{e_1, \ldots, e_n\} \text{ standardna baza $\OO^n$} \\
e_j = \begin{bmatrix}
0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots
\end{bmatrix} \\
x \in \OO^n, \quad x = \begin{bmatrix}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{bmatrix}
\end{gather*}
Poznamo $Ae_1, \ldots Ae_n \Rightarrow$ poznamo $A$.
\begin{gather*}
Ae_j \in \OO^m \\
Ae_j = \begin{bmatrix}
a_{1j} \\ a_{2j} \\ \vdots \\ a_{mj}
\end{bmatrix} \in \OO^m \\
A = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
a_{31} & a_{32} & \cdots & a_{3n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} = \text{$m \times n$ matrika, ki predstavlja linearno preslikavo $A$}
\end{gather*}
$a_{ij} (1 \leq i \leq m, 1 \leq j \leq n)$ je "clen matrike $A$. $a_{ij}$ le"zi v $i$-ti vrstici in $j$-tem stolpcu.
\begin{gather*}
A^{(j)} = \begin{bmatrix}
a_{1j} \\ a_{2j} \\ \vdots \\ a^{mj}
\end{bmatrix} = \text{$j$-ti stolpec matrike} \\
A_{(i)} = \begin{bmatrix}
a_{i1} & a_{i2} & \cdots & a_{in}
\end{bmatrix} \\
A = [a_{ij}]\\\\
A : \OO^n \to \OO^m \\
x = \begin{bmatrix}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{bmatrix} \in \OO^n \\
A = [a_{ij}] \\
Ax = y \\
y = \begin{bmatrix}
y_1 \\ y_2 \\ \cdots \\ y_m
\end{bmatrix}
\end{gather*} 
$y$ izra"cunamo kot:
\begin{multline*}
y = Ax = A(x_1 e_1 + x_2 e_2 + \cdots + x_n e_n) = \\
= x_1 A e_1 + x_2 A e_2 + \cdots + x_n A e_n = \\
= x_1 A^{(1)} + x_2 A^{(2)} + \cdots + x_n A^{(n)} \\
\Rightarrow y_i = x_1 a_{i1} + x_2 a_{i2} + \cdots + x_n a_{in} = \\
y_i = \sum_{j=1}^{n} a_{ij} x_j, \quad i = 1, \ldots, m
\end{multline*}
\textsc{Primer:} $A: \RR^3 \to \RR^3$ zasuk za kot $\varphi$ okrog $z$-osi. Kaj je matrika $A$ in kam $A$ preslika to"cko $(1, 2, 3)$?
\begin{align*}
A e_1 &= A\vec{i} = A^{(1)} \\
A e_2 &= A\vec{j} = A^{(2)} \\
A e_3 &= A\vec{k} = A^{(3)}
\end{align*}
\begin{gather*}
A^{(3)} = A\vec{k} = \begin{bmatrix}0 \\ 0 \\ 1\end{bmatrix} \\
A^{(1)} = A\vec{i} = \begin{bmatrix}\cos \varphi '' \sin \varphi \\ 0 \end{bmatrix} \\
A^{(2)} = A\vec{j} = \begin{bmatrix}- \sin \varphi \\ \cos \varphi \\ 0\end{bmatrix} \\
A = \begin{bmatrix}
\cos \varphi & -\sin \varphi & 0 \\
\sin \varphi & \cos \varphi & 0 \\
0 & 0 & 1
\end{bmatrix}
\end{gather*}
Izra"cunajmo sliko to"cke $(1, 2, 3)$:
\begin{equation*}
A\begin{bmatrix}1 \\ 2 \\ 3\end{bmatrix} = \begin{bmatrix}
\cos \varphi - 2 \sin \varphi \\
\sin \varphi + 2 \cos \varphi \\
3
\end{bmatrix}
\end{equation*}
$\LL(\OO^n, \OO^m) \equiv \OO^{m \times n}$ je mno"zica vseh $m \times n$ matrik s "cleni $\OO$. Preslikave smo \emph{identificirali} (poistovetili) z matrikami.

$\LL(\OO^n, \OO^m)$ je vektorski prostor nad $\OO$. $\OO^{m \times n}$ postane vektorski prostor nad $\OO$.

Naj bosta $A, B \in \OO^{m \times n}$.
\begin{gather*}
(A + B) x = Ax + Bx \quad \forall x \in \OO^n \\
(\underbrace{A + B}_{C \in \OO^{m\times n}})e_j = Ae_j + Be_j = A^{(j)} + B^{(j)}
\end{gather*}
\begin{gather*}
\Rightarrow C^{(j)} = Ce_j = A^{(j)} + B^{(j)} \\
\Rightarrow c_{ij} = a_{ij} + b_{ij} \quad \forall i,j \\
\end{gather*}
$\Rightarrow$ v $\OO^{m \times n}$ se"stevamo po "clenih. Podobno je z mno"zenjem s skalarji.
%
\subsubsection{Splo"sna situacija}
Naj bosta $V, U$ vektorska prostora nad $\OO$. 
\begin{gather*}
\begin{aligned}
\dim V &= n\\
\dim U &= m
\end{aligned} \\
\begin{aligned}
\mathcal{V} &= \{v_1, \ldots, v_n\} \text{ urejena baza $V$} \\
\mathcal{U} &= \{u_1, \ldots, u_n\} \text{ urejena baza $U$}
\end{aligned}
\end{gather*}
$\A = \LL(V, U)$, $\A$ poznamo, "ce poznamo slike $\A v_j, \quad j = 1, \ldots, n$.
\begin{gather*}
\Phi_\mathcal{V}: V \to \OO^n \text{ izomorfizem} \\
\begin{aligned}
v &\in V \\
v &= \alpha_1 v_1 + \cdots + \alpha_n v_n \\
v &\to (\alpha_1, \ldots, \alpha_n) = \Phi_\mathcal{V}(v) = \begin{bmatrix}\alpha_1 \\ \vdots \\ \alpha_n\end{bmatrix}
\end{aligned} \\
\Psi_{\mathcal{V}}(v_j) = \begin{bmatrix}0 \\ \vdots \\ 0 \\ 1 \\ 0 \\ \vdots \\ 0\end{bmatrix} = e_j
\end{gather*}
Podobno velja za izomorfizem $\Phi_\mathcal{U}: U \to \OO^m$.
\begin{figure}[!htbp]
	\centering
	\begin{tikzpicture}
	\node (V) at (0, 0) {V};
	\node (U) at (3, 0) {U};
	\node (On) at (0, -3) {$\OO^n$};
	\node (Om) at (3, -3) {$\OO^m$};
	
	%\draw (Point1) -- (Point2) node [<position>, fill=white] {Label Text};
	
	\draw[->] (V) edge node [midway, above] {$\A$} (U);
	\draw[->] (V) edge node [midway, left] {$\Phi_\mathcal{V}$} (On);
	\draw[->] (U) edge node [midway, right] {$\Phi_\mathcal{U}$} (Om);
	\draw[->] (On) edge node [midway, below] {$A$} (Om);
	\end{tikzpicture}
	\caption{Diagram preslikave}
\end{figure}

Diagram \emph{komutira} $\Phi_\mathcal{U}\A = A\Phi_\mathcal{V}$
\begin{gather*}
(\Phi_{\mathcal{U}}\A)v_j = (A \Phi_{\mathcal{V}})v_j = Ae_j = A^{(j)} \\
(\Phi_{\mathcal{U}}\A)v_j = \Phi_{\mathcal{U}}(\A v_j) = \Phi_{\mathcal{U}} (\alpha_1 u_1 + \cdots + \alpha_m u_m) = \alpha_1 e_1 + \cdots + \alpha_m e_m = \begin{bmatrix}\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_m \end{bmatrix} \\
\A v_j = \alpha_1 u_1 + \alpha_2 u_2 + \cdots + \alpha_m u_m \\
\Rightarrow A^{(j)} = \begin{bmatrix}\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_m \end{bmatrix} \Rightarrow \alpha_i = a_{ij} \quad \forall i, j
\end{gather*}
\begin{equation*}
\A v_j = a_{1j} u_1 + a_{2j} u_2 + \cdots + a_{mj} u_m
\end{equation*}
Linearni preslikavi $\A \in \LL(V, U)$ priredimo (glede na bazi $\mathcal{U}, \mathcal{V}$) matriko $A \in \OO^{m \times n}$.
\begin{gather*}
\begin{aligned}
F : \LL(V, U) &\to \OO^{m \times n} \\
\A &\mapsto A = F(\A)
\end{aligned} \\
F(\A) = \Phi_{\mathcal{U}}\A\left(\Phi_{\mathcal{V}}\right)^{-1}
\end{gather*}
$F$ je izomorfizem med $\LL(V, U)$ in $\OO^{m \times n}$
\begin{itemize}
	\item  aditivnost in homogenost sta o"citni
	\item iz diagrama hitro dobimo inverz $F^{-1} = \left(\Phi_{\mathcal{U}}\right)^{-1}A\Phi_{\mathcal{V}}$
\end{itemize}
\begin{equation*}
\dim \LL(V, U) = \dim \OO^{m \times n} = ?
\end{equation*}
Standradna baza $\OO^{m \times n}$ je sestavljena iz \emph{elementarnih matrik}. V elementarni matriki se nahaja ena 1, ostali "cleni so 0.
\begin{align*}
E_{pq} &= [e_{ij}] \quad i = 1, \ldots, m \quad j = 1, \ldots, n \\
e_{ij}& = \begin{cases}
1 & i = p \land j = q \\
0 & \text{sicer}
\end{cases}
\end{align*}
%
\subsubsection{Mno"zenje matrik}
Naj bodo $U, V$ in $W$ vektorski prostori, linearna preslikava $\mathcal{B}: W \to V$, $\A: V \to U$ in $\mathcal{C}: W \to U$, t.j.: $\mathcal{C} = \mathcal{A} \mathcal{B}$. 

$\mathcal{U}$ je urejeneba baza v.p. $U$, $\mathcal{V}$ urejena baza $V$, $\mathcal{W}$, pa urejena baza $W$.

Poznamo $\Phi_{\mathcal{V}}: V \to \OO^n$, $\Phi_{\mathcal{U}}: U \to \OO^m$ in $\Phi_\mathcal{W}: W \to \OO^p$. in poznamo preslikavi $A: \OO^n \to \OO^m$, ter $B: \OO^p \to \OO^n$. Zanima nas $C = AB$.
\begin{align*}
A &= [a_{ij}] \in \OO^{m \times n} \\
B &= [b_{ij}] \in \OO^{n \times p} \\
C &= [c_{ij}] \in \OO^{m \times p}
\end{align*}
\begin{gather*}
C = AB \\
C^{(j)} = C e_j = (AB)e_j = A(B e_j) = AB^{(j)} \Rightarrow \\
C^{(j)} = AB^{(j)} \quad \forall j \\
\Rightarrow C_ij = A_{(i)} B^{(j)} \\
C_{ij} = \sum_{k = 1}^{n} a_{ik} b_{kj}
\end{gather*}
%
\subsubsection{Poseben primer}
Naj bo $U = V = W$, in $m = n = p$.
\begin{equation*}
A, B \in \OO^{n \times n} \Rightarrow C = AB \in \OO^{n \times n}
\end{equation*}
$\LL(\OO^n) \equiv \OO^{n \times n}$  je \emph{algebra kvadratnih matrik}.
Naj bodo baze $U, V, W$ enake, to je $\mathcal{U} = \mathcal{V} = \mathbb{V}$. Skonstruiramo preslikavo
\begin{align*}
F: \LL(V) &\to \LL(\OO^n) \equiv \OO^{n \times n} \\
\A &\mapsto A \\
F(\A) &= \Phi_{\mathcal{V}} \A \Phi_{\mathcal{V}}^{-1}
\end{align*}
\textbf{Vemo:} $F$ je izomorfizem vektorskih prostorov $\LL(V)$ in $\OO^{n \times n}$.

\textsc{Trditev:} $F$ je izomorfizem med algebrama $\LL(V)$ in $\OO^{n \times n}$.

\textsc{Dokaz:} Zado"s"ca ugotoviti, da $F$ ohranja mno"zenje
\dashuline{$F(\mathcal{A} \mathcal{B}) = F(\A) F(\mathcal{B})$}

\begin{gather*}
F(\A \mathcal{B}) = \Phi_{\mathcal{V}} (\A \mathcal{B}) \Phi_{\mathcal{V}}^{-1} \\
F(\A) F(\mathbb{B}) = \Phi_{\mathcal{V}} \A \Phi_{\mathcal{V}}^{-1} \Phi_{\mathcal{V}} \mathcal{B} \Phi_{\mathcal{V}}^{-1} = \Phi_{\mathcal{V}} \A \mathcal{B} \Phi_{\mathcal{V}}^-1
\end{gather*}
\hfill $\square$

$id_V$ je enota algebre $\LL(V)$. $F(id_V)$ je enota algebre $\OO^{n \times n}$
\begin{equation*}
F(id_V) = id_{\OO^{n \times n}} = I
\end{equation*}
$I$ je \emph{enotska} (ali identi"cna) matrika. Velja:
\begin{equation*}
I^{(j)} = I e_j = e_j
\end{equation*}
torej 
\begin{equation*}
I = [e_1, e_1, \ldots, e_n]
\end{equation*}
Zapi"semo lahko tudi kot
\begin{equation*}
I = [\delta_{ij}]\quad i,j = 1, \ldots, n
\end{equation*}
kjer je $\delta_{ij}$ \emph{Kroneckerjeva delta}, za katero velja predpis
\begin{equation*}
\delta_{ij} = \begin{cases}
1 & i = j \\
0 & \text{sicer}
\end{cases}
\end{equation*}
%
\textsc{Definicija:} Naj bo $\A \in \LL(V)$ bijekcija ($\exists \mathcal{B} \in \LL(V): \A \mathbb{B} = \mathcal{B} \A = id_V$). Pravimo, da je $F(\A) = A$ \emph{obrnljiva}:
\begin{equation*}
\exists B \in \OO^{n \times n} : A B = BA = I
\end{equation*}
$A$ obrnljiva $\Rightarrow B$ je enoli"cno dolo"cena. Ozna"cimo:
\begin{equation*}
B = A^{-1}
\end{equation*}
\subsubsection{Rang linearne preslikave in matrike}
Naj bosta $V, U$ kon"cno razse"zna vektorksa prostora nad $\OO$ in $\A \in \LL(V, U)$.

\textsc{Izrek:} Za $\A$ velja formula
\begin{equation}
\label{eq:rang-izrek}
\dim (\im \A) + \dim (\ker \A) = \dim V
\end{equation}
\textsc{Dokaz:} Vemo, da sta vekotrska prostora $V_{\ker \A}$ in $\im \A$ izomorfna. Zato je $\dim V/_{\ker \A} = \dim (\im \A)$. Vemo $\dim V/_{\ker \A} = \dim V - \dim (\ker \A)$. $\Rightarrow$~\refeq{eq:rang-izrek}.

\hfill $\square$

\textsc{Definicija:} Rang preslikave $\A$ je $\dim (\im \A)$. Oznaka $\rang \A = \dim (\im \A)$.

\textsc{Trditev:} $\A = \LL(V, U)$
\begin{enumerate}
	\item $\A$ je injektivna $\iff \rang \A = \dim V$
	\item $\A$ je surjektivna $\iff \rang A = \dim U$
	\item $\A$ je bijektivna $\iff \dim V = \dim U = \rang \A$
\end{enumerate}
\textsc{Dokaz:}
\begin{enumerate}
	\item vemo: $\A$ injektivna $\iff \ker \A = \{0\}$
	\begin{equation*}
	\ker \A = \{0\} \iff \dim (\ker \A) = 0
	\end{equation*}
	
	\item vemo: $\A$ surjektivna $\iff \im \A = U$
	\begin{equation*}
	\im \A = U \iff \underbrace{\dim (\im \A)}_{\rang \A} = \dim U
	\end{equation*}
	
	\item kombiniramo 1 in 2.
\end{enumerate}
%
\textsc{Trditev:} Za $\A \in \LL(V)$ so ekvivalentne naslednje izjave:
\begin{enumerate}
	\item $\A$ je bijekcija
	\item $\A$ je surjekcija
	\item $\A$ je injekcija
	\item $\rang \A = \dim V$
\end{enumerate}
\textsc{Dokaz:} $U = V$ v prej"snji trditvi $\Rightarrow$
\begin{equation*}
\Rightarrow [(1) \iff (4), (2) \iff (4), (3) \iff (4)]
\end{equation*}
\textsc{Posledica:} Matrika $A \in \OO^{n \times n}$ je obrnljiva natanko takrat, kadar je $\rang A = n$.

\textsc{Dokaz:} V prej"snji trditvi vzamemo $V = \OO^n$ in $A$ razumemo kot endomorfizem vektorskih prostorov $\OO^n$. 

$A$ obrnljiva $\iff A$ bijekcija, t.j.: $(1) \iff (4)$ po prej"snji trditvi.

\textsc{Trditev:} Naj bo $\A \in \LL(V, U)$ in $A$ matrika, ki pripada $\A$ gelde na dai baz $\mathcal{V} \in V, \mathcal{U} \in U$. Potem velja:
\begin{equation*}
\rang \A = \rang A
\end{equation*}
\textsc{Dokaz:}
Nari"semo si diagram in opazimo, da komutira.
\begin{gather*}
\Phi_{\mathcal{U}} \A =  A \Phi_{\mathcal{V}} \\
(\Phi_{\mathcal{U}} \underbrace{\A) V}_{\im \A} = (A \underbrace{\Phi_{\mathcal{V}}) V}_{\OO^n} \Rightarrow \\
\Rightarrow \Phi_{\mathcal{U}} (\im \A) = \im A
\end{gather*}
$\Phi_{\mathcal{U}}$ je izomorfizem, zato je
\begin{gather*}
\begin{aligned}
\dim (\im \A) &= \dim (\im A) \\
\rang \A &= \rang A
\end{aligned}
\end{gather*}
%
Naj bo $A \in \OO^{m \times n} \equiv \LL(\OO^n, \OO^m)$. Velja
\begin{gather*}
\begin{aligned}
\im A &= \{Ax: x \in \OO^n\} = \\
&= \{A(x_1 e_1 + \cdots + x_n e_n): x \in \OO^n\} = \\
&= \{x_1Ae_1 + \cdots + x_n A e_n\} = \\
&= \{x_1 A^{(1)} + \cdots + x_n A^{(n): x_j \in \OO \forall j} = \\
& = \Lin \{A^{(1)}, \ldots, A^{(n)}\}
\end{aligned}
\end{gather*}
\textsc{Trditev:} Stolpci matrike $A$ tvorijo ogrodje vektorskega prostora $\im A$.

\textsc{Posledica:} Rang matrike $A$ je najve"cje "stevilo linearno neodvisnih stolpcev te matrike.

Operacije na matrkah, ki ohranjujejo rang:
\begin{enumerate}[S1)]
	\item  med sabo zamenjamo dva stolpca
	\item stolpec pomno"zimo z neni"celnim skalarjem
	\item Stolpci pri"stejemo ve"ckratnik kak"snega drugega stolpca
\end{enumerate}
V1, V2, V3 so analogne operacije na vrsticah.

\textsc{Trditev:} S1, S2, S3 in V1, V2, V3 ohranjajo rang.

\textsc{Dokaz:}
\begin{enumerate}[S1)]
	\item o"citno
	\item  Dokazati moramo, da velja
	\begin{equation*}
	L1 = \Lin \{\alpha A^{(1)}, A^{(2)}, \ldots, A^{(n)}\} = \Lin \{A^{(1)}, A^{(2)}, \ldots, A^{(n)}\} = L2
	\end{equation*}
	Torej morajo biti vsi vektorji, ki so linearne kombinacije vektorjev L1 tudi linearne kombinacije vektorjev L2 in obratno. Zado"s"ca
	\begin{equation*}
	A^{(1)} = \alpha^{-1} (\alpha A^{(1)})
	\end{equation*}
	To velja, ker $\alpha \neq 0$. Torej lahko vsak vektor, ki je zapisan z linearno kombinacijo L1 pretvorimo v linearno kombinacijo vektorjev L2 in obratno, zato se ohranja slika preslikave $A$ in posledi"cno tudi rang.
	
	\item Dokazati moramo
	\begin{equation*}
	\Lin \{A^{(1)} + \alpha A^{(2)}, A^{(2)}, \ldots, A^{(n)}\} = \Lin \{A^{(2)}, A^{(2)}, \ldots, A^{(n)} \}
	\end{equation*}
	Velja podoben razmislek kot pri S2, zato zado"s"ca
	\begin{equation*}
	A^{(1)} = \left(A^{(1)} + \alpha A^{(2)}\right) + (- \alpha) A^{(2)}
	\end{equation*}
\end{enumerate}
\dashuline{V1, V2, V3 ohranjajo $\ker A$}
\begin{equation*}
x \in \ker A \iff Ax = 0 \iff A_{i} x = 0, \quad i = 1, \ldots, m
\end{equation*}
\begin{enumerate}[V1)]
	\item o"citno iz zgornje enakosti
	\item \begin{equation*}
	A \to 
	\begin{bmatrix}
	\alpha A_{(1)} \\
	A_{(2)} \\
	\vdots \\
	A_{(m)}
	\end{bmatrix}
	\end{equation*}
	Pokazati moramo, da $\alpha A_{(1)} x = 0 \quad \forall x \in \OO^n$. Ker $\alpha \neq 0$, velja
	\begin{equation*}
	\alpha A_{(1)} x = 0 \iff A_{(1)} x = 0
	\end{equation*}
	Torej operacija ohranja $\ker A$.
	
	\item
	\begin{equation*}
	A \to 
	\begin{bmatrix}
	A_{(1)} +  \alpha A_{(2)} \\
	A_{(2)} \\
	\vdots \\
	A_{(m)}
	\end{bmatrix}
	\end{equation*}
	Pokazati moramo
	\begin{equation*}
	\begin{Bmatrix}
	(A_{(1)} + \alpha A_{(2)}) x = 0 \\
	A_{(2)} x = 0 \\
	\cdots \\
	A_{(n)} x = 0
	\end{Bmatrix}
	\iff
	\begin{Bmatrix}
	A_{(1)}x = 0 \\
	A_{(2)} x = 0 \\
	\cdots \\
	A_{(n)} x = 0
	\end{Bmatrix}
	\end{equation*}
	\begin{itemize}
		\item[($\Leftarrow$)] o"citno
		\item [($\Rightarrow$)] vemo $(A_{(1)} + \alpha A_{(2)}) x = 0$. Dokazati moramo, da je $A_{(1)} x = 0$.
		\begin{gather*}
			(A_{(1)} + \alpha A_{(2)}) x = 0 \\
			A_{(1)} x + \alpha \underbrace{A_{(2)} x}_{0} = 0 \\
			\Rightarrow A_{(1)} x = 0
		\end{gather*}
	\end{itemize}
\end{enumerate}
Ker se ohranja jedro, se ohranja rang ($= n - \dim (\ker A)$).

\textsc{Trditev:} Naj bo $A \in \OO^{m \times n}$. Z uporabo operacij S1 - S3, V1 - V3 lahko postopoma pridemo iz matrike $A$, do matrike $A_0$ oblike
\begin{equation*}
A_0 = \begin{bmatrix}
1 &  &  &  \\
 & \ddots &  & \\
 &  & 1 & 
\end{bmatrix} \in \OO^{m \times n}
\end{equation*}
Kjer je $\rang A$ "stevilo stolpcev z eno enico. Natan"cna shema postopka je v zvezku.

\textsc{Primer}
\begin{equation*}
A = \begin{bmatrix}
1 & 2 & 3 & 4 \\
3 & 2 & 1 & 0 \\
2 & 3 & 4 & 5
\end{bmatrix} \sim
\begin{bmatrix}
1 & 2 & 3 & 4 \\
0 & -4 & -8 & -12 \\
0 & -1 & -2 & -3
\end{bmatrix} \sim
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 2 & 3 \\
0 & 0 & 0 & 0
\end{bmatrix} \sim
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix} = A_0
\end{equation*}
Torej je $\rang A = \rang A_0 = 2$.

\textsc{Posledica} Rang matrike je enak rangu njene \emph{transponiranke}.
\begin{equation*}
\rang A = \rang A^\intercal
\end{equation*}
"Ce je $A = [a_{ij}] \in \OO^{m \times n}$, transponiranko $B = A^\intercal$, t.j.: $B = [b_{ij}] \in \OO^{n \times m}$ tvorimo na nasleden na"cin:
\begin{equation*}
b_{ij} = a_{ji} \quad \forall i, j
\end{equation*}
\textsc{Dokaz:} O"citno je, da "ce na matriki $A$ izvedemo operaijo S$i$, se bo ta pretvorila v V$i$ na matriki $A^\intercal$. Analogno za operacije V$i$.

\textsc{Posledica:} Najve"cje "stevilo linearno neodvisnih stolpcev matrike je enako najve"cjemu "stevilu njenih linearno neodvisnih vrstic.

\subsubsection{Sistemi linearnih ena"cb}
Naj bo
\begin{gather*}
a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n = b_1 \\
a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n = b_2 \\
\vdots \\
a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n = b_m \\
\end{gather*}
sistem linearnih ena"cb. Zapi"semo lahko $A \in \OO^{m \times n}, \quad A = [a_{ij}]$. Za $b$ lahko zapi"semo
\begin{equation*}
b \in \OO^m, \quad b = \begin{bmatrix}
b_1 \\
\vdots \\
b_m
\end{bmatrix}
\end{equation*}
Podobno lahko $x$ zapi"semo kot
\begin{equation*}
x = \begin{bmatrix}
x_1 \\
\vdots \\
x_n
\end{bmatrix} \in \OO^n
\end{equation*}
I"s"cemo $x \in \OO^n$, da bo veljalo
\begin{equation*}
Ax = b
\end{equation*}
"Ce gledamo na $A$ kot na preslikavo, velja $A \in \LL(\OO^n, \OO^m)$. Naj bo $\mathcal{R}$ mno"zica vseh re"sitev sistema $Ax = b$, t.j.:
\begin{equation*}
\mathcal{R} = \{x \in \OO^n: Ax = b\}
\end{equation*}
$[A|b] \in \OO^{m \times (n + 1)}$ je \emph{raz"sirjena matrika} sistema $Ax = b$. 

"Ce je $b = 0$, potem imamo \emph{homogen sistem} $Ax = 0$, potem
\begin{equation*}
\mathcal{R} = \ker A
\end{equation*}

"Ce je $b \neq 0$. imamo \emph{nehomogen sistem} $Ax = b$. Sistem je \emph{protisloven}, kadar je $\mathcal{R} = \varnothing$, sicer pa je \emph{neprotisloven}. Naj bo sistem $Ax = b$ neprotisloven in $w$ ena od re"sitev ($w \in \mathcal{R}$). Pravimo, da je $w$ \emph{partikularna re"sitev}.

Naj bo 
\begin{gather*}
A w = b, \quad x \in \mathcal{R} \Rightarrow Ax = b \\
\Rightarrow A(x - w) = \underbrace{Ax}_{b} - \underbrace{Aw}_{b} = 0 \Rightarrow x - w \in \ker A \\
\Rightarrow x \in w + \ker A
\end{gather*}
Torej velja $\mathcal{R} \subseteq w + \ker A$.

Naj bo $x \in w + \ker A$. Potem je $x = w + y, y \in \ker A$.
\begin{equation*}
\Rightarrow Ax = A(w + y) = \underbrace{Aw}_{b} + \underbrace{Ay}_{0} = b \\
\Rightarrow x \in \mathcal{R}
\end{equation*}
Torej velja $w + \ker A \subset \mathcal{R}$

Iz $(1) \& (2)$ sledi
\begin{equation*}
\mathcal{R} = w + \ker A
\end{equation*}
\textsc{Trditev:} "Ce je $w$ partikularna re"sitev sistema $Ax = b$, je 
\begin{equation*}
\mathcal{R} = w + \ker A
\end{equation*}
\textsc{Izrek} (Kronecker, Capelli): $\mathcal{R} \neq \varnothing$ natanko takrat, kadar je
\begin{equation*}
\rang [A | b] = \rang[A]
\end{equation*}
\textsc{Dokaz:} $\mathcal{R} \neq \varnothing \iff b \in \im A$ (ker $Ax = b$ pomeni, da je $b \in \im A$)
\begin{gather*}
\begin{aligned}
\im [A | b] &= \Lin \{A^{(1)}, \ldots, A^{(n)}, b\} \\
\im A = &= \Lin \{A^{(1)}, \ldots, A^{(n)}\}
\end{aligned}\\
\dim (\im [A | b]) = \dim (\im A) \iff \im A = \im [A | b] \iff b \in \im A
\end{gather*}
ker $\im A \subseteq \im [A | b]$, preveriti je treba "se $\im [A | b] \subseteq \im A \iff b \im A$.
%
\subsubsection{Gaussov algoritem za re"sevanje sistema}
Dovoljene operacije so V1 - V3 in S1. S1 je dovoljena operacija samo za prvih $n$ stolpcev in paziti je treba, da med seboj ustrezno zamenjamo spremenljivke. S temi operacijami bo mno"zica re"sitev ostala ista.

Skica poteka je v zvezku. Na za"cetku leta sem opozoril, da tu ne bo skic. "Ce si pri"cakoval spremembo toplo priporo"cam da zniza"s pri"cakovanja. Ko pridemo do kon"cne matrike, katere skica nje je v prej omenjenem zvezku, velja
\begin{gather*}
Ax = b \iff\\
1 x_{i1} + 0 x_{i2} + \cdots + 0 x_{ir} + \ast x_{ir+1} + \cdots + \ast x_{in} = \ast \\
0 x_{i1} + 1 x_{i2} + \cdots + 0 x_{ir} + \ast x_{ir + 1} + \cdots + \ast x_{in} = \ast \\
\vdots \\
0 x_{i1} + 0 x_{i2} + \cdots + 1 x_{ir} + \ast x_{ir + 1} + \cdots + \ast x_{in} = \ast \\
0 x_{i1} + 0 x_{i2} + \cdots + 0 x_{ir} + 0 x_{ir + 1} + \cdots + 0 x_{in} = \delta
\end{gather*}
"Ce je $\delta = 1$, je sistem protisloven, "ce pa je $\delta = 0$, ima sistem $n - r$ parametri"cno dru"zino re"sitev. Prametri so
\begin{gather*}
x_{ir+1} = \alpha _1 \\
\vdots \\
x_{in} = \alpha_{n-r}
\end{gather*}
re"sitve ena"cbe pa so
\begin{gather*}
x_{i1} = \ast + \ast \alpha_1 + \cdots + \ast \alpha_{n-r} \\
x_{i2} = \ast + \ast \alpha_1 + \cdots + \ast \alpha_{n-r} \\
\vdots \\
x_{ir} = \ast + \ast \alpha_1 + \cdots + \ast \alpha_{n-r}
\end{gather*}
%
\textsc{Primer:} Obravnavaj sistem linearnih ena"cb:
\begin{align*}
x_1 + 2x_2 + 3x_3 + 4x_4 &= 1\\
5x_1 + 4x_2 + 3x_3 + 2x_4 &= -1 \\
3x_1 + 4x_2 + 5x_3 + 6x_4 &= p
\end{align*}
glede na realen parameter $p$.

\begin{gather*}
\begin{bmatrix}
1 & 2 & 3 & 4 & | & 1 \\
5 & 4 & 3 & 2 & | & -1 \\
3 & 4 & 5 & 6 & | & p
\end{bmatrix} \to
\begin{bmatrix}
1 & 2 & 3 & 4 & | & 1 \\
0 & -6 & -12 & -18 & | & -6 \\
0 & -2 & -4 & -6 & | & p-3
\end{bmatrix} \to
\begin{bmatrix}
1 & 2 & 3 & 4 & | & 1 \\
0 & 1 & 2 & 3 & | & 1 \\
0 & -2 & -4 & -6 & | & p-3
\end{bmatrix} \to \\
\begin{bmatrix}
1 & 2 & 3 & 4 & | & 1 \\
0 & 1 & 2 & 3 & | & 1 \\
0 & 0 & 0 & 0 & | & p - 1
\end{bmatrix} \to
\begin{bmatrix}
1 & 0 & -1 & -2 & | & -1 \\
0 & 1 & 2 & 3 & | & 1 \\
0 & 0 & 0 & 0 & | & p-1
\end{bmatrix}
\end{gather*}
Sistem je neprotisloven natanko takrat, kadar je $p-1 = 0$, torej $p=1$.
\begin{align*}
x_1 - x_3 - 2x_4 &= -1 \\
x_2 + 2x_3 + 3x_4 &= 1 \\
x_3 &= \alpha_1 \\
x_4 &= \alpha_2
\end{align*}
Za $p=1$ torej velja:
\begin{align*}
x_1 &= -1 + \alpha_1 + 2\alpha_2 \\
x_2 &= 1 - 2\alpha_1 - 3\alpha_2 \\
x_3 &= \alpha_1 \\
x_4 &= \alpha_2
\end{align*}
kjer sta $\alpha_1$ in $\alpha_2$ realna parametra.

V resnici re"sujemo sistem $Ax = b$, kjer je $x = \begin{bmatrix}x_1 \\ x_2 \\ x_3 \\ x_4\end{bmatrix}$

Spomnimo se, da za mno"zico re"sitev $R$ velja $R = w + \ker A$, kjer je $w$ partikularna re"sitev. Torej velja
\begin{gather*}
x \in R \iff x = \begin{bmatrix}-1 \\ 1 \\ 0 \\ 0\end{bmatrix}
+ \alpha_1 \begin{bmatrix}1 \\ -2 \\ 1 \\ 0\end{bmatrix}
+ \alpha_2 \begin{bmatrix}2 \\ -3 \\ 0 \\ 1\end{bmatrix}
\\
R = \begin{bmatrix}-1 \\ 1 \\ 0 \\ 0\end{bmatrix}
+ \Lin \left\{
\begin{bmatrix}1 \\ -2 \\ 1 \\ 0\end{bmatrix},
\begin{bmatrix}2 \\ -3 \\ 0 \\ 1\end{bmatrix}
 \right\}
\end{gather*}
$\Rightarrow \begin{bmatrix}1 \\ -2 \\ 1 \\ 0\end{bmatrix}$ in $\begin{bmatrix}2 \\ -3 \\ 0 \\ 1\end{bmatrix}$ tvorita bazo jedra $\ker A$.
%
\subsubsection{Simultano re"sevanje sistemov z isto matriko koeficienotv}
\begin{gather*}
\begin{aligned}
AX^{(1)} &= B^{(1)}\\
AX^{(2)} &= B^{(2)} \\
&\cdots \\
AX^{(p)} &= B^{(p)}
\end{aligned}
\end{gather*}
Zapi"semo lahko
\begin{align*}
X &= \begin{bmatrix}X^{(1)} & \ldots & X^{(p)}\end{bmatrix} \in \OO^{n \times p} \\
B &= \begin{bmatrix}B^{(1)} & \ldots & B^{(p)}\end{bmatrix} \in \OO^{m \times p}
\end{align*}
Torej re"sujemo sistem $AX = B$.

Z Gaussom dobimo $\begin{bmatrix}A & | & B\end{bmatrix} \to \begin{bmatrix}A' & | & B'\end{bmatrix}$.

\textsc{Poseben primer:}

$A \in \OO^{n \times n}$, $A$ obrnljiva ($\Rightarrow \rang A = n$).

$A' = I$.
\begin{align*}
AX = B \iff IX = B' \Rightarrow B' &= X = A^{-1}B \\
B' &= A^{-1}B
\end{align*}
Vzamemo $B = I$, dobimo $B' = A^{-1}$.
\begin{equation*}
\begin{bmatrix}A & | & I\end{bmatrix} \to
\begin{bmatrix}I & | & A^{-1}\end{bmatrix}
\end{equation*}
%
\subsubsection{Sprememba baze}
$V$ v.p. nad $\OO$.

$\mathcal{V} = \{v_1, \ldots, v_n\}$ urejena baza

$\mathcal{V'} = \{v_1', \ldots, v_n'\}$ urejena baza
\begin{gather*}
v_j' = p_{1j} v_1 + p_{2j}v_2 + \cdots + p_{nj}v_n \\
P = \begin{bmatrix}p_{ij}\end{bmatrix} i,j = 1, \ldots, n \quad \in \OO^{n \times n}
\end{gather*}
$P$ je \emph{prehodna matrika} med $\V$ in $\V'$.

Skica, ki naj bi bila v zvezku zelo pomaga pri naslednjem sklepu
\begin{gather*}
P = \Phi_\V (\Phi_V')^{-1} \\
id_V v_j' = v_j' = p_{1j}v_1 + \cdots + p_{nj}v_n
\end{gather*}
%
\textsc{Poseben primer:}

$V = \OO^n$

$\V = \{e_1, e_2, \ldots, e_n\}$ standardna baza

$P$ - prehodna matrika
\begin{gather*}
\Rightarrow v_j' = p_{1j}e_1 + p_{2j}e_2 + \cdots + p_{nj}e_n = \begin{bmatrix}p_{1j} \\ p_{2j} \\ \vdots \\ p_{nj}\end{bmatrix} = P^{(j)} \\
\Rightarrow \V' = \{P^{(1)}, P^{(2)}, \ldots, P^{(n)}\}
\end{gather*}

Naj bo $\A \in \LL (V, U)$ in naj bosta $\V , \V '$ bazi $V$ in $\U, \U'$  bazi $U$. Naj $A \in \OO^{m \times n}$ pripada $\A$ glede na $\V, \U$ in naj $\A' \in \OO^{m \times n}$ pripada $\A$ glede na $\V', \U'$.

$P$ naj bo prehodna matrika med $\V$ in $\V'$, $Q$ pa naj bo prehodna matrika med $\U$ in $\U'$.

$P \in \OO^{n \times n}, \quad Q \in \OO^{m \times m}$

Zanima nas zveza med $A'$ in $A$.

V zvezku na tem mestu stoji (ali pa le"zi, odvisno v kak"sni poziciji bere"s zvezek) en velik diagram, ki komutira. Iz tega diagrama razberemo
\begin{equation*}
A' = Q^{-1}AP
\end{equation*}
%
\textsc{Poseben primer:}

$\A = A$, $\V, \U$ standardni bazi v $V = \OO^n$ in $U = \OO^m$

$\Rightarrow A' = Q^{-1}AP$ je matrika, ki pripada $A$ glede na urejeni bazi $\V' = \{P^{(1)}, \ldots, P^{(n)}\}$ in $\U = \{Q^{(1)}, \ldots, Q^{(m)}\}$
%
\subsubsection{Ekivalentnost matrik}
Naj bosta $A, B \in \OO^{m \times n}$

\textsc{Definicija:} $B$ je \emph{ekvivalentna} $A$ ($B \sim A$), kadar obstajata taki obrnljivi matriki $P, Q$, da velja
\begin{equation*}
B = Q^{-1}AP
\end{equation*}
%
$\sim$ je ekvivalen"cna relacija:
\begin{itemize}
	\item $A \sim A$ (refleksivnost) (za $Q, P$ vzamemo $I$)
	\item $A \sim B \Rightarrow B \sim A$ (simetri"cnost) ($B = Q^{-1}AP \Rightarrow A = \underbrace{QBP^{-1}}_{(Q^{-1})^{-1}B(P^{-1})}$)
	\item $A \sim B \land B \sim C \Rightarrow A \sim C$ (tranzitivnost) (dokaz za DN)
\end{itemize}
%
\textsc{Trditev:} Naj bo $\A \in \LL(V, U)$. Potem obstajata v $V$ in $U$ taki urejeni bazi, da ima matrika, ki pripada $\A$ v teh dveh bazah obliko
\begin{equation*}
A_0 = \begin{bmatrix}
1 & & & &\\
& \ddots && & \\
&& 1 & &\\
&&&&&
\end{bmatrix}
\end{equation*}
kjer je $r = \rang \A$.

\textsc{Dokaz:} I"s"cemo bazi $\{v_1, \ldots, v_n\}$ v $V$ in $\{u_1, \ldots, u_n\}$ v $U$, tako da bo veljalo:
\begin{align*}
\A v_1 &= u_1 \\
\A v_2 &= u_2 \\
&\cdots \\
\A v_r &= u_r \\
\A v_{r+1} &= 0 \\
&\cdots \\
\A v_n &= 0
\end{align*}
V $\im \A$ izberemo bazo $\{u_1, \ldots, u_r\}$. Izberemo "se praslike teh elementov $\{v_1, \ldots, v_r\} \in V$. Velja $\A v_j = u_j$ za $j = 1, \ldots, r$.

Raz"sirimo $\{u_1, \ldots, u_r\}$ do baze $\{u_1, \ldots, u_r, \ldots, u_m\}$ v. p. $U$.

Spomnimo se: $\dim (\ker \A) = n - \dim (\im \A) = n - r$.

Izberemo bazo $\ker \A: \{\underbrace{v_{r+1}, \ldots, v_n}_{n-r \text{ vektorjev}}\}$.

Trdimo, da je $\{v1, \ldots, v_n\}$ baza $V$. Zado"s"ca ugotoviti, da so ti vektorji linearno neodvisni (ker je $\dim V = n$).
\begin{gather*}
\alpha_1 v_1 + \cdots + \alpha_r v_r + \alpha_{r+1} v_{r+1} + \cdots + \alpha_n v_n = 0 \\
\alpha_1 \underbrace{\A v_1}_{u_1} + \cdots + \alpha_r \underbrace{\A v_r}_{u_r} + \alpha_{r+1} \underbrace{\A v_{r+1}}_0 + \cdots + \alpha_n \underbrace{\A v_n}_0 = 0 \tag{*} \\
\alpha_1 u_1 + \cdots + \alpha_r u_r = 0 \Rightarrow \alpha_1 = \cdots = \alpha_r = 0
\end{gather*}
"Ce to vstavimo v (*) dobimo:
\begin{equation*}
\alpha_{r+1} v_{r+1} + \cdots + \alpha_n v_n = 0 \Rightarrow \alpha_{r+1}  = \cdots = \alpha_n = 0
\end{equation*}
Torej so $v_1, \ldots, v_n$ res linearno neodvisni.

\hfill $\square$

\textsc{Posledica:} Vsaka matrika je ekvivalentna matriki oblike $A_0$.

\textsc{Dokaz:} $A$ razumemo kot prelikavo. Matrika, ki pripada $A$ glede na bazi $\{P^{(1)}, \ldots, P^{(n)}\}$ in $\{Q^{(1)}, \ldots, Q^{(m)}\}$, naj bo $A_0$. Ker je $A_0 = Q^{-1} A P$, sta matriki $A$ in $A_0$ ekvivalentni.

\textbf{Opomba:} 
\begin{gather*}
A_0 = Q^{-1}AP \iff AP = Q A_0 \\
AP = [Q^{(1)}, \ldots, Q^{(r)}, 0, \ldots, 0] \\
[AP^{(1)}, \ldots, AP^{(r)}, \ldots AP^{(n)}] = [Q^{(1)}, \ldots, Q^{(r)}, 0, \ldots, 0] \\
\iff AP^{(j)} = Q^{(j)} \text{ za } j = 1, \ldots r \\
AP^{(j)} = 0 \text{ za } j = r+1, \ldots, n
\end{gather*}
%
\textsc{Trditev:} Matriki $A, B \in \OO^{m \times n}$ sta ekvivalentni natanko takrat, kadar velja
\begin{equation*}
\rang A = \rang B
\end{equation*}
\textsc{Dokaz:}
\begin{itemize}
	\item[$(\Rightarrow)$] Naj bosta $A, B$ ekvivalentni. Vemo, da velja
	\begin{equation*}
	B = Q^{-1}AP
	\end{equation*}
	kjer sta $P$ in $Q$ obrnljivi matriki. Torej $B$ pripada preslikavi $A: \OO^n \to \OO^m$ glede na bazi $\{P^{(1)}, \ldots, P^{(n)}\}$ in $\{Q^{(1)}, \ldots, Q^{(m)}\}$. Po neki trditvi velja $\rang B = \rang A$.
	
	\item[$(\Leftarrow)$] Naj velja $\rang A = \rang B = r$. Vemo, da je $A$ ekvivalentna $A_0$. Prav tako je $B$ ekvivalentna $B_0$. Ker $A, B \in \OO^{m \times n}$ imata isti rang, zato je $A_0 = B_0$. Torej velja $A \sim A_0 = B_0 \sim B$. Iz tranzitivnosti sledi $A \sim B$.
\end{itemize}
\hfill $\square$
%
\subsubsection{Podobnost matrik}
Naj bo $\A \in \LL(V), \dim V = n$. In naj bosta $\V, \V'$ urejeni bazi $V$, ter $P$ prehodna matrika. Matrika $A \in \OO^{n \times n}$ naj pripada preslikavi $\A$ glede na bazo $\V$, matrika $A' \in \OO^{m \times n}$ pa naj pripada preslikavi $\A$ glede na bazo $\V'$. Vemo, da je zveza med $A'$ in $A$
\begin{equation*}
A' = P^{-1}AP
\end{equation*}
%
\textsc{Definicija:} Matrika $B \in \OO^{n \times n}$ je \emph{podobna} matriki $A \in \OO^{n \times n}$, kadar obstaja taka obrnljiva matrika $P \in \OO^{n \times n}$, da velja
\begin{equation*}
B = P^{-1}AP
\end{equation*}
Ozna"cimo z $B \mpod A$.

Relacija podobnosti je ekvivalen"cna relacija
\begin{itemize}
	\item refleksivnost: $A \mpod A$, za $P$ vzamemo $I$.
	\item simetri"cnost $B = P^{-1}AP \Rightarrow A = PBP^{-1} = (P^{-1})^{-1}BP^{-1}$
	\item tranzitivnost: $B \mpod B, B \mpod C \Rightarrow A = P^{-1} BP, B = Q^{-1} CQ \Rightarrow A = P^{-1} Q^{-1} CQP = (QP)^{-1} C (QP) \Rightarrow A \mpod C$
\end{itemize}
Vse matrike, ki pripadajo danemu endomorfizmu so med seboj podobne.

\subsubsection{Diagonalne matrike in diagonalizacija}
Naj bo $A \in \OO^{n \times n}, A = [a_{ij}] \quad i, j = 1, \ldots, n$. Pravimo, da je $A$ \emph{diagonalna}, kadar je $a_{ij} = 0$ za vsak $i \neq j$. Oblika $A$:
\begin{equation*}
A = \begin{bmatrix}
a_{11}&&&&& \\
&a_{22}&&&& \\
&&a_{33}&&& \\
&&& a_{44}&& \\
&&&& \ddots & \\
&&&&& a_{nn}
\end{bmatrix}
\end{equation*}
\textbf{Zapis:} $A = \diag (a_{11}, a_{22}, \ldots, a_{nn}) = \diag (b_1, b_2, \ldots, b_n)$.

Velja:
\begin{gather*}
\diag (a_1, \ldots, a_n) + \diag (b_1, \ldots, b_n) = \diag (a_1 + b_1, \ldots, a_n + b_n) \\
\diag (a_1, \ldots, a_n)  \diag (b_1, \ldots, b_n) = \diag(a_1 b_1, \ldots, a_n b_n)
\end{gather*}
%
\textsc{Definicija:} Endomorfizem $\A \in \LL(V)$ se da \emph{diagonalizirati}, kadar obstaja taka baza $\V \in V$, da je matrika $A$, ki pripada $\A$ v tej bazi, diagonalna.

Naj preslikavi $\A$ v bazi $\V$ pripada matrika $A = \diag (a_1, \ldots, a_n)$ in naj bo $\V = \{v_1, \ldots, v_n\}$. Takrat velja:
\begin{equation*}
\A v_j = 0 v_1 + 0 v_2 + \cdots + a_j v_j + \cdots + 0 v_n = a_j v_j \qquad j = 1, \ldots, n
\end{equation*}
Torej velja:
\begin{equation*}
\A v_j = a_j v_j \quad \forall j
\end{equation*}
%
\textsc{Definicija:} Vektor $x \in V \setminus \{0\}$ imenujemo \emph{lastni vektor} endomorfizma $\A \in \LL(V)$, kadar velja
\begin{equation*}
\A x = \lambda x
\end{equation*}
za kak"sen $\lambda \in \OO$. Velja, da je $\lambda$ enoli"cno dolo"cen z $\A$ in lastnim vektorjem $x$. $\lambda$ imenujemo \emph{lastna vrednost} endomorfizma $\A$, ki pripada danemu vektorju $x$.

\textsc{Dokaz} enoli"cnosti $\lambda$:

Naj velja $\A x = \lambda x$ in $\A x = \mu x$. Potem velja
\begin{equation*}
\lambda x = \mu x \Rightarrow (\lambda - \mu) \underbrace{x}_{\neq 0} = 0 \Rightarrow \lambda - \mu = 0 \Rightarrow \lambda = \mu
\end{equation*}

Naj bo $\A \in \LL(V), \lambda \in \OO$. $\lambda$ je lastna vrednost end. $\A$, kadar obstaja kak"sen lasten vektor $x$, da je 
\begin{equation*}
\A x = \lambda x
\end{equation*}
%
Poglejmo si mno"zico $\{x \in V: \A x = \lambda x\}$ za fiksiran $\lambda \in \OO$.
\begin{equation*}
\{x \in V: \A x = \lambda x\} = \{x \in V: (\A - \lambda \I) x = 0\} = \ker (\A - \lambda \I)
\end{equation*}
kjer je $\I = id_V$.

$\ker (\A - \lambda \I)$ se imenuje \emph{lastni podprostor} end. $\A$, ki pripada l. vrednosti $\lambda$.

"Ce je $x$ lastni vektor (za $\A$ in $\lambda$), potem je $\alpha x$ lastni vektor, "ce je $\alpha \neq 0$.

V $\ker (\A - \lambda \I)$ so vsi lastni vektorji end. $\A$, ki pripadajo l. vrednosti $\lambda$, poleg njih pa "se vektor 0.

\textsc{Trditev:} Endomorfizem $\A$ se da diagonalizirati natanko takrat, kadar obstaja baza v. p. $V$, sestavljena iz lastnih vektorjev end. $\A$. Pripadajo"ca diagonalna matrika ima na diagonali lastne vrednosti $\A$.

\textsc{Dokaz:} Naj se da $\A$ diagonaliziragi v $\{v_1, \ldots, v_n\} \Rightarrow \A v_j = a_j v_j \quad \forall j$. 

$A = \diag (a_1, \ldots, a_n)$

$v_j$ je l. vektor $\forall j (v_j \neq 0)$. $a_j$ je lastna vrednost za $\A$ in $v_j$.

Obratno: $\{v_1, \ldots, v_n\}$ je baza iz l. vektorjev $Av_j = \lambda_j v_j$. $A = \diag (\lambda_1, \ldots, \lambda_n)$

\textsc{Trditev:} Naj bodo $\lambda_1, \ldots, \lambda_h$ razli"cne lastne vrednosti endomorfizma $\A \in \LL(V)$ in $x_1, \ldots, x_h$ pripadajo"ci vektorji. Potem so $x_1, \ldots x_h$ linearno neodvisni.

\textsc{Dokaz:} Recimo, da so $x_1, \ldots, x_h$ linearno odvisni. Izberemo najmanj"si $j > 1$, tako da je $x_j = \alpha_1 x_1 + \cdots + a_{j-1} x_{j-1}$. Preslikamo z $\A$:
\begin{gather*}
\A x_j = \alpha_1 \A x_1 + \cdots + \alpha_{j-1} \A x_{j-1} \\
\Rightarrow \lambda_j x_j = \alpha_1 \lambda_1 x_1 + \cdots + a_{j-1} \lambda_{j-1} x_{j-1} \\
\end{gather*}
Velja tudi:
\begin{equation*}
\lambda_j x_j = \lambda_j \alpha_1 x_1 + \cdots + \lambda_j \alpha_{j-1}x_{j-1}
\end{equation*}
"Ce te ena"cbi od"stejemo dobimo:
\begin{gather*}
(\alpha_1 \lambda_1 - \lambda_j \alpha_1) x_1 + \cdots + (\alpha_{j-1} \lambda_{j-1} - \lambda_j \alpha_{j-1})x_{j-1} = 0 \\
\alpha_1 (\lambda_1 - \lambda_j) x_1 + \alpha_2 (\lambda_2 - \lambda_j) x_2 + \cdots + \alpha_{j-1} (\lambda_{j-1} - \lambda_j) x_{j-1} = 0
\end{gather*}
Zaradi izbire $j$ (minimalnost) so $x_1, \ldots, x_{j-1}$ linearno neodvisni.
\begin{gather*}
\Rightarrow \alpha_1 \underbrace{(\lambda_1 - \lambda_j)}_{\neq 0} = \cdots = \alpha_{j-1} \underbrace{(\lambda_{j-1} - \lambda_j)}_{\neq 0} = 0 \\
\Rightarrow \alpha_1 = \cdots = \alpha_{j-1} = 0
\end{gather*}
Torej je $x_j = 0$ $\rightarrow \leftarrow$.

Zato so $x_1, \ldots, x_h$ linearno neodvisni.

\textsc{Posledica:} "Ce ima endomorfizem $\A \in \LL(V)$ $n$ razli"cnih lastnih vrednosti, kjer je $n = \dim (V)$, potem se da $\A$ diagonalizirati.

\textsc{Dokaz:} $\lambda_1, \ldots, \lambda_n$ razli"cne lastne vrednosti.
\begin{gather*}
\A x_j = \lambda_j x_j, \qquad j = 1, \ldots, n \\
x_j \neq 0 \quad \forall j
\end{gather*}
$\Rightarrow \{x_1, \ldots, x_n\}$ je baza $V$ sestavljena iz lastnih vektorjev. Zato se da $\A$ diagonalizirati.

Naj bo $A \in \OO^{n \times n} = \LL(\OO^{n})$. $A$ se da diagonalizirati, kadar je $A$ podobna diagonalni matriki:
\begin{equation*}
\exists P \in \OO^{n \times n} \text{ obrnljiva}: P^{-1}AP = D = \diag(d_1, \ldots, d_n)
\end{equation*}
Velja:
\begin{gather*}
AP = PD \\
\Rightarrow AP^{(j)} = PD^{(j)} \quad j = 1, \ldots, n \\
PD^{(j)} = P(d_j e_j) = d_j Pe_j \\
\Rightarrow AP^{(j)} = d_jP^{(j)} \quad \forall j
\end{gather*}
$\Rightarrow P^{(1)}, \ldots, P^{(n)}$ so lastni vektorji matrike $A$. $d_1, \ldots, d_n$ so pripadajo"ce lastne vrednosti.
%
\subsubsection{Iskanje lastnih vrednosti in lastnih vektorjev}
Naj bo $\A \in \LL(V), \dim V = n$

$Ax = \lambda x \iff x \in \ker (\A - \lambda \I)$

$\lambda$ je lastna vrednost endomorfizma $\A \iff \ker (\A - \lambda \I) \neq \{0\} \iff \A - \lambda \I$ ni bijekcija (nima inverza) $\iff \rang(\A - \lambda \I) < n$.

\textsc{Primer:} $n = 3, \quad \OO = \RR$. Kdaj je $\rang(A - \lambda I) < 3$?

$\iff$ stolpci oziroma vrstice matrike $A - \lambda I$ so linearno odvisni \\
$\iff$ me"sani produkt vseh vrstic matrike $A - \lambda I$ je enak 0 \\
$\iff \det(A - \lambda I) = 0$
\begin{equation*}
\det(A - \lambda I) = 
\begin{vmatrix}
a_{11} - \lambda & a_{12} & a_{13} \\
a_{21} & a_{22} - \lambda & a_{23} \\
a_{31} & a_{32} & a_{33} - \lambda
\end{vmatrix}
= a_0 + a_1 \lambda + a_2 \lambda^2 + a_3 \lambda^3
\end{equation*}
Hitro lahko razberemo, da je $a_3 = -1$. Torej je $\lambda$ lastna vrednost $A \iff \Delta_A(\lambda) = 0$, kjer je
\begin{equation*}
\Delta_A(\lambda) = a_0 + a_1 \lambda + a_2 \lambda^2 - \lambda^3
\end{equation*}
Ni"cle polinoma $\Delta_A(\lambda)$, $\alpha_1, \alpha_2, \alpha_3 \in \RR$, so lastne vrednosti matrike $A$. Pravimo, da je $\Delta_A(\lambda)$ \emph{karakteristi"cni polinom} matrike $A$.
%
\subsubsection{Determinante}
Naj bosta $V$ in $U$ vektorska porstora nad $\OO$. Definiramo
\begin{equation*}
V^n = \underbrace{V \times V \times \cdots \times V}_n
\end{equation*}
Velja
\begin{align*}
(v_1, v_2, \ldots, v_n) &\in V^n \\
\forall j \quad v_j &\in V
\end{align*}
%
\textsc{Definicija:} $F: V^n \to U$ je \emph{$n$-linearna}, kadar so za vsak $(v_1, \ldots, v_n) \in V^n$ preslikave $F_j: V \to U \quad (j = 1, \ldots n)$, definirane s predpisom
\begin{equation*}
F_j(x) = F(v_1, \ldots, v_{j-1}, x, v_{j+1}, \ldots, v_n)
\end{equation*}
linearne.

"Ce je $n = 2$ pravimo da je preslikava \emph{bilinearna}, "ce je $n=3$ pa pravimo, da je preslikava \emph{trilinearna}.

\textsc{Primeri:}
\begin{enumerate}[(1)]
	\item Skalarni produkt na $\RR^3$
	\begin{gather*}
	F: \RR^3 \times \RR^3 \to \RR \\
	V = \RR^3, \quad U= \RR \\
	F(\vec{a}, \vec{b}) = \vec{a} \cdot \vec{b}
	\end{gather*}
	$F$ je bilinearna preslikava
	\begin{equation*}
	F_1(\vec{x}) = F(\vec{x}, \vec{b}) = \vec{x} \cdot \vec{b} \\
	F_1(\vec{x} + \vec{y}) = (\vec{x} + \vec{y}) \cdot \vec{b} = \vec{x} \vec{b} + \vec{y} \vec{b} = F_1(\vec{x}) + F_1(\vec{y})
	\end{equation*}
	Torej je $F_1$ aditivna. Podobno hitro se preveri, da je tudi homogena. Zato je $F_1$ linearna. Podobno velja tudi za $F_2$, zato je $F$ bilinearna.
	
	\item Vektroski produkt v $\RR^3$
	\begin{gather*}
	F: \RR^3 \times \RR^3 \to \RR^3 \\
	V = \RR^3, \quad U = \RR^3 \\
	F(\vec{a}, \vec{b}) = \vec{a} \times \vec{b}
	\end{gather*}
	Podbno kot v prvem primeru preverimo linearnost preslikav $F_1$ in $F_2$ in opazimo, da je tudi v tem primeru $F$ bilinearna.
	
	\item Me"sani produkt v $\RR^3$
	\begin{gather*}
	F: \RR^3 \times \RR^3 \times \RR^3 \to \RR \\
	V = \RR^3, \quad U = \RR \\
	F(\vec{a}, \vec{b}, \vec{c}) = (\vec{a} \times \vec{b}) \cdot \vec{c}
	\end{gather*}
	Podobno kot v prvih dveh primerih preverimo linearnost preslikav $F_1, F_2$ in $F_3$ in opazimo, da je $F$ trilinearna preslikava.
\end{enumerate}
\textsc{Primer ra"cunanja:} Naj bo $F: V^2 \to U$ bilinearna
\begin{multline*}
F(u, w) = F(\alpha_1 v_1 + \cdots + \alpha_n v_n, \beta_1 w_1 + \cdots + \beta_n w_n) = \\
= \alpha_1 F(v_1, w) + \alpha_2 F(v_2, w) + \cdots + \alpha_n F(v_n, w) = \\
= \alpha_1 F(v_1, \beta_1 w_1 + \cdots + \beta_n w_n) + \cdots = \\
= \alpha_1 (\beta_1 F(v_1, w_1) + \beta_2 F(v_1, w_2) + \cdots + \beta_n (v_1, w_n)) = \\
= \sum_{1 \leq i, j \leq n} \alpha_i \beta_j F(v_1, w_j)
\end{multline*}
%
\textsc{Definicija:} $F: V^n \to U$ je \emph{antisimetri"cna}, kadar velja za vsak $(v_1, \ldots, v_n) \in V^n$ enakost
\begin{equation*}
F(v_1, \ldots, v_j, \ldots, v_k, \ldots, v_n) = - F(v_1, \ldots, v_k, \ldots, v_j, \ldots, v_n)
\end{equation*}
\textsc{Primera:} Vektorski in me"sani produkt.

Naj bo $\OO$ obseg, kjer $1 + 1 \neq 0$. Potem je $F(v_1, \ldots, v_n) = 0$, "ce je $v_j = v_k$ za kak"sen $j \neq k$.
\begin{gather*}
F(v_1, \ldots, v_n) = - F(v_1, \ldots, v_n) \Rightarrow \\
2F(v_1, \ldots, v_n) = 0 \Rightarrow F(v_1, \ldots, v_n) = 0
\end{gather*}

Naj bo $\pi \in S_n, \pi = \begin{pmatrix}
1 & 2 & \ldots & n \\
i_1 & i_2 & \ldots & i_n
\end{pmatrix}$ Potem velja:
\begin{equation*}
F(v_{i_1}, v_{i_2}, \ldots, v_{i_n}) = s(\pi) F(v_1, \ldots, v_n)
\end{equation*}
Kjer je
\begin{equation*}
s(\pi) = \begin{cases}
1 & \text{$\pi$ soda}\\
-1 & \text{$\pi$ liha}
\end{cases}
\end{equation*}
%
Determinanta reda 3 je trilinearna in antisimetri"cna. "Ce "zelimo to posplo"siti, i"s"cemo $n$-linearen antisimetri"cen funkcional. 

Naj bo $V = \OO^n, U = \OO$ in naj bo $F: V^n \to U$, to je $F: (\OO^n)^n \to \OO$. Poglejmo si $(\OO^n)^n$.
\begin{equation*}
(\OO^n)^n = \underbrace{\OO^n \times \OO^n \times \cdots \times \OO^n}_n
\end{equation*}
Torej lahko matriko $\OO^{n \times n}$ identificiramo z $(\OO^n)^n$, to je $(A^{(1)}, \ldots, A^{(n)}) \equiv A$.
 
Torej i"s"cemo $n$-linearen antisimetri"cen funkcional $F: \OO^{n \times n} \equiv (\OO^n)^n \to \OO$. Recimo, da je $F$ tak funkcional.
\begin{multline*}
F(A) = F(A^{(1)}, A^{(2)}, \ldots, A^{(n)}) = \\
= F(\underbrace{a_{11} e_1 + a_{21} e_2 + \cdots + a_{n1}e_n}_{A^{(1)}}, \underbrace{a_{12} e_1  + \cdots + a_{n2} e_n}_{A^{(2)}}, \ldots, \underbrace{a_{1n} e_1  + \cdots + a_{nn} e_n}_{A^{(n)}}) = \\
= \sum_{1 \leq i_1, i_2, \ldots, i_n \leq n} F(a_{{i_1}1} e_{i_1}, a_{{i_2}2} e_2, \ldots, a_{{i_n}n}e_n) = \\
= \sum_{1 \leq i_1, i_2, \ldots, i_n \leq n} a_{i_11} a_{i_22} \cdots a_{i_nn} F(e_{i_1}, e_{i_2}, \ldots, e_{i_n}) = \\
= \sum_{\pi \in S_n} s(\pi) a_{i_11} a_{i_22} \cdots a_{i_nn} F(e_1, \ldots, e_n)
\end{multline*}
kjer je $\pi = \begin{pmatrix}
1 & 2 & \ldots & n \\
i_1 & i_2 & \ldots & i_n
\end{pmatrix}$. $i_1, i_2, \ldots, i_n$ so razli"cni. Ostali sumandi so $s_0 = 0$ zaradi antisimetri"cnosti.

Determinatno definiramo kot
\begin{equation*}
\det A = \sum_{\pi \in S_n} s(\pi) a_{i_11} a_{i_22} \cdots a_{i_nn}
\end{equation*}
kjer je $\pi = \begin{pmatrix}
1 & 2 & \ldots & n \\
i_1 & i_2 & \ldots & i_n
\end{pmatrix}$. Torej je
\begin{align*}
\det: \OO^{n \times n} &\to \OO \\
A &\mapsto \det A
\end{align*}
Ugotovili smo, da "ce je $F: \OO^{n \times n} \to \OO$ $n$-linearen antisimetri"cen funkcional, potem velja
\begin{equation*}
F(A) = F(I) \cdot \det A
\end{equation*}
\textsc{Trditev:} $\det: \OO^{n \times n} \to \OO$ je $n$-linearen antisimetri"cen funkcional.

\textsc{Dokaz:}
\begin{itemize}
	\item $n$-linearnost (na prvem faktorju, ker zaradi antisimetri"cnosti velja na ostalih)
	
	\textbf{Homogenost:}
	\begin{multline*}
		\det(\alpha A^{(1)}, A^{(2)}, \ldots, A^{(n)}) = \\
		= \sum_{\pi \in S_n} s(\pi) (\alpha a_{i_11}) a_{i_22} \cdots a_{i_nn} = \\
		= \alpha \det A
	\end{multline*}
	\textbf{Aditivnost:}
	\begin{multline*}
		\det (B^{(1)} + C^{(1)}, A^{(2)}, \ldots, A^{(n)}) = \\
		= \sum_{\pi \in S_n} s(\pi) (b_{i_11} + c_{i_11}) a_{i_22} \cdots a_{i_nn} = \\
		= \sum_{\pi \in S_n} s(\pi) b_{i_11} a_{i_22} \cdots a_{i_nn} + \sum_{\pi \in S_n} c_{i_11} a_{i_22} \cdots a_{i_nn} = \\
		= \det(B^{(1)}, A^{(2)}, \ldots, A^{(n)}) + \det (C^{(1)}, A^{(2)}, \ldots, A^{(n)})
	\end{multline*}
	
	\item antisimetri"cnost:
	\begin{multline*}
		\det(A^{(2)}, A^{(1)}, A^{(3)}, \ldots, A^{(n)}) = \\
		= \sum_{\pi \in S_n} a_{i_12} a_{i_21} a_{i_33} \cdots a_{i_nn} = \\
		= \sum_{\pi \in S_n} a_{i_21} a_{i_12} a_{i_33} \cdots a_{i_nn} = \\
		= \sum_{\rho \in S_n} s(\rho) a_{i_21} a_{i_12} a_{i_33} \cdots a_{i_nn} = -\det A
	\end{multline*}
	kjer je $\rho = \begin{pmatrix}
	1 & 2 & 3 & \ldots & n \\
	i_2 & i_1 & i_3 & \ldots & i_n
	\end{pmatrix}$, torej je $s(\rho) = - s(\pi)$.
\end{itemize}
Torej so $n$-linearni antisimetri"cni funkcionali $F: \OO^{n \times n} \to \OO$ to"cno vsi funkcionali oblike $F(A) = \alpha \det(A)$, kjer je $\alpha \in \OO$. Pri tem je $\alpha = F(I)$.

\subsubsection{Lastnosti determinante}
\begin{enumerate}


	\item Velja $\det (A^\intercal)  = \det A$. 
	
	\textsc{Dokaz:} Naj bo $B = A^\intercal, B = [b_{ij}]$ kjer je $b_{ij} = a_{ji}, \quad \forall i, j$.
	\begin{gather*}
	\det B = \sum_{\pi \in S_n} s(\pi) b_{i_11} b_{i_22} \cdots b_{i_nn} = \\
	= \sum_{\pi \in S_n} s(\pi) a_{1i_1} a_{2i_2} \cdots a_{ni_n} = \sum _{\rho \in S_n} s(\rho) a_{j_11} a_{j_22} \cdots a_{j_nn}
	\end{gather*}
	Ustrezna permutacija $\rho = \begin{pmatrix}
	1 & 2 & \ldots &n \\
	j_1 & j_2 & \ldots &j_n
	\end{pmatrix}$ je enaka $\rho = \begin{pmatrix}
	i_1 & i_2 & \ldots & i_n \\
	1 & 2 & 2 & \ldots & n
	\end{pmatrix} = \pi^{-1}$. Ker velja $s(\rho) = s(\pi)$, dobimo
	\begin{equation*}
	\det B = \det A
	\end{equation*}
	Torej je
	\begin{equation*}
	\det A^\intercal = \det A
	\end{equation*}
	%
	\item \textbf{Determinanta in operacije za ra"cunanje ranga}
	\begin{itemize}
		\item Pri medsebojni zamenjavi dveh stolpcev (vrstic), se determinanta pomno"zi z  $-1$ zaradi antisimetri"cnosti. Za vrstice velja $\det A^\intercal = \det A$.
	
		\item Pri mno"zenju stolpca (vrstice) z $\alpha$, se determinanta pomno"zi z $\alpha$, ker je $n$-linearen funkcional.
		
		\item "Ce stolpcu pri"stejemo ve"ckratnik kakega drugega stolpca (analogno za vrstice), se determinanta ohrani.
		\begin{gather*}
			\det(A^{(1)} + \alpha A^{(2)}, A^{(2)}, \ldots, A^{(n)}) = \\
			= \det(A^{(1)}, A^{(2)}, \ldots, A^{(n)}) + \alpha \det(A^{(2)}, A^{(2)}, \ldots, A^{(n)}) = \det A
		\end{gather*}
	\end{itemize}
	Iz definicije determinante sledi, da "ce ima $A$ kak stolpec (ali vrstico) enak 0, je $\det A = 0$.
	
	"Ce stolpcu pri"stejemo linearno kombinacijo drugih stolpcev, se determinanta ohrani.
	
	Recimo, da so stolpci matrike $A$ linearno odvisni. Npr $A^{(1)} = \alpha_2 A^{(2)} + \cdots + \alpha_n A^{(n)}$. $A^{(1)}$ pri"stejemo $(-\alpha_2)A^{(2)} + \cdots + (-\alpha_n)A^{(n)}$ in dobimo stolpec 0. Ker se determinanta ohrani, je $\det A = 0$.
	
	\textsc{Trditev:} "Ce matrika ni obrnljiva je $\det A = 0$ ($\det A \neq 0 \Rightarrow \exists A^{-1}$).
	
	\textsc{Dokaz:} $A$ ni obrnljiva $\Rightarrow \rang A < n \Rightarrow$ stolpci matrike $A$ so linearno odvisni $\Rightarrow \det A = 0$.
	
	Naj bo $A$ zgornje ali spdnje trikotna matrika. Potem velja
	\begin{equation*}
	\det A = \prod_{i=1}^{n} a_{ii}
	\end{equation*}
	To hitro vidimo, "ce si nari"semo shemo matrike, kar je v zvezku.
	
	"Ce je v zgornje trikotni matriki $a_{ii} \neq 0$ za $i = 1, \ldots n$, je ta matrika obrnljiva.
	
	\item \textbf{Multiplikativnost}
	Za $A, B \in \OO^{n \times n}$ velja
	\begin{equation*}
	\det (A B) = \det A \cdot \det B
	\end{equation*}
	\textsc{Dokaz:} Naj bo $F: \OO^{n \times n} \to \OO$ in $A \in \OO^{n \times n}$. $F$ definiramo kot
	\begin{equation*}
	F(X) = \det(AX)
	\end{equation*}
	$F$ je $n$-linearna antisimetri"cna preslikava. Velja
	\begin{equation*}
	F(X) = F(X^{(1)}, \ldots, X^{(n)}) = \det(A X^{(1)}, \ldots, AX^{(n)})
	\end{equation*}
	Vemo, da velja
	\begin{align*}
	F(X) &= F(I) \det X \\
	F(I) &= \det (AI) = \det A
	\end{align*}
	Od tod sledi
	\begin{equation*}
	\det (AX) = (\det A) (\det X)
	\end{equation*}
	\hfill $\square$
	
	Recimo, da je $A$ obrnljiva. Potem velja
	\begin{equation*}
	A A^{-1} = I \Rightarrow \underbrace{\det (A A^{-1})}_{(\det A) (\det A^{-1})} = \det I = 1 \Rightarrow \det(A^{-1}) = (\det A)^{-1}
	\end{equation*}
	Torej velja, da "ce je $A$ obrnljiva, je $\det A \neq 0$. Vemo "ze, da velja obratno, torej velja
	\begin{equation*}
	\exists A^{-1} \iff \det A \neq 0
	\end{equation*}
	
	\item \textbf{Razvoj determinante}
	
	\textsc{Definicija:} Naj bo $A \in \OO^{n \times n}$ in $n > 0$.. $A_{ij} \in \OO^{(n-1) \times (n-1)}$ dobimo tako, da iz $A$ odstranimo $i$-to vrstico in $j$-ti stolpec. Pravimo, da je $A_{ij}$ \emph{podmatrika}.
	
	\emph{Poddeterminanto} matrike $A$ definiramo kot
	\begin{equation*}
	(-1)^{i + j} \det A_{ij} \equiv \widetilde{a_{ij}}
	\end{equation*}
	
	Matrika $\widetilde{A} = [\widetilde{a_{ij}}]\ i,j = 1, \ldots, n \in \OO^{n \times n}$ je \emph{prirejenka} matrike $A$.
	
	Poglejmo si naslednjo determinanto
	\begin{multline*}
	\det \begin{bmatrix}A^{(1)} & \ldots & A^{(n-1)} & e_n\end{bmatrix} = \\
	\sum_{\pi \in S_n} s(\pi) a_{i_11} a_{i_22} \cdots a_{i_{n-1}n-1} = \sum_{\rho \in S_{n-1}} s(\rho) a_{i_11} \cdots a_{i_{n-1}n-1} = \det A_{nn}
	\end{multline*}
	Kjer je $\pi = \begin{pmatrix}
	1 & 2 & \cdots & n-1 & n \\
	i_1 & i_2 & \cdots & i_{n-1} & n
	\end{pmatrix}$, ker je druga"ce $a_{i_nn} = 0$. $\rho$ definiramo kot $\rho = \begin{pmatrix}
	1 & \cdots & n-1 \\
	i_1 & \cdots & i_{n-1}
	\end{pmatrix} \in S_{n-1}$. Velja $s(\pi) = s(\rho)$.

	Poglejmo si "se
	\begin{equation*}
	\det \begin{bmatrix}A^{(1)} & \ldots & e_i & \ldots & A^{(n)}\end{bmatrix}
	\end{equation*}
	Kjer je $e_i$ na $j$-tem mestu. "Zeleli bi si matriko preoblikovati v tak"sno obliko, kot smo jo obravnavali v prej"snjem primeru. "Zal ne moremo kar zamenjati $i$-te in $n$-te vrstice, ter $j$-tega in $n$-tega stolpca, ker bi s tem spremenili vsrtni red stolpcev in vrstic v matriki. Lahko pa postopoma premikamo stolpec/vrstico, tako da delamo neke vrste transpozicije (skica v zvezku). S tem pridelamo podmatriko $A_{ij}$, ki ima v zadnjem stolpcu enotski vektor $e_n$. Zaradi antisimteri"cnosti se nam spremeni predznak determinante. Torej dobimo
	\begin{multline*}
	\det \begin{bmatrix}A^{(1)} & \ldots & e_i & \ldots & A^{(n)}\end{bmatrix} = \\
	= (-1)^{(n - i) + (n-j)} \det A_{ij} = (-1)^{i + j} \det A_{ij} = \widetilde{a_{ij}}
	\end{multline*}
	
	Poglejmo si, \emph{razvoj} determinante po $j$-tem stolpcu.
	\begin{multline*}
	\det A = \det \begin{bmatrix}
	A^{(1)} &
	\cdots &
	\underbrace{a_{1j} e_1 + a_{2j} e_2 + \cdots + a^{nj} e_n}_{A^{(j)}} &
	\cdots &
	A^{(n)}
	\end{bmatrix} = \\
	= \sum_{i = 1}^n a_{ij} \det \begin{bmatrix}A^{(1)} & \cdots & e_i & \cdots & A^{(n)}\end{bmatrix} = \sum_{i = 1}^{n} a_{ij} \widetilde{a_{ij}}
	\end{multline*}
	Torej velja
	\begin{equation*}
	\sum_{i=1}^{n} a_{ij} \widetilde{a_{ij}} = \det A \quad \forall j
	\end{equation*}
	"Ce zamenjamo $A$ z $A^\intercal$, dobimo podobno formulo za razvoj determinante po $i$-it vrstici
	\begin{equation*}
	\sum_{j=1}^{n} a_{ij} \widetilde{a_{ij}} = \det A \quad \forall i
	\end{equation*}
	%
	Za $j \neq k$ velja
	\begin{equation*}
	\sum_{i = 1}^{n} a_{ij} \widetilde{a_{ik}} = \det \begin{bmatrix}
	A^{(1)} & \cdots & \underbrace{A^{(j)}}_{\text{$j$-to mesto}} & \cdots & \underbrace{A^{(j)}}_{\text{$k$-to mesto}} & \cdots & A^{(n)}
	\end{bmatrix} = 0
	\end{equation*}
	Torej velja
	\begin{equation*}
	\sum_{i = 1}^{n} a_{ij} \widetilde{a_{ik}} = 0 \quad \forall j, k: j \neq k
	\end{equation*}
	"Ce $A$ zamenjamo z $A^\intercal$ dobimo podobno za vrstice
	\begin{equation*}
	\sum_{j=1}^n a_{ij} \widetilde{a_{kj}} = 0 \quad \forall i, k: i \neq k
	\end{equation*}
	%
	Te formule lahko zdru"zimo v naslednje
	\begin{equation*}
	A \widetilde{A}^\intercal =
	\begin{bmatrix}
	\det A	&	0	 &	\cdots	&	0 \\
	0		  &\det A&              & \vdots \\
	\vdots &   		 &  \ddots  &  0 \\
	0         &\cdots&   0        & \det A
	\end{bmatrix} = (\det A) I
	\end{equation*}
	Podobno lahko zapi"semo
	\begin{equation*}
	\widetilde{A}^\intercal A = (\det A) I
	\end{equation*}
	To dvoje lahko zdru"zimo v
	\begin{equation*}
	\widetilde{A}^\intercal A = A \widetilde{A}^\intercal = (\det A) I
	\end{equation*}
	
	\textsc{Posledica:} "Ce je $\det A \neq 0$ velja
	\begin{equation*}
	A^{-1} = (\det A) ^{-1} \widetilde{A}^\intercal
	\end{equation*}
	
	\textsc{Determinante nekatirh matrik posebne oblike:}
	\begin{equation*}
	\det \begin{bmatrix}
	A & \varhexstar \\
	0 & B
	\end{bmatrix} = (\det A) (\det B)
	\end{equation*}
	kjer sta $A$ in $B$ kvadratni matriki.
	
	\textsc{Osnovna ideja dokaza}:
	
	Delamo indukcijo glede na velikost matirke $A$ in razvoj determinante po prvem stolpcu.

	Za $k = 1$ velja:
	\begin{equation*}
	\det \begin{bmatrix}
	a_{11} & \varhexstar \\
	0 & B
	\end{bmatrix} = a_{11} \det B
	\end{equation*}
	Za $k = 2$ veja:
	\begin{multline*}
	\det \begin{bmatrix}
	a_{11} & a_{12} & \\
	a_{21} & a_{22} & \\
	   		  &            & B
	\end{bmatrix} = a_{11} (a_{22} \det B) - a_{21} (a_{12} \det B) = \\
	= \det B (a_{11} a_{22} - a_{12} a_{21}) = (\det A) (\det B)
	\end{multline*}
	Sorodno naredimo za $k \rightsquigarrow k + 1$.
	
	"Ce imamo blo"cno zgornje trikotno matriko velja
	\begin{equation*}
	\det \begin{bmatrix}
	A_1 & & &\\
	& A_2 & &\\
	& & \ddots & \\
	&&& A_k
	\end{bmatrix} = (\det A_1) (\det A_2) \cdots (\det A_k)
	\end{equation*}
	Podobno velja tudi za blo"cno spodnje trikotne.
	
	Blo"cno diagonalno matriko lahko zapi"semo kot
	\begin{equation*}
	\begin{bmatrix}
	A_1 & & &\\
	& A_2 & &\\
	& & \ddots & \\
	&&& A_k
	\end{bmatrix} = \diag (A_1, A_2, \ldots, A_k)
	\end{equation*}
	in velja
	\begin{equation*}
	\det (\diag (A_1, \ldots, A_k)) = (\det A_1) \cdots (\det A_k)
	\end{equation*}
\end{enumerate}

\subsubsection{Determinanta endomorfizma}
Naj bo preslikava $\A \in \LL(V)$ in naj bosta $A, A'$ matriki, ki pripada preslikavi $\A$. Ker sta si $A$ in $A'$ podobni, velja
\begin{align*}
A' &= P^{-1} AP \\
P A' &= AP
\end{align*}
Od tod sledi
\begin{gather*}
\det (PA') = \det (AP) \\
(\det P) (\det A') = (\det A) (\det P) \\
\exists P^{-1} \Rightarrow \det P \neq 0 \\
\Rightarrow \det A' = \det A
\end{gather*}
Podobni matriki imata enako determinanto. Zato je smiselno definirati
\begin{equation*}
\det \A = \det A
\end{equation*}
(neodvisno od izbire baze v $V$)

\textsc{Cramerjeva formula:}

Naj bo $Ax = b, A \in \OO^{n \times n}$ sistem ena"cb innaj bo $\det A \neq 0$. Vemo, da je $x = \begin{bmatrix}x_1 \\ \vdots \\ x_n\end{bmatrix}$. Definiramo
\begin{equation*}
A_j = \begin{bmatrix}A^{(1)}, \ldots, A^{(j-1)}, b, A^{(j+1)}, \ldots, A^{(n)}\end{bmatrix}
\end{equation*}
Cramerjeva formula pravi, da velja
\begin{equation*}
x_j = \dfrac{\det A_j}{\det A}, \quad j = 1, \ldots, n
\end{equation*}
\textsc{Dokaz:}

Ker $\det A \neq 0$, obstja $A^{-1}$. Vemo, da velja
\begin{equation*}
A^{-1} = \dfrac{1}{\det A} \widetilde{A}^\intercal
\end{equation*}
Zato velja
\begin{gather*}
Ax = b \Rightarrow x = A^{-1} b = \dfrac{1}{\det A} \widetilde{A}^\intercal b \Rightarrow \\
\Rightarrow x_j = \dfrac{1}{\det A} \left( \widetilde{A}^\intercal b \right)_j = \dfrac{1}{\det A} \underbrace{(\widetilde{a_{1j}} b_1 + \widetilde{a_{2j}} b_2 + \cdots + \widetilde{a_{nj}} b_n)}_\text{razvoj determinante po $j$-tem stolpcu} = \\
\dfrac{1}{\det A} \det \begin{bmatrix}
A^{(1)}, \ldots, b, \ldots, A^{(n)}
\end{bmatrix}
\end{gather*}

\subsubsection{Karakteristi"cni polinom in minimalni polinom}
Naj bo $A \in \OO^{n \times n}$. Potem je
\begin{equation*}
\Delta_A(\delta) = \det (A - \lambda I)
\end{equation*}
\emph{karakteristi"cni polinom} matrike $A$ (glej $A \in \RR^3$). $\Delta_A(\delta)$ je polinom $n$-te stopnje s koeficienti v $\OO$.
\begin{gather*}
\Delta_A(\delta) = \det \begin{bmatrix}
a_{11} - \lambda & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} - \lambda & \cdots & a_{2n} \\
\vdots & \vdots & & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn} - \lambda
\end{bmatrix} = \\
= (a_{11} - \lambda) (a_{22} - \lambda) \cdots (a_{nn} - \lambda) + \underbrace{p(\lambda)}_\text{st $\leq n-2$} = a_0 + a_1 \lambda + \cdots + a_{n-1} \lambda^{n-1} + a_n \lambda^n
\end{gather*}
Iz tega zapisa lahko hitro razberemo, da veljajo naslednje ena"cbe
\begin{align*}
a_n &= (-1)^n \\
a_{n-1} &= (-1)^{n-1} \overbrace{(a_{nn} + a_{22} + \cdots + a_{nn})}^{sl A} \\
a_0 &= \det A
\end{align*}
\textsc{Izrek:} Naj bo $A \in \OO^{n \times n}$ in $\Delta_A(\delta)$ njen karakteristi"cni polinom. Potem je $\alpha \in \OO$ lastna vrednost matrike $A$ natanko takrat, kadar je
\begin{equation*}
\Delta_A(\alpha) = 0
\end{equation*}
\textsc{Dokaz:} $\alpha \in \OO:$

$\alpha$ je lastna vrednost $A \iff A- \alpha I$ ni obrnljiva $\iff \det (A - \alpha I) = 0 \iff \Delta_A(\alpha) = 0$

\hfill $\square$

Za lastne vektorje re"sujemo homogen sistem $(A - \alpha I)x = 0$.

Naj bo preslikava $\A \in \LL(V)$ in naj ji pripadata matriki $A, A'$. Vemo $A' = P^{-1} AP$. Velja
\begin{multline*}
\Delta_{A'} = \det (A' - \lambda I) = \\
= \det (P^{-1} AP - \lambda I) = \det (P^{-1}(A - \lambda I)P) = \\
= \underbrace{(\det (P^{-1}))}_{(\det P)^{-1}} \det (A - \lambda I) (\det P) = \\
= \det (A - \lambda I) = \Delta_A
\end{multline*}
Torej velja
\begin{equation*}
\Delta_{A'}(\lambda) = \Delta_A(\lambda)
\end{equation*}
Zato je smiselno definirati
\begin{equation*}
\Delta_{\A}(\lambda) = \Delta_A(\lambda)
\end{equation*}
Torej je $\alpha$ lastna vrednost endomorfizma $\A$ natanko takrat, ko je $\Delta_{\A}(\alpha) = 0$.

\textsc{Polinom z matri"cnimi koeficienti}

Naj bo
\begin{equation*}
p(\lambda) = A_0 + A_1 \lambda + \cdots + A_k \lambda^k, \quad A_j \in \OO^{n \times n}
\end{equation*}
To lahko zapi"semo v matriko kot
\begin{equation*}
p(\lambda) = \begin{bmatrix}
p_{11}(\lambda) & \cdots & \cdots \\
\vdots & & \vdots \\
\cdots & \cdots & p_{nn} (\lambda)
\end{bmatrix} = [p_{ij}(\lambda)], \quad i, j = 1, \ldots, n
\end{equation*}
kjer je $p_{ij}(\lambda)$ polinom s koeficienti v $\OO$ in stopnja $p_{ij}(\lambda) \leq k$.

Naj bo $B \in \OO^{n \times n}$. Potem je
\begin{equation*}
p(B) = A_0 + A_1 B + A_2 B^2 + \cdots + A_k B^k
\end{equation*}
in $B$ je ni"cla polinoma $p(\lambda)$, "ce je $p(B) = 0$.

Naj bo
\begin{equation*}
q(\lambda) = a_0 + a_1 \lambda + \cdots + a_k \lambda^k
\end{equation*}
in $a_i \in \OO, \quad i = 0, 1, \ldots, k$. Naj bo $B \in \OO^{n \times n}$. Potem je
\begin{equation*}
q(B) = a_0 I + a_1 B + a_2 B^2 + \cdots + a_k B^k
\end{equation*}
$B$ je ni"cla polinoma $q(\lambda)$, "ce je $q(B) = 0$.

\textsc{Izrek} (Cayley, Hamilton): Kvadratna matrika je ni"cla svojega karakteristi"cnega polinoma.

\textsc{Dokaz:}
\begin{gather*}
(A - \lambda I) \widetilde{(A - \lambda I)}^\intercal = (\det (A - \lambda I)) I \\
\widetilde{(A - \lambda I)}^\intercal = [p_{ij}(\lambda)] \quad i, j = 1, \ldots, n \\
= B_0 + B_1 \lambda + \cdots + B_{n-1} \lambda^{n-1} \\
\Rightarrow (A - \lambda I) (B_0 + B_1 \lambda + \cdots + B_{n-1} \lambda^{n-1}) = \\
= \Delta_A(\lambda) I = (a_0 + a_1 \lambda + \cdots + a_n \lambda^{n}) I
\end{gather*}
Zmno"zimo in uredimo po potencah $\lambda$, nato izena"cimo keoficiente:
\begin{align*}
AB_0 &= a_0 I \\
A B_1 - B_0 &= a_1 I  && \cdot A\\
A B_2 - B_1 &= a_2 I  && \cdot A^2 \\
\vdots \\
A B_{n-1} - B_{n-2} &= a_{n-1} I && \cdot A^{n-1}\\
- B_{n-1} &= a_n I && \cdot A^n
\end{align*}
"Ce te ena"cbe "se"stejemo, dobimo
\begin{gather*}
0 = \underbrace{a_0 I + a_1 A + a_2 A^2 + \cdots + a_n A^n}_{\Delta_A(A)} \\
\Rightarrow \Delta_A(A) = 0
\end{gather*}
%
Naj bo $A \in \OO^{n \times n}$. Ozna"cimo
\begin{equation*}
P = \{p(\lambda): p(A) = 0\}
\end{equation*}
in velja $\Delta(\lambda) \in P$.

\textsc{Definicija:} \emph{Minimalni polinom} matrike $A$: 
\begin{equation*}
m_A (\lambda) \in P
\end{equation*}
Vodilni koeficient $m_A (\lambda)$ je 1 in velja
\begin{equation*}
\st m_A (\lambda) \leq \st p(\lambda), \quad p \in P \setminus \{0\}
\end{equation*}
\subsubsection*{Lastnosti:}
\begin{enumerate}[(1)]
	\item $m_A(\lambda) | \Delta_A(\lambda) \quad $ ($\exists q(\lambda): \Delta_A(\lambda) = q(\lambda) \cdot m_A(\lambda)$)
	
	Dokaz:
	\begin{gather*}
	\Delta_A(\lambda) = q(\lambda)m_A (\lambda) + o(\lambda) \\
	\st o(\lambda) < \st m_A(\lambda)
	\end{gather*}
	$\lambda$ zamenjamo z $A$ in dobimo
	\begin{equation*}
	\underbrace{\Delta_A(A)}_0 = q(A) \underbrace{m_A(A)}_0 + o(A)
	\end{equation*}
	Od tod sledi
	\begin{align*}
	&\Rightarrow o(A) = 0 \\
	& \Rightarrow o(\lambda) = 0 \quad \text{druga"ce protislovje z def.\,$m_A(\lambda)$} \\
	& \Rightarrow \Delta_A(\lambda) = q(\lambda) m_A(\lambda)
	\end{align*}
	
	\item $\alpha \in \OO: m_A(\alpha) = 0 \iff \Delta_A(\alpha) = 0$
	
	Dokaz:
	\begin{itemize}
	\item[$(\Rightarrow)$] Uporabimo (1).
	\item[$(\Leftarrow)$] $\Delta_A(\alpha) = 0 \Rightarrow \alpha$ je lastna vrednost $A$, zato obstaja $x \in \OO^n, x \neq 0$, ki je lasten vektor matrike $A$, to je, $Ax = \alpha x$. Torej velja
	\begin{gather*}
	m_A(\lambda) = q(\lambda)(\lambda - \alpha) + m_A (\alpha) \\
	\lambda \leftrightarrow A \\
	\underbrace{m_A(A)}_0 = q(A) (A - \alpha I) + m_A(\alpha)I \qquad | \cdot x \\
	\Rightarrow 0 = q(A) \underbrace{(A - \alpha I)x}_{Ax - \alpha x = 0} + m_A(\alpha)x \\
	\Rightarrow m_A(\alpha)x = 0 \Rightarrow m_A(\alpha) = 0
	\end{gather*}
	\hfill $\square$
	\end{itemize}
\end{enumerate}

Poglejmo si obseg kompleksni "stevil $\OO = \CC$.
\begin{equation*}
\Delta_A(\lambda) = (-1)^n (\lambda - \lambda_i)^{n_1} \cdots (\lambda - \lambda_k)^{n_k}
\end{equation*}
$\lambda_1, \ldots, \lambda_k$ so razli"cne ni"cle $\Delta_A(\lambda)$ in so edine lastne vrednosti matrike $A$. $n_j$ je \emph{algebrajska kratnost} lastne vrednost $\lambda_j$. Zapi"semo lahko
\begin{equation*}
m_A(\lambda) = (\lambda - \lambda_1)^{m_1} \cdots (\lambda - \lambda_k)^{m_k}
\end{equation*}
in velja $1 \leq m_j \leq n_j \quad \forall j$.

\textsc{Primer:}
\begin{gather*}
A = \begin{bmatrix}
0 & -1 \\
1 & 0
\end{bmatrix}  \\
\Delta_A(\lambda) = \det (A - \lambda I) = \det \begin{bmatrix}
-\lambda & -1 \\
-1 & - \lambda
 \end{bmatrix} = \lambda^2 + 1 = (\lambda - i) (\lambda + i)
\end{gather*}
Torej sta $i$ in $-i$ kompleksni lastni vrednosti matrike $A$.

\textsc{Trditev:} Podobni matriki imata isti minimalni polinom.

\textsc{Dokaz:} 
\begin{gather*}
B = P^{-1} AP \\
B^2 = (P^{-1}AP)(P^{-1}AP) = P^{-1} A^2 P \\
B^j = \underbrace{(P^{-1}AP) \cdots (P^{-1}AP)}_j = P^{-1}A^jP \\
p(\lambda) = a_0 + a_1 \lambda + \cdots + a_k \lambda^k \\
p(B) = a_0 I + a_1 B + \cdots + a_k B^k = P^{-1} (a_0 I + a_1 A + \cdots + a_k A^k) P = P^{-1}p(A)P \\
\Rightarrow p(B) = P^{-1}p(A)P \\
\Rightarrow p(B) = 0 \iff p(A) = 0 \\
\Rightarrow m_B(\lambda) = m_A(\lambda)
\end{gather*}
Zato definiramo minimalni polinom endomirfizma $\A$ s predpisom
\begin{equation*}
m_\A (\lambda) = m_A(\lambda)
\end{equation*}
kjer $A$ pripada $\A$ v katerikoli bazi.

Velja 
\begin{align*}
m_\A (\A) &= 0 \\
m_\A (\lambda) &= a_0 + a_1 \lambda + \cdots + \lambda^k \\
m_\A (\A) &= a_0 id_V + a_1 \A + \cdots + \A^k = 0
\end{align*}

\subsubsection{Invariantni podprostori}
$\A \in \LL(V)$, vektorski podprostor $U \subseteq V$ je \emph{invarianten} za $\A$, kadar velja
\begin{equation*}
x \in U \Rightarrow \A x \in U
\end{equation*}

$\lambda$ - lastna vrednost $\A$\\
$\ker(\A - \lambda I)$ - lastni podprostor endomorfizma $\A$ \\
\dashuline{$\ker(\A - \lambda I)$ je invarianten za $\A$}
\begin{gather*}
x \in \ker (\A - \lambda I) \Rightarrow (\A - \lambda I) (\A x) = \\
= (\A^2 - \lambda \A) x = \A \underbrace{(\A - \lambda I)x}_0 = 0 \\
\Rightarrow \A x \in \ker(\A - \lambda I)
\end{gather*}
%
Naj bo $U$ invarianten za $\A$. Potem lahko definiramo preslikavo
\begin{align*}
&\A_U : U \to U \\
&\A_U x = \A x \quad \forall x \in U
\end{align*}
$\A_U$ je zo"zitev $\A$ na $U$ in $\A_U \in \LL(U)$.

Naj bo $\A \in \LL(V)$ Potem je
\begin{equation*}
V = V_1 \oplus V_2 \oplus \cdots \oplus V_k
\end{equation*}
kjer je $V_j$ invarianten za $\A$ za vse $j = 1, \ldots, k$. Ozna"cimo
\begin{equation*}
\A_j := \A_{V_j} \in \LL(V_j)
\end{equation*}
To zapi"semo v obliki
\begin{equation*}
\A = \A_1 \oplus \A_2 \oplus \cdots \oplus \A_k
\end{equation*}
%
Naj bodo $\B_1, \B_2, \ldots, \B_k$ urejene baze $V_1, V_2, \ldots, V_k$ in $A_j$ matrika, ki pripada endomorfizmu $\A_j$ v bazi $\B_j$. Potem je 
\begin{equation*}
\B = \B_1 \cup \B_2 \cup \cdots \cup \B_k
\end{equation*}
urejena baza prostora $V$, ker $\B_i \cap \B_j = \varnothing$ za vsak $i \neq j$.

Naj bo $A$ matirka, ki pripada endomorfizmu $\A$ v bazi $\B$. Velja
\begin{equation*}
A = \begin{bmatrix}
A_1 & & & \\
& A_2 & & \\
& & \ddots & \\
& & & A_k
\end{bmatrix} = \diag(A_1, A_2, \ldots, A_k)
\end{equation*}
Ker dokaz vsebuje veliko skica in je relativno o"citen, obstaja samo v zvezku.

Naj bo $V$ kompleksen kon"cno razse"zen vektorski prostor.
\begin{gather*}
\A \in \LL(V) \quad (\OO \in \CC) \\
\Delta_\A (\lambda) = (-1)^n (\lambda - \lambda_1)^{n_1} \cdots (\lambda - \lambda_k)^{n_k} \\
m_\A (\lambda) = (\lambda - \lambda_1)^{m_1} \cdots (\lambda - \lambda_k)^{m_k}
\end{gather*}
$\lambda_1, \ldots, \lambda_k$ so razli"cne lastne vrednosti $\A$ in velja $1 \leq m_j \leq n_j$ za vsak $j$.
\begin{equation*}
W_j = \ker(\A - \lambda_j I)^{m_j} \quad j = 1, \ldots, k
\end{equation*}
$W_j$ je \emph{korenski podprostor} endomorfizma $\A$ (pripada lastni vrednost $\lambda_j$).

\textsc{Izrek:} Korenski podprostori $W_j, j = 1, \ldots, k$ so invariantni za $\A$, poleg tega pa velja
\begin{equation*}
V = W_1 \oplus \cdots \oplus W_k
\end{equation*}
\textsc{Dokaz:} \dashuline{invariantnost}
\begin{gather*}
x \in W_j \Rightarrow (\A - \lambda_j I)^{m_j} \A x = \A \underbrace{(\A - \lambda_jI)^{m_j}}_0 x = 0 \\
\Rightarrow \A x \in W_j
\end{gather*}
Naj bo 
\begin{equation*}
p_j (\lambda) = \prod_{\stackrel{i = 1}{i \neq j}}^{k} (\lambda - \lambda_i)^{m_i}
\end{equation*}
$p_1(\lambda), p_2(\lambda), \ldots, p_k(\lambda)$ so tuji, ker nimajo nobene skupne ni"cle. Potem obstajajo taki polinomi $q_1(\lambda), q_2(\lambda), \ldots, q_k(\lambda)$, da velja
\begin{equation*}
p_1(\lambda) q_1(\lambda) + p_2(\lambda)q_2(\lambda) + \cdots + p_k(\lambda)q_k(\lambda) = 1
\end{equation*}
Torej velja
\begin{equation*}
\sum_{i =1}^{k}p_i(\A)q_i(\A) = \I \quad (\I = id_V)
\end{equation*}
\begin{equation*}
x \in V \Rightarrow x = \I x = \sum_{i = 1}^{k}\underbrace{p_i(\A)q_i(\A)x}_{x_i} = \sum_{i=1}^k x_i
\end{equation*}
Trdimo, da je $x_i \in W_i$ (od tod sledi $V = W_1 + \cdots + W_k$).
\begin{gather*}
x_i \in \ker(\A - \lambda_i \I)^{m_i} \quad ? \\
(\A - \lambda_i I)^{m_i} x_i = 0 \quad ? \\
m_\A (\lambda) = p_i(\lambda) ( \lambda - \lambda_i)^{m_i} \\
\underbrace{(\A - \lambda_i \I)^{m_i} p_i(\A)}_{m_\A(\A) = 0} q_i(\A) x = 0
\end{gather*}
\dashuline{$V = W_1 \oplus \cdots \oplus W_k$} \quad ,,direktnost''
\begin{gather*}
x \in V \\
\begin{aligned}
x &= x_1 + x_2 + \cdots + x_k, \quad x_i \in W_i \forall i \quad \text{(vemo)} \\
x &= x_1' + x_2' + \cdots + x_k' \quad x_i \in W_i \forall i
\end{aligned} \\
\Rightarrow x_i = x_i' \forall i \quad ? \\
\underbrace{(x_1 - x_1')}_{\in W_1} + \cdots + (\underbrace{x_k - x_k'})_{\in W_k} = 0 \\
y_i = x_i - x_i' \in W_i \quad \forall i \\
y_1 + y_2 + \cdots + y_k = 0 \\
\Rightarrow y_i = 0 \quad \forall i \quad ? \\
y_i \in W_i \Rightarrow (\A - \lambda_i I)^{m_i}y_i =0 \\
p_j(\lambda) = \prod_{\stackrel{i = 1}{i \neq j}} (\lambda - \lambda_i)^{m_i} \\
j \neq i \Rightarrow p_j(\lambda) \text{ vsebuje faktor $(\lambda - \lambda_i)^{m_i}$} \\
\Rightarrow p_j(\A)y_i = 0 \quad \forall i \neq j \\
y_1 + y_2 + \cdots + y_k = 0 \\
\Rightarrow p_j(\A)(y_1 + y_2 + \cdots + y_k) = 0 \\
\Rightarrow p_j(\A) y_j = 0 \\
y_j = \I y_j = \left(\sum_{i = 1}^{k} p_i(\A) q_i(\A) \right) y_j = \sum_{i=1}^k q_i(\A) p_i(\A) y_j = 0 \quad \forall j
\end{gather*}
\hfill $\square$

Torej velja
\begin{gather*}
\A \in \LL(V) \Rightarrow \A = \A_1 \oplus \A_2 \oplus \cdots \oplus \A_k \\
\A_j := \A_{W_j}
\end{gather*}
\textsc{Izrek:} Za zo"zitve $\A_j \in \LL(W_j), j = 1, \ldots, k$, veljajo "se naslednje lastnosti:
\begin{enumerate}[(i)]
	\item $\lambda_j$ je edina lastna vrednost $\A_j$
	\item $\Delta_{\A_j} (\lambda) = (-1)^{n_j} (\lambda - \lambda_j)^{n_j}$
	\item $m_{\A_j} (\lambda) = (\lambda - \lambda_j)^{m_j}$
\end{enumerate}
\textsc{Posledica:}
\begin{equation*}
\dim W_j = n_j \quad \forall j
\end{equation*}
\textsc{Dokaz:}
\begin{gather*}
(\A_j - \lambda_j \I_j)^{m_j} x = (\A - \lambda_j \I)^{m_j} x = 0 \\
\Rightarrow (A_j - \lambda_j \I_j)^{m_j} = 0 \Rightarrow \text{$\A_j$ je ni"cla polinoma $(\lambda - \lambda_j)^{m_j}$}
\end{gather*}
Zato je $m_{\A_j}(\lambda) = (\lambda - \lambda_j)^{t_j}, t_j \leq m_j \quad \forall j$.
\begin{gather*}
\Delta_{\A_j}(\lambda) = (-1)^{s_j} (\lambda - \lambda_j)^{s_j}, s_j \geq t_j \quad \forall j \\
\Delta_{\A}(\lambda) = \Delta_A (\lambda) = \det(A - \lambda I) = \det(A_1 - \lambda I_1) \cdots \det (A_k - \lambda I_k) = \\
= \Delta_{\A_1}(\lambda) \cdots \Delta_{\A_k} (\lambda) \\
(-1)^n (\lambda - \lambda_1)^{n_1} \cdots (\lambda - \lambda_k)^{n_k} = (-1)^{s_1} (\lambda - \lambda_1)^{s_1} \cdots (-1)^{s_k} (\lambda - \lambda_k)^{s_k} \\
\Rightarrow s_i = n_i \quad \forall i \\
m_{\A_j} (\lambda) = (\lambda - \lambda_j)^{t_j} \quad t_j \leq m_j \\
r(\lambda) = (\lambda - \lambda_1)^{t_1} \cdots (\lambda - \lambda_k)^{t_k} \\
\st (r) = t_1 + t_2 + \cdots + t_k \leq m_1 + m_2 + \cdots + m_k = \st (m_\A (\lambda))
\end{gather*}
Ker je $(\A_j - \lambda \I_j)^{t_j} = 0$, velja 
\begin{equation*}
r(\A) = (\A - \lambda_1 \I_1)^{t_1}\cdots (\A - \lambda_k \I_k)^{t_k} = 0
\end{equation*}
Zato je $t_1 + \cdots + t_k = m_1 + \cdots + m_k$. Od tod dobimo $t_j = m_j \quad \forall j$.

\subsubsection{Endomorfizmi z eno samo lastno vrednostjo}
(na $\OO = \CC$)

Naj bo $\A \in \LL(V)$ in $\rho \in \CC$ edina lastna vrednost $\A$. Potem je
\begin{align*}
\Delta_{\A} (\lambda) &= (-1)^n (\lambda - \rho)^n \\
m_\A (\lambda) &= (\lambda - \rho)^r, \quad 1 \leq r \leq n
\end{align*}
Po definiciji minimalnega polinoma velja
\begin{align*}
(\A - \rho \I)^r &= 0 \\
(\A - \rho \I)^{r - 1} & \neq 0
\end{align*}

Definiramo
\begin{equation*}
\B = \A- \rho \I
\end{equation*}
kjer je $\B^r = 0$ in $\B^{r - 1} \neq 0$. Pravimo, da je $\B$ \emph{nilpotent} in $r$ \emph{indeks nilpotentnosti}. Potem velja

\begin{align*}
\Delta_\B (\lambda) &= (-1)^n \lambda^n \\
m_\B (\lambda) &= \lambda^r
\end{align*}
Ozna"cimo
\begin{equation*}
V_i = \ker \B^i, \quad i = 0, 1, \ldots
\end{equation*}
in velja $\B^0 = \I$. "Ce $i \geq r$, potem $V_i = V$. in $V_0 = \{0\}$. Velja
\begin{equation*}
x \in V_i \Rightarrow B^i x = 0 \Rightarrow B^{i+1} x = B(B^i x) = 0 \Rightarrow x \in V_{i + 1}
\end{equation*}
zato velja
\begin{equation*}
\{0\} = V_0 \subseteq V_1 \subseteq \cdots \subseteq V_r = V
\end{equation*}
\textbf{Lastnosti:}
\begin{enumerate}
	\item $x \in V_i \iff Bx \in V_{i-1}$
	
	\textsc{Dokaz:}
	\begin{equation*}
	x \in V_i \iff B^i x = 0 \iff B^{i-1} (Bx) = 0 \iff Bx \in V_{i-1}
	\end{equation*}
	
	\item "Ce so $v_1, \ldots, v_p \in V_i$ linearno neodvisni in velja $\Lin \{v_1, \ldots, v_p\} \cap V_{i-1} = \{0\}$, potem so tudi $\B v_1, \ldots \B v_p \in V_{i-1}$ linearno neodvisni in velja $\Lin \{\B v_1, \ldots, \B v_p\} \cap V_{i-2} = \{0\}$.
	
	\textsc{Dokaz:} 
	\begin{gather*}
		y \in \Lin \{\B v_1, \ldots, \B v_p\} \cap V_{i-2} \\
		y = \alpha_1 \B v_1 + \cdots + \alpha_p \B v_p = \B (\alpha_1 v_1 + \cdots + \alpha_p v_p) \in V_{i-2} \\
		\Rightarrow \alpha_1 v_1 + \cdots + \alpha_p v_p \in V_{i-1} \cap \Lin \{v_1, \ldots, v_p\} \\
		\Rightarrow \alpha_1 = \cdots = \alpha_p = 0 \\
		\Rightarrow y = 0
	\end{gather*}
	iz dokaza sledi tudi $\B v_1, \ldots, \B v_p$ so linearno neodvisni.
\end{enumerate}

Iz skice v zvezku sledi, da je baza vektorskega prostora $W$
\begin{equation*}
\mathcal{W} = \{\B^{q-1}x, \B^{q-2}x, \ldots, x\}
\end{equation*}
$W$ invarianten za $\B$, za kar zado"s"ca opaziti $\B w \subseteq W$.

$J_q$ je matrika, ki pripada zo"zitvi $\B$ na $W$ glede na urejeno bazo $\mathcal{W}$.
\begin{equation*}
J_q  = \begin{bmatrix}
0 & 1 & 0 \\
0 & \ddots & 1 \\
0 & 0 & 0
\end{bmatrix} \in \CC^{q \times q}
\end{equation*}
Pravimo, da je $J_q$ \emph{Jordanova celica}. 

Zapi"semo lahko Jordanovo bazo za $\B$:
\begin{equation*}
\{v_1^{(1)}, v_1^{(2)}, \ldots, v_1^{(r)}, v_2^{(1)}, \ldots, v_2^{(*)}, \ldots, v_{s_1}^{(1)}, \ldots, v_{s_1}^{(*)}\}
\end{equation*}
$J(B)$ je matrika, ki pripada $\B$ v Jodranovi bazi. Je blo"cno diagonalna, bloki pa so Jordanove celice
\begin{equation*}
J(B) = \diag (J_r, \ldots, J_t)
\end{equation*}

\subsubsection*{Splo"sna situacija}
$\A \in \LL(V)$
\begin{align*}
\Delta_\A(\lambda) &= (-1)^n (\lambda - \lambda_)^{n_1} \cdots (\lambda - \lambda_k)^{n_k} \\
m_\A (\lambda) &= (\lambda - \lambda_1)^{m_1} \cdots (\lambda - \lambda_k)^{m_k}
\end{align*}
Vemo
\begin{gather}
V = W_1 \oplus \cdots \oplus W_k \\
W_j = \ker (\A - \lambda_j \I)^{m_j} \\
\end{gather}
Vemo tudi, da je $W_j$ invarianten za $\A$ in $\A_j := \A_{W_j} \in \LL(W_j)$.

Poi"s"cemo Jordanove baze za endomorfizme $\A_j$ in jih razvrstimo po vrsti v bazo v.p.\,$V$. Dobimo Jordanovo bazo endomorfizma $\A$. $J(\A)$ je Jodranova matrika endomorfizma $\A$, ki pripada $\A$ v Jordanovi bazi.
\begin{equation*}
J(\A) = \diag( J(\A_1), \ldots, J(\A_k))
\end{equation*}
Pravimo, da je $n_j$ \emph{algebrajska kratnost} $\lambda_j$.
\begin{equation*}
J(\A_j) = \diag (J_{r_1}(\lambda_j), \ldots, J_{r_p}(\lambda_j))
\end{equation*}
kjer je $r_1 = m_j$ in $p = \dim (\ker (\A_j - \lambda_j \I_j)) = \dim(\ker(\A - \lambda_j \I))$. Pravimo, da je $p$ \emph{geometri"cna kratnost} $\lambda_j$.

Jordanova matrika je do vrstenga reda blokov z isto lastno vrednostjo na diagonali enoli"cno dolo"cena.

\textsc{Matri"cna verzija}

$J(A)$ je Jordanova matrika za $A$ (Jordanova kanoni"cna forma matirke $A$). Jordanova baza za $A$ je
\begin{equation*}
\{P^{(1)}, \ldots, P^{(n)}\}
\end{equation*}
in velja zveza
\begin{equation*}
P^{-1}AP = J(A)
\end{equation*}

\subsubsection{Funkcije matrik}
Vemo, da je $J = \rho I + N$. Zelo hitro se razbere
\begin{align*}
N^j e_1 &= 0 \\
\vdots \\
N^j e_j &= 0 \\
N^j e_{j + 1} &= e_1 \\
\vdots \\
N^j e_r &= e_{r-r}
\end{align*}
Vemo "ze
\begin{gather*}
p(\lambda) = a_0 + a_1 \lambda + \cdots + a_s \lambda^s \\
p(N) = a_0 I + a_1 N + \cdots + a_s N^s \\
p(N) = \begin{bmatrix}
a_0 & a_1 & \cdots & a_s & & \\
& \ddots & \ddots & & \ddots & \\
& & \ddots & \ddots & &  a_s \\
&&& \ddots & \ddots & \\
&&&& \ddots & a_1 \\
&&&&& a_2
\end{bmatrix}
\end{gather*}
,,Taylor'' za polinom $p(\lambda)$:
\begin{equation*}
p(\lambda) = p(\rho) + p'(\rho)(\lambda - \rho) + \dfrac{p''(\rho)}{2} (\lambda - \rho)^2 + \cdots + \dfrac{p^{(j)}(\rho)}{j!} (\lambda - \rho)^j + \cdots
\end{equation*}
Vemo $J - \rho I = N$. Od tod sledi
\begin{equation*}
p(J) = p(\rho)I + p'(\rho) N + \dfrac{p''(\rho)}{2} N^2 + \cdots + \dfrac{p^{(j)}(\rho)}{j!} N^j + \cdots
\end{equation*}
Naj bo $f$ povsod definirina in odvadljiva. Potem velja
\begin{equation*}
f(\lambda) = \sum_{j = 0}^\infty \dfrac{1}{j!} f^{(j)} (\rho) (\lambda - \rho)^j
\end{equation*}
Od tod sledi:
\begin{equation*}
f(J) = \sum_{j = 0}{r-1} \dfrac{1}{j!} f^{(j)} (\rho) N^j
\end{equation*}
Naj bo $A \in \CC^{n \times n}$. Potem je $J(A)$ Jordanova matrika za $A$. Potem je 
\begin{equation*}
J(A) = \diag(J_*, \ldots, J_*)
\end{equation*}
kjer so $J_*$ Jordanove celice. Definiramo
\begin{equation*}
f(J(A)) := \diag(f(J_*), \ldots, f(J_*))
\end{equation*}
$f$ se da razviti v Taylorjevo vrsto v okolici \emph{spektra} matrike $A$.
\begin{equation*}
\spec A = \{\lambda_1, \ldots, \lambda_k\}
\end{equation*}
Vemo $P^{-1}AP = J(A)$. Torej velja $A = PJ(A)P^{-1}$. Za polinome velja
\begin{equation*}
p(A) = P p(J(A)) P^{-1}
\end{equation*}
Definicijo je smiselno raz"siriti na vse funkcije in velja
\begin{equation*}
f(A) := Pf(J(A)) P^{-1}
\end{equation*}

\textsc{Izrek o preslikavi spektra:} Naj bo $A \in \CC^{n \times n}$ in $\spec A = \{ \lambda_1, \ldots, \lambda_k \}$. Potem velja
\begin{equation*}
\spec f(A) = \{ f(\lambda_1), \ldots, f(\lambda_k) \} = f(\spec A)
\end{equation*}

Naj bo
\begin{equation*}
\mathcal{F}(A) = \{ f: D_f \to \CC, \text{ $D_f$ odprta okolica $\spec A$, $f$ analiti"cna} \}
\end{equation*}
Torej $f \in \mathcal{F}(A) \Rightarrow \exists f(A)$. Velja, da  je $(\mathcal{F}(A), +, \cdot)$ za $+, \cdot$ po to"ckah in mno"zenje s skalarji po to"ckah algebra. Definirajmo preslikavo
\begin{align*}
F: & \mathcal{F}(A) \to \CC^{n \times n} \\
& f \mapsto f(A)
\end{align*}
Velja, da je $F$ homomorfizem med algebrama $\mathcal{F}(A)$ in $\CC^{n \times n}$.
\begin{enumerate}
    \item $(f + g)(A) = f(A) + g(A)$
    \item $(f \cdot g)(A) = f(A) \cdot g(A)$
    \item $(\alpha f)(A) = \alpha f(A), \quad \alpha \in \CC$
    \item $1_\CC (A) = I$
    \item $id_\CC(A) = A$
\end{enumerate}
\textsc{Primer:} Na $\sin^2 \lambda + \cos^2 \lambda = 1$ uporabimo $F$ in dobimo
\begin{equation*}
\sin^2 A + \cos^2 A = I
\end{equation*}

Naj bo $f(\lambda) = \frac{1}{\lambda}$ analiti"cna na $\CC \setminus \{ 0 \}$ (punktirana ravnina) in naj bo $A \in \CC^{n \times n}$, ter $0 \notin \spec A (\iff \exists A^{-1})$. Potem velja
\begin{equation*}
\exists f(A) = A^{-1}
\end{equation*}
Vemo da velja
\begin{equation*}
f(\lambda) \cdot id_\CC (\lambda) = \dfrac{1}{\lambda} \lambda = 1 \quad \forall \lambda \in \CC \setminus \{ 0 \}
\end{equation*}
Uporabimo $F$ in dobimo
\begin{equation*}
f(A) \cdot A = I \Rightarrow f(A) = A^{-1}
\end{equation*}

\subsection{Vektorski prostori s skalarnih produktom}
V realnem ali kompleksnem prostoru. Ozna"cimo $\FF$ obseg kompleksnih ali realnih "stevil.

\textsc{Definicija:} \emph{Skalarni produkt} na $V$ je preslikava
\begin{align*}
V \times V &\to \FF \\
(x, y) &\mapsto \langle x, y \rangle
\end{align*}
ki ustreza pogojem
\begin{enumerate}[(i)]
    \item $\langle x + y, z \rangle = \langle x, z \rangle + \langle y, z \rangle$ \hfill $\forall x, y, z \in V$
    \item $\langle \alpha x, y \rangle = \alpha \langle x, y \rangle$ \hfill $\forall \alpha \in \FF, \quad \forall x, y \in V$
    \item $\langle x, y \rangle = \overline{\langle y, x \rangle}$ \hfill $\forall x, y \in V$
    \item $\langle x, x \rangle > 0$ \hfill $\forall x \in V \setminus \{ 0 \}$
\end{enumerate}
\textsc{Primeri}
\begin{enumerate}
    \item Obi"cajni skalarni produkt v $\RR^n$.
    \item Standardni skalarni produkt v $\FF^n$:
    \begin{gather*}
    \begin{aligned}
    x = \begin{bmatrix}
    x_1 \\ \vdots \\ x_n
    \end{bmatrix} \in \FF^n
    &&
    y = \begin{bmatrix}
    y_1 \\ \vdots \\ y_n
    \end{bmatrix} \in \FF^n
    \end{aligned} \\
    \langle x, y \rangle = \sum_{j = 1}^n x_j \overline{y_j}
    \end{gather*}
    
    \item $V = C[a, b] \quad a, b \in \RR, a < b$
    \begin{equation*}
    f \in V: f: [a, b] \to \RR \text{ je zvezna}
    \end{equation*}
    $V$ realen vektorski prostor. $f, g \in V$
    \begin{equation*}
    \langle f, g \rangle = \int_a^b f(t), g(t) dt
    \end{equation*}
    je standardni skalarni produkt na $V$.
\end{enumerate}
%
V v.p.\,s s.p.\, veljata lastnosti
\begin{enumerate}[(i*)]
    \item $\langle x, y + z \rangle = \langle x, y \rangle + \langle x, z \rangle$ \hfill $\forall x, y, z \in V$
    \item $\langle x, \alpha y \rangle = \overline{\alpha} \langle x, y \rangle$ \hfill $\forall \alpha \in \FF \quad \forall x, y \in V$
\end{enumerate}
Dokaz (i*):
\begin{equation*}
\langle x, y + z \rangle = \overline{\langle y + z, x \rangle} = \overline{\langle y, x \rangle} + \overline{\langle z, x \rangle} = \langle x, y \rangle + \langle x, z \rangle
\end{equation*}
Dokaz (ii*):
\begin{equation*}
\langle x, \alpha y \rangle = \overline{\langle \alpha y, x \rangle} = \overline{\alpha \langle y, x \rangle} = \overline{\alpha} \langle x, y \rangle
\end{equation*}
\textsc{Primer:}
\begin{multline*}
\langle \alpha x + \beta y, \gamma u + \delta v \rangle = \\
= \langle\alpha x, \gamma u \rangle + \langle \alpha x, \delta v \rangle + \langle \beta y, \gamma u \rangle + \langle \beta y, \delta v \rangle = \\
= \alpha \overline{\gamma} \langle x, u \rangle + \alpha \overline{\delta} \langle x, v \rangle + \beta \overline{\gamma} \langle y, u \rangle + \beta \overline{\delta} \langle y, v \rangle
\end{multline*}

\textsc{Definicija:} Naj bo $V$ vektorski prostor s skalarnim produktom in $x \in V$. \emph{Norma} dolo"cena s skalarnim produktom je
\begin{equation*}
\| x \| := \sqrt{\langle x, x \rangle}
\end{equation*}
in velja 
\begin{equation*}
d(x, y) = \| x - y \|
\end{equation*}
kjer je $d$ metrika na $V$.

\textsc{Lastnosti:}
\begin{enumerate}[(1)]
    \item $\| x \| > 0$ \hfill $\forall x \in V \setminus \{ 0 \}$
    \item $\| \alpha x \| = |\alpha| \| x \|$ \hfill $\forall \alpha \in \FF$
    \item $\| x + y \| \leq \|x \| + \| y \|$ \hfill $\forall x, y \in V$
\end{enumerate}
Dokaz (2):
\begin{equation*}
\| \alpha x \|^2 = \langle \alpha x , \alpha x \rangle  = \alpha \overline{\alpha} \langle x, x \rangle = |\alpha|^2 \| x \|^2
\end{equation*}

\subsubsection{Koti:}
Naj bosta $x, y \in V \setminus \{ 0 \}$. "Zeleli bi si, da bi veljalo podobno kot v $\RR^3$, torej
\begin{equation*}
\cos \varphi = \dfrac{\langle x, y \rangle}{\| x \| \| y \|}
\end{equation*}
Denimo, da je $\FF = \RR$. Ali velja
\begin{align*}
\left| \dfrac{\langle x, y \rangle}{\| x \| \| y \|} \right| &\leq 1 \\
|\langle x, y \rangle| &\leq \| x \| \| y \|
\end{align*}

\textsc{Izrek} (Caucy, Bunjakovski, Schwarz): V vektorskem prostoru s skalarnim produktom velja neenakost
\begin{equation*}
|\langle x, y \rangle| \leq \| x \| \| y \|
\end{equation*}
pri "cemer velja ena"caj natanko tedaj, kadar sta $x$ in $y$ linearno odvisna.

\textsc{Dokaz:} Vemo, da velja
\begin{multline*}
0 \leq \langle \alpha x + \beta y, \alpha x + \beta y \rangle = \\
= \alpha \overline{\alpha} \langle x, x \rangle + \alpha \overline{\beta} \langle x, y \rangle + \beta \overline{\alpha} \langle y, x \rangle + \beta \overline{\beta} \langle y, y \rangle
\end{multline*}
Za
\begin{align*}
\alpha &= \langle y, y \rangle \geq 0 \\
\beta &= - \langle x, y \rangle
\end{align*}
v zgornji ena"cba enaka
\begin{multline*}
\langle y, y \rangle \langle y, y \rangle \langle x, x \rangle - \langle x, y \rangle \langle y, y \rangle \langle y, x \rangle = \\
= \underbrace{ \langle y, y \rangle}_{\| y \| \geq 0} ( \| x \|^2 \| y \|^2 - |\langle x, y \rangle|^2) \geq 0
\end{multline*}
Torej mora biti $y =0$ ali pa
\begin{equation*}
| \langle x, y \rangle| \leq \| x \| \| y \|
\end{equation*}
"Ce je $y = 0$, potem $\langle x, y \rangle = \langle x, 0 \rangle = 0$ in $\|x \| \|y \| = \| x \| 0 = 0$.

Ena"caj velja $\iff$ ($y = 0$ ali $\alpha x + \beta y = 0$ za $\alpha = \langle y, y \rangle$ in $\beta = -\langle x, y \rangle$) $\iff$ ($y = 0$ ali $x = \frac{\langle x, y \rangle}{\langle y, y \rangle} y$) $\iff$ $x, y$ sta linearno odvisna.

Naj bo $x = \alpha y$. Potem velja
\begin{equation*}
|\langle x, y \rangle| = |\langle \alpha y, y \rangle| = |\alpha \langle y, y \rangle| = |\alpha| \| y \|^2
\end{equation*}
in
\begin{equation*}
\| x \| \| y \| = \| \alpha y \| \| y \| = |\alpha| \| y \| \| y \| = | \alpha | \| y \|^2
\end{equation*}

\textsc{Dokaz} trikotni"ske neenakosti \dashuline{$\| x + y \| \leq \| x \| \| y \|$}
\begin{multline*}
\| x + y \|^2 = \langle x + y, x + y \rangle = \\
= \langle x, x \rangle + \langle x, y \rangle + \langle y, x \rangle + \langle y, y \rangle = \\
= \| x \| ^2 + \langle x, y \rangle + \overline{\langle x, y \rangle} + \| y \| ^2  = \\
= \| x \|^2 + 2 \Re \langle x, y \rangle + \| y \|^2 \leq \\
\leq \| x \|^2 + 2|\langle x, y \rangle| + \| y \|^2 \leq \\
\leq \| x \|^2 + 2 \|x\| \|y\| + \| y \|^2 = (\| x \| + \| y \|)^2
\end{multline*}
\hfill $\square$

\textsc{Definicija:} Naj bo $V$ vektorski prostor s skalarnim produktom in $x, y \in V$.Pravimo, da sta $x$ in $y$ \emph{pravokotna} oziroma \emph{ortogonalna} natanko takrat, kadar velja
\begin{equation*}
\langle x, y \rangle = 0
\end{equation*}
in ozna"cimo $x \perp y$.

\textsc{Lastnosti:}
\begin{itemize}
    \item $x \perp 0$ \hfill $\forall x \in V$
    \item $x \perp y \iff y \perp x$
    \item $x \perp x \iff x = 0$
\end{itemize}

\textsc{Trditev:} "Ce so vektorji $x_1, \ldots, x_k$ paroma parvokotni in razli"cni od 0, potem so linearno neodvisni.

\textsc{Dokaz:}
\begin{equation*}
\alpha_1 x_1 + \cdots + \alpha_k x_k = 0
\end{equation*}
Skalarno pomno"zimo z $x_j$, $j \in \{ 1, \ldots, k\}$.
\begin{gather*}
\langle \alpha_1 x_1 + \cdots + \alpha_k x_k, x_j \rangle = \langle 0, x_j \rangle = 0 \\
\alpha_1 \langle x_1, x_j \rangle + \cdots = \alpha_k \langle x_k, x_j \rangle = \alpha_j \langle x_j x_j \rangle
\end{gather*}
Velja
\begin{align*}
\langle x_1, x_j \rangle &= 0 \\
\langle x_2, x_j \rangle &= 0 \\
\vdots & \\
\langle x_j, x_j \rangle &> 0 \\
\vdots & \\
\langle x_k, x_j \rangle &= 0
\end{align*}
Sledi
\begin{equation*}
\alpha_j \underbrace{\langle x_j, x_j \rangle}_{\neq 0} = 0 \Rightarrow \alpha_j = 0
\end{equation*}
Torej so $x_1, \ldots, x_k$ linearno neodvisni.

\textsc{Definicija:} Naj bo $V$ vektorski prostor s skalarnim produktom in $M \subseteq V$. Pravimo, da je $M$ \emph{ortogonalna}, kadar velja sklep
\begin{equation*}
\forall x, y \in M: x \neq y \Rightarrow x \perp y
\end{equation*}

"Ce je $M$ ortogonalan in $0 \notin M$, potem je $M$ linearno neodvisna.

\textsc{Definicija:} Pravimo, da je $M$ \emph{ortonormirana}, kadar je ortogonalna in za vsak $x \in M$ velja
\begin{equation*}
\| x \| = 1
\end{equation*}

Naj bo $\{ v_1, \ldots, v_n \}$ ONB v.p.\,$V$ s s.p. Za $x \in V$ velja
\begin{equation*}
x = \alpha_1 v_1 + \cdots + \alpha_n v_n
\end{equation*}
Koeficient $\alpha_j$ izra"cnamo na slede"c na"cin
\begin{multline*}
\langle x, v_j \rangle = \langle \alpha_1 v_1 + \cdots + \alpha_n v_n, v_j \rangle = \\
= \alpha_1 \langle v_1, v_j \rangle + \cdots + \alpha_n \langle v_n, v_j \rangle = \alpha_j
\end{multline*}
Ker je $ \{ v_1, \ldots, v_n \}$ ortonormirana baza, velja
\begin{equation*}
\langle v_i, v_j \rangle = \delta_{ij}
\end{equation*}
Torej velja
\begin{equation*}
x = \sum_{j = 1}^n \langle x, v_j \rangle v_j
\end{equation*}

\textsc{Ortogonalizacija} (Gramm-Schmidt): Naj bodo $x_1, \ldots, x_m$ linearno neodvisni. "Zelimo najti $y_1, \ldots, y_m$, ki so paroma pravokotni in velja
\begin{equation*}
\Lin \{ x_1, \ldots, x_k \} = \Lin \{ y_1, \ldots, y_k \}
\end{equation*}
kjer je $k = 1, \ldots, m$.

Poglejmo si indukcijsko bazo $m = 2$. Naj bosta $x_1, x_2 \in V$ in i"s"cemo $y_1, y_2$, da velja $\langle y_1, y_2 \rangle = 0$. Vemo, da bo $y_2$ oblike
\begin{equation*}
y_2 = x_2 + \alpha y_1
\end{equation*}
Ena"cbo skalarno pomno"zimo z $y_1$ in dobimo
\begin{equation*}
\underbrace{\langle y_2, y_1 \rangle}_{0} = \langle x_2, y_1 \rangle + \alpha \langle y_1, y_1 \rangle
\end{equation*}
Od tod sledi
\begin{equation*}
\alpha = - \dfrac{\langle x_2, y_1 \rangle}{\langle y_1, y_1 \rangle}
\end{equation*}
%
Za splo"sen indukcijski korak naredimo podoben postopek:

Recimo, da poznamo $y_1, \ldots, y_{k-1}$ in i"s"cemo $y_k$. Vemo, da bo $y_k$ oblike
\begin{equation*}
y_k = x_k + \alpha_1 y_1 + \cdots + \alpha_{k-1} x_{k-1}
\end{equation*}
in i"s"cemo $\alpha_1, \ldots, \alpha_{k-1}$. "Zelimo si da velja
\begin{equation*}
\langle y_k, y_i \rangle = 0 \qquad i = 1, \ldots, k-1
\end{equation*}
Zgornjo ena"cbo skalarno pomno"zimo z $y_j$ in dobimo
\begin{equation*}
\underbrace{\langle y_k, y_j \rangle}_{0} = \langle x_k, y_j \rangle + \alpha_j \langle y_j, y_j \rangle
\end{equation*}
Od tod sledi
\begin{equation*}
\alpha_j = - \dfrac{\langle x_k, y_j \rangle}{\langle y_j, y_j \rangle}
\end{equation*}
Torej velja
\begin{equation}
\label{eq:gm-ortogonalizacija}
y_k = x_k - \sum_{j = 1}^{k-1} \dfrac{\langle x_k, y_j \rangle}{\langle y_j, y_j \rangle} y_j
\end{equation}

Z indukcijo doka"zemo, da zaporedje $y_1, \ldots, y_m$ ustreza pogojem za GS-ortogonalizacijo. Za $m=2$ "ze vemo, dokazaujemo "se indukcijski korak $k-1 \rightsquigarrow k$. Po indukcijski predpostavki $y_1, \ldots, y_{k-1}$ ustrezajo pogojem in trdimo, da $y_1, \ldots, y_{k-1}, y_k$ ustrezajo pogojem:
\begin{enumerate}
    \item $\langle y_i, y_j \rangle = 0 \quad \forall i \neq j$
    
    Velja zaradi indukcijske predpostavke in izbire koeficientov $\alpha_1, \ldots, \alpha_{k-1}$.
    
    \item $\Lin \{ x_1, \ldots, x_j \} = \Lin \{y_1, \ldots, y_j \}$ za $j = 1, \ldots, k$
    
    Za $j = 1, \ldots, k-1$ vemo po indukcijski predpostavki. Dokazati moramo
    \begin{equation*}
    \Lin \{ x_1, \ldots, x_k \} = \Lin \{ y_1, \ldots, y_k \}
    \end{equation*}
    Ker vemo, da so $y_1, \ldots, y_{k-1}$ linearna kombinacija $x_1, \ldots, x_{k-1}$ in obratno, je dovolj dokazati, da je $x_k$ linearna kombinacija vektorjev $y_1, \ldots, y_k$ in da je $y_k$ linearna kombinacija vektorjev $x_1, \ldots, x_k$.
    \begin{itemize}
        \item \dashuline{$x_k$ linearna kombinacija $y_1, \ldots, y_k$}
        
        Neposredno iz formule \refeq{eq:gm-ortogonalizacija}.
        
        \item \dashuline{$y_k$ linearna kombinacija $x_1, \ldots, x_k$}
        
        Ker je $\Lin \{ y_1, \ldots, y_{k-1} = \Lin \{ x_1, \ldots, x_{k-1} \}$, so $y_1, \ldots, y_{k-1}$ linearna kombinacija vektorjev $x_1, \ldots, x_{k-1}$. Nato uporabimo formulo \refeq{eq:gm-ortogonalizacija}.
    \end{itemize}
\end{enumerate}

\textbf{Dodatek:}
\begin{equation*}
z_j = \dfrac{y_j}{\| y_j \|} \hfill j = 1, \ldots, m
\end{equation*}
Vektorji $z_1, \ldots, z_m$ ustrezajo pogoejm GS-ortogonalizacije, poleg tega pa velja $\| z_j \| = 1$ za vsak $j$. Torej velja
\begin{equation*}
\langle z_i, z_j \rangle = \delta_{ij}
\end{equation*}
in
\begin{equation*}
\Lin \{ x_1, \ldots, x_j \} = \Lin \{ z_1, \ldots, z_j \} \hfill j = 1, \ldots, m
\end{equation*}
Za $i \neq j$ velja
\begin{equation*}
\langle z_i, z_j \rangle = \left\langle \dfrac{y_i}{\| y_i \|}, \dfrac{y_j}{\| y_j \|} \right\rangle = \dfrac{1}{\| y_i \|} \dfrac{1}{\| y_j \|} \overbrace{\langle y_i, y_j \rangle}^0 = 0
\end{equation*}
Za $i = j$ velja
\begin{equation*}
\langle z_i, z_i \rangle = \left\langle \dfrac{y_i}{\| y_i \|}, \dfrac{y_i}{\| y_i \|} \right\rangle = \dfrac{1}{\| y_i \|^2} \langle y_i, y_i \rangle = \dfrac{1}{\| y_i \|^2} \| y_i \|^2 = 1
\end{equation*}

\textsc{Posledica:} Vsak netrivialen kon"cno razse"zen vektorski prostor s skalarnim produktom ima ortonormirano bazo.

\textsc{Dokaz:} Naj bodo $\{ x_1, \ldots, x_n \}$ baza $V$. Z GS-ortogonalizacijo in normiranje dobimo $\{ z_1, \ldots, z_n \}$, za katere vemo, da so ortonormirana baza prostora $V$.

Naj bodo $\{ v_1, \ldots, v_n \}$ ONB $V$ in $x, y \in V$. Zapi"semo lahko
\begin{align*}
x &= \sum_{i = 1}^n \alpha_i v_i \\
y &= \sum_{j = 1}^n \beta_j v_j
\end{align*}
kjer je $\alpha_i = \langle x, v_i \rangle$ in $\beta_j = \langle y, v_j \rangle$. Potem velja
\begin{multline*}
\langle x, y \rangle = \left\langle \sum_{i = 1}^n \alpha_i v_i, \sum_{j =1}^n \beta_j v_j \right\rangle = \sum_{i, j = 1}^n \langle \alpha_i v_i, \beta_j v_j \rangle = \\
= \sum_{i, j = 1}^n \alpha_i \overline{\beta_j} \langle v_i, v_j \rangle = \sum_{i=1}^n \alpha_i \overline{\beta_i}
\end{multline*}
Pravimo, da je
\begin{equation*}
\langle x, y \rangle = \sum_{i=1}^n \alpha_i \overline{\beta_i}
\end{equation*}
\emph{standardni} skalarni produkt vektorskega prostora $\FF^n$.

Naj bo $\Phi: V \to \FF^n$ preslikava s predpisom:
\begin{equation*}
\Phi(x) = \Phi \left( \sum_{i=1}^n \langle x, v_i \rangle v_i \right) = \begin{bmatrix}
\langle x, v_1 \rangle \\
\langle x, v_2 \rangle \\
\vdots \\
\langle x, v_n \rangle
\end{bmatrix} = \alpha
\end{equation*}
$\Phi$ je izomorfizem vektorskih prostorov in velja
\begin{equation*}
\langle x, y \rangle = \underbrace{\langle \Phi(x), \Phi(y) \rangle}_\text{standrardni s.p.\, v $\FF^n$}
\end{equation*}

\textsc{Definicija:} Naj bo $V$ vektorski prostor s skalarnim produktom in $M, N \subseteq V$ podmno"zici. Velja
\begin{equation*}
M \perp N \iff x \perp y \qquad \forall x \in M \quad \forall y \in N
\end{equation*}
Pravimo, da je
\begin{equation*}
M^\perp = \{ x \in V: x \perp y \quad \forall y \in M \}
\end{equation*}
\emph{ortogonalni komplement} mno"zice $M$ v $V$.

\textsc{Definicija:} Naj bosta $V_1, V_2$ podprostora v vektorskem prostoru $V$. Pravimo, da je vsota $V_1 + V_2$ \emph{ortogonalna}, kadar je $V_1 \perp V_2$.

\textsc{Trditev:} Ortogonalna vsota je direktna. Ozna"cimo z $V_1 \boxplus V_2$.

\textsc{Dokaz:} Vaja za DN.

\textsc{Trditev:} "Ce je $V = V_1 \boxplus V_2$, potem je $V_2 = V_1^\perp$ in $V_1 = V_2^\perp$.

\textsc{Dokaz:} Prav tako vaja za DN.

\textsc{Izrek:} Naj bo $U$ vektorski podprostor vektroskega prostora $V$. Potem je
\begin{equation*}
V = U \boxplus U^\perp
\end{equation*}
\textsc{Dokaz:} "Ce je $U = \{ 0 \}$ velja $U^\perp = V$. Naj bo $U \neq \{ 0 \}$ in $\{ v_1, \ldots, v_k \}$ \ONB $U$. Za $x \in V$ lahko definiramo
\begin{equation*}
\sum_{j=1}^k \langle x, v_j \rangle v_j \quad \in U
\end{equation*}
Velja 
\begin{equation*}
x = y + z \qquad z = x - y
\end{equation*}
Trdimo \dashuline{$z \in U^\perp$}
\begin{multline*}
\langle z, v_i \rangle = \langle x - y, v_i \rangle = \langle x, v_i \rangle - \left\langle \sum_{j=1}^k \langle x, v_j \rangle v_j, v_i \right\rangle = \\
= \langle x, v_i \rangle - \sum_{j=1}^k \langle x, v_j \rangle \underbrace{\langle v_j, v_i \rangle}_{\delta_{ij}} = \langle x, v_i \rangle - \langle x, v_i \rangle = 0
\end{multline*}
Torej je $\langle z, v_i \rangle = 0$ za $i = 1, \ldots, k$.

Za $u \in U$ velja
\begin{equation*}
u = \sum_{j=1}^k \alpha_j v_j
\end{equation*}
Torej je
\begin{equation*}
\langle z, u \rangle = \langle z, \sum_{j=1}^k \alpha_j, v_j \rangle = \sum_{j=1}^k \overline{\alpha_j} \underbrace{\langle z, v_j \rangle}_0 = 0
\end{equation*}
Po definiciji sledi, da je $z \in U^\perp$.

\textbf{Opomba:} $y$ je pravokotna projekcija $x$ na $U$.

Naj bo $\{ v_1, \ldots, v_k \}$ \ONB vektorskega podprostora $U$, v v.p.\,s s.p.\,$V$. Naj bo endomorfizem $P \in \LL(V), P: V \to V$ definiran s predpisom
\begin{gather*}
x \mapsto y \\
P x = \sum_{i=1}^k \langle x, v_i \rangle v_i
\end{gather*}
Pravimo, da je $P$ \emph{pravokotni projektor} na $U$ in velja
\begin{align*}
\im P &= U \\
\ker P &= U^\perp \\
P^2 &= P
\end{align*}
Za $x \in  V$ velja
\begin{equation*}
x = \underbrace{y}_{Px} + z
\end{equation*}
Od tod sledi 
\begin{equation*}
z = x - Px = \underbrace{(\I - P)}_Q x
\end{equation*}
$Q = \I - P$ je pravokotna projekcija na $U^\perp$.

\subsubsection{Linearne preslikave na vektorskih prostorih s skalarnim produktom}
\textsc{Definicija:} Naj bo $\varphi: V \to \FF$ linearna. Pravimo, da je $\varphi$ \emph{linearen funkcional}.

Naj bo $y \in V$. $\varphi_y: V \to \FF$ definiramo s predpisom
\begin{equation*}
f_y(x) = \langle x, y \rangle
\end{equation*}
$\varphi_y$ je linearen funkcional, ker je skalaren produkt linearen v prvem faktorju.

\textsc{Trditev:} Naj bosta $y, z \in V$ in $y \neq z$. Potem velja, da je $\varphi_y \neq \varphi_z$.

\textsc{Dokaz:} Dokazujemo v obratno smer, t.j.: $\varphi_y = \varphi_z \Rightarrow y = z$. "Ce je $\varphi_y = \varphi_z$, potem sta preslikavi enaki za vsak $x \in V$ in velja
\begin{align*}
\varphi_y (x) &= \varphi_z(x) \\
\langle x, y \rangle &= \langle x, z \rangle
\end{align*}
Torej velja
\begin{equation*}
\langle x, y - z \rangle = 0 \qquad \forall x \in V
\end{equation*}
Ker velja za vsak $x$, si lhako izberemo $x = y - z$. Potem velja
\begin{equation*}
\langle y - z, y - z \rangle = 0
\end{equation*}
torej je $y = z$.

\hfill $\square$

Ozna"cimo:
\begin{equation*}
\LL (V, \FF) \equiv V^*
\end{equation*}
in pravimo, da je $V^*$ \emph{dualni prostor} vektorskega prostora $V$.

\textsc{Izrek} (Reisz-ov izrek o reprezentaciji linearnih funkcionalov): Za vsak $\varphi \in V^*$ obstaja natanko en $y \in V$, tako da je $\varphi = \varphi_y$, t.j.:
\begin{equation*}
\varphi(x) = \langle x, y \rangle \qquad \forall x \in V
\end{equation*}
\textsc{Dokaz:} Naj bo $\{ v_1, \ldots, v_n \}$ \ONB $V$ in $\varphi \in V^*$. I"s"cemo $y$, da bo $\varphi = \varphi_y$. Za $x \in V$ velja
\begin{equation*}
x = \sum_{j=1}^n \langle x, v_j \rangle v_j
\end{equation*}
Od tod sledi:
\begin{multline*}
\varphi(x) = \varphi \left( \sum_{j=1}^n \langle x, v_j \rangle v_j \right) = \sum_{j=1}^n \langle x, v_j \rangle \varphi(v_j) = \sum_{j=1}^n \langle x, \overline{\varphi(v_j)}v_j \rangle = \\
= \left\langle x, \underbrace{\sum_{j=1}^n \overline{\varphi(v_j)} v_j}_y \right\rangle
\end{multline*}
$\Rightarrow \varphi = \varphi_y$. Enoli"cnost smo "ze dokazali v zgornjem dokazu.

\hfill $\square$

Definirajmo preslikavo
\begin{align*}
F: V &\to V^* \\
y &\mapsto \varphi_y
\end{align*}
$F$ je aditivna in \emph{antihomogena}\footnote{Nekateri pravijo tudi \emph{po"sevno linearna}.} $(F(\alpha y) = \overline{\alpha}F(y))$ in je bijekcija po Reisz-ovem izreku o reprezentaciji.

\subsubsection{Hermitsko adjungirani endomorfizmi}
Naj bo $\A \in \L(V)$ in $y \in V$. Preslikava $\varphi$ naj bo definirana s predpisom
\begin{align*}
\varphi: V &\to \FF \\
x &\mapsto \langle \A x, y \rangle
\end{align*}
$\varphi \in V^*$, ker je $A$ linearna. Po Reiszovem izreku obstaja $z \in V$, da velja $\varphi = \varphi_z$, t.j.:
\begin{equation*}
\langle \A x, y \rangle = \langle x, z \rangle \qquad \forall x \in V
\end{equation*}
kjer je $z$ odvisen od $y$. Torej lahko zapi"semo
\begin{align*}
z = f(y) && f: V \to V
\end{align*}
Torej velja
\begin{equation*}
\langle \A x, y \rangle = \langle x, f(y) \rangle \qquad \forall x \in V
\end{equation*}

\textsc{Trditev:} $f$ je linearna preslikava, t.j.: $f \in \LL(V)$.

\textsc{Dokaz:}
\begin{itemize}
    \item \textbf{aditivnost}
    \begin{multline*}
    \langle x, f(\overbrace{y_1 + y_2}^u) \rangle = \langle \A x, y_1 + y_2 \rangle = \langle \A x, y_1 \rangle + \langle \A x, y_2 \rangle = \\
    = \langle x, f(y_1) \rangle + \langle x, f(y_2) \rangle = \langle x,\underbrace{ f(y_1) + f(y_2)}_v \rangle
    \end{multline*}
    Torej velja
    \begin{gather*}
    \langle x, u \rangle = \langle x, v \rangle \qquad \forall x \in V \\
    \langle x, u - v \rangle = 0 \qquad \forall x \in V
    \end{gather*}
    Ker velja za vsak $x$ si lahko izberemo $x = u - v$. Od tod sledi
    \begin{equation*}
    \langle u - v, u - v \rangle = 0 \Rightarrow u = v
    \end{equation*}
    Torej velja
    \begin{equation*}
    f(y_1 + y_2) = f(y_1) + f(y_2)
    \end{equation*}
    
    \item \textbf{homogenost}
    \begin{equation*}
    \langle x, \underbrace{f(\alpha y)}_u \rangle = \langle \A x, \alpha y \rangle = \overline{\alpha} \langle \A x, y \rangle = \overline{\alpha} \langle x, f(y) \rangle = \langle x,\underbrace{ \alpha f(y)}_v \rangle
    \end{equation*}
    Po enakem premisleku kot prej velja $u = v$, torej
    \begin{equation*}
    f(\alpha y) = \alpha f(y)
    \end{equation*}
\end{itemize}
\hfill $\square$

Ozna"cimo
\begin{equation*}
f \equiv \A^*
\end{equation*}
in pravimo, da je $\A^*$ \emph{hermitsko adjungirani endomorfizem}. Torej velja
\begin{equation*}
\langle \A x, y \rangle = \langle x, \A^* y \rangle \qquad \forall x, y \in V
\end{equation*}

\textsc{Trditev:}
Naj bo $\A \in \LL(V)$ in $\A^* \in \LL(V)$ in naj velja:
\begin{equation*}
\langle \A x, y \rangle = \langle x, \A^* y \rangle \qquad \forall x,y \in V
\end{equation*}
Potem velja
\begin{equation*}
\langle x, \A y \rangle = \langle \A^* x, y \rangle
\end{equation*}
\textsc{Dokaz:}
\begin{equation*}
\langle x, \A y \rangle = \overline{\langle \A y, x \rangle} = \overline{\langle y, \A^* x \rangle} = \langle \A^* x, y \rangle
\end{equation*}
\hfill $\square$

\textsc{Trditev:} Za preslikavo, ki slika $\LL(V) \to \LL(V)$ s predpisom $\A \mapsto \A^*$ velja
\begin{enumerate}
    \item $\A^{**} = \A$ \emph{involucija}
    \item $(\A + \B)^* = \A^* + \B^*$
    \item $(\alpha \A)^* = \overline{\alpha} \A^*$
    \item $(\A \B)^* = \B^* \A^*$ \emph{antimultiplikativnost}
    \item $0^* = 0, \quad \I^* = \I$
\end{enumerate}
\textsc{Lema:} Naj bosta $\C_1, \C_2 \in \LL(V)$ "Ce je
\begin{equation*}
\langle \C_1 x, y \rangle = \langle \C_2 x, y \rangle \qquad \forall x, y \in V
\end{equation*}
potem je $\C_1 = \C_2$. Analogno velja za $\C_1, \C_2$ pri drugem faktorju.

\textsc{Dokaz:} $x$ fiksiramo in ozna"cimo
\begin{align*}
\C_1 x = u && \C_2 x = v
\end{align*}
Po predpostavki velja
\begin{equation*}
\langle u, y \rangle = \langle v, y \rangle \qquad \forall y \in V
\end{equation*}
Po istem premisleku ko smo ga "ze naredili velja $u = v$. Torej velja
\begin{equation*}
\C_1 x = \C_2 x \qquad \forall x \in V
\end{equation*}
Zato je $\C_1 = \C_2$.

\textsc{Dokaz lastnosti (4):}
\begin{multline*}
\langle (\A \B)^* x, y \rangle = \langle x, (\A \B) y \rangle = \langle x, \A (\B y) \rangle = \\
= \langle \A^* x, y \rangle = \langle \B^* \A^* x, y \rangle \qquad \forall x, y \in V
\end{multline*}
Po lemi torej velja
\begin{equation*}
(\A \B)^* = \B^* \A^*
\end{equation*}
\hfill $\square$

\subsubsection{Prehod na matrike}
Naj bo $\A \in \LL(V)$ in $\V = \{ v_1, \ldots, v_n \}$ \ONB $V$. Preslikavi $\A$ priredimo matriko $A = [a_{ij}]_{i, j = 1, \ldots, n}$ v bazi $\V$. Velja
\begin{equation*}
\A v_j = a_{1j} v_1 + a_{2j} v_2 + \cdots a_{nj} v_n
\end{equation*}
Ena"cbo skalarno pomno"zimo z $v_i$ in dobimo
\begin{equation*}
\langle \A v_j, v_i \rangle = a_{1j} \underbrace{\langle v_1, v_i \rangle}_{\delta_{1i}} + a_{2j} \underbrace{\langle v_2, v_i \rangle}_{\delta_{2i}} + \cdots + a_{nj} \underbrace{\langle v_n, v_i \rangle}_{\delta_{nj}} = a_{ij}
\end{equation*}
Torej velja
\begin{equation*}
a_{ij} = \langle A v_j, v_i \rangle \qquad \forall i, j
\end{equation*}
Zanima nas kak"sno matriko $B = [b_{ij}]_{i, j = 1, \ldots, n}$ v bazi $\V$ ima preslikava $\A^*$.
\begin{equation*}
b_{ij} = \langle \A^* v_j, v_i \rangle = \langle v_j, \A v_i \rangle = \overline{\langle \A v_i, v_j \rangle} = \overline{a_{ji}}
\end{equation*}
Torej velja
\begin{equation*}
b_{ij} = \overline{a_{ji}}
\end{equation*}
Matrika $B$ je torej oblike
\begin{equation*}
B = \overline{A}^T = A^H
\end{equation*}
in pravimo, da je $A^H$ \emph{hermitsko transponirana}.

S tem smo dokazali naslednjo trditev

\textsc{Trditev:} "Ce endomorfizmu $\A\in \L(V)$ v \ONB $\V$ pripada matrika $A$, potem endomorfizmu $\A^*$ v tej bazi pripada $A^H$.

\subsubsection{Normalni endomorfizmi}
\textsc{Definicija:} Naj bo $\A \in \LL(V)$. Pravimo, da je $\A$ \emph{normalen}, kadar velja
\begin{equation*}
\A \A^* = \A^* \A
\end{equation*}

\textsc{Lastnosti:}
\begin{enumerate}
    \item $\A$ je normalen $\iff \langle \A x, \A y \rangle = \langle \A^* x, \A^* y, \rangle$ \hfill $\forall x, y \in V$
    \item $\| \A x \| = \| \A^* x \|$ \hfill $\forall x \in V$
    \item $\ker \A = \ker \A^*$
    \item $\A - \lambda \I$ je normalen \hfill $\forall \lambda \in \FF$
    \item $\A x = \lambda x \iff \A^* x = \overline{\lambda}x$
    \item $(\A x = \lambda x \land \A y = \mu y \land \lambda \neq \mu ) \Rightarrow \langle x, y \rangle = 0$
\end{enumerate}
\textsc{Dokaz:}
\begin{enumerate}
    \item
    \begin{itemize}
        \item[($\Rightarrow$)]
        \begin{equation*}
        \langle \A x, \A y \rangle = \langle \A^* \A x, y \rangle = \langle \A \A^* x, y \rangle = \langle \A^* x, \A^* y \rangle
        \end{equation*}
        
        \item[($\Leftarrow$)]
        \begin{equation*}
        \langle \A \A^* x, y \rangle = \langle \A^* x, \A^* y \rangle = \langle \A x, \A y \rangle = \langle \A^* \A x, y \rangle \qquad \forall x, y \in V
        \end{equation*}
        Po Lemi velja $\A \A^* = \A^* \A$.
    \end{itemize}

    \item 
    \begin{equation*}
    \| \A x \|^2 = \langle \A x, \A x \rangle = \langle \A^* x, \A^* x \rangle = \| \A^* x \|^2
    \end{equation*}
    
    \item
    \begin{multline*}
    x \in \ker \A \iff \A x = 0 \iff \| \A x \| = 0 \iff \| \A^* x \| = 0 \iff \\
    \iff \A^* x = 0 \iff x \in \ker \A^*
    \end{multline*}
    
    \item
    \begin{multline*}
    (\A - \lambda \I) (\A - \lambda \I)^* = (\A - \lambda \I) (\A^* - \overline{\lambda} \I ) = \\
    = \A \A^* - \overline{\lambda} \A - \lambda \A^* + \lambda \overline{\lambda} \I = \A^* \A - \lambda \A^* - \overline{\lambda} \A - \overline{\lambda}\lambda \I = \\
    = (\A^* - \overline{\lambda} \I) (\A - \lambda \I) = (\A - \lambda \I)^* (\A - \lambda \I)
    \end{multline*}
    
    \item
    \begin{multline*}
    \A x = \lambda x \iff (\A - \lambda \I ) = 0 \iff x \in \ker (\A - \lambda \I) \stackrel{(3), (4)}{\iff} \\
    \iff x \in \ker(A - \lambda \I)^* \iff x \in \ker (\A* - \overline{\lambda} \I)  \iff \\
    \iff (\A^* - \overline{\lambda} \I)x = 0 \iff \A^* x = \overline{\lambda} x
    \end{multline*}
    
    \item
    \begin{gather*}
    \lambda \langle x, y \rangle = \langle \lambda x, y \rangle = \langle \A x, y \rangle = \langle x, \A^* y \rangle \stackrel{(5)}{=} \langle x, \overline{\mu} y \rangle = \mu \langle x, y \rangle \\
    \Rightarrow \underbrace{(\lambda - \mu)}_{\neq 0} \langle x, y \rangle = 0 \Rightarrow \langle x, y \rangle = 0
    \end{gather*}
\end{enumerate}
\hfill $\square$

\textbf{Opombe:}
\begin{itemize}
    \item Lastnost (5) nam pove $\spec \A^* = \overline{\spec \A}$
    \item Iz (6) sledi
    \begin{equation*}
    \ker (\A - \lambda \I) \perp \ker(\A - \mu I) \qquad \forall \lambda \neq \mu
    \end{equation*}
\end{itemize}

\textsc{Trditev:} Naj bo $\dim V = n$, normalen endomorfizem $\A\in \LL(V)$ pa naj ima $n$ razli"cnih lastnih vrednosti. Potem se da $\A$ diagonalizirati v ONB.

\textsc{Dokaz:} Naj bodo $\lambda_1, \ldots, \lambda_n \in \FF$ razli"cne lastne vrednosti. Velja
\begin{equation*}
\A x_j = \lambda_j x_j \qquad j = 1, \ldots, n
\end{equation*}
za $x_j \neq 0$. Iz lastnosti normalnih endomorfizmov (6) sledi $x_i \perp x_j \forall i \neq j$. Torej lahko definiramo vektorje
\begin{equation*}
y_j = \dfrac{x_j}{\| x_j \|} \qquad \forall j \Rightarrow \A y_j = \lambda_j y_j
\end{equation*}
ki tvorijo ONB $\{ y_1, \ldots, y_n \}$.

\hfill $\square$

\textsc{Trditev:} Naj bo $\A \in \LL(V)$ in $U$ v.\,podprostor v.p.\,$V$. Potem velja
\begin{equation*}
\A U \subseteq U  \Rightarrow \A^* (U^\perp) \subseteq U^\perp
\end{equation*}
\textsc{Dokaz:} Naj bo $x \in U$ in $y \in U^\perp$. Velja
\begin{equation*}
\langle \A^* x, y \rangle = \langle \underbrace{x}_{\in U^\perp}, \underbrace{\A y}_{\in U} \rangle = 0
\end{equation*}
Od tod sledi
\begin{gather*}
\Rightarrow \A^* x \in U^\perp \qquad \forall x \in U^\perp \\
\Rightarrow \A^* (U^\perp) \subseteq U^\perp
\end{gather*}
\hfill $\square$

\textsc{Izrek:} Naj bo $\A$ normalen endomorfizem na $V$. "Ce je $V$ kompleksen ($\FF = \CC$) ali "ce je $V$ realen in ima karakteristi"cni polinom vse ni"cle realne, se da $\A$ diagonalizirati v ONB.

\textsc{Dokaz:} Z uporabo indukcije glede na $\dim V = n$. Za $n = 1$ je o"citno. Dokazujemo indukcijski korak $n -1 \rightsquigarrow n > 1$.

Poi"s"cemo lastni vektor (obstaja zaradi predpostavk) z normo 1.
\begin{equation*}
\A v_1 = \lambda v_1 , \quad \| v_1 \| = 1
\end{equation*}
$\FF v_1$ je invarianten za $\A$.

Ker je $\A^* v_1 = \overline{\lambda} v_1$ je $\FF v_1$ invarianten za $\A^*$.

Po prej"snji trditvi je $(\FF v_1)^\perp$ invarianten za $\A^*$ in za $\A^{**} = \A$.
\begin{equation*}
W = (\FF v_1)^\perp = \{ v_1 \}^\perp \equiv v_1^\perp
\end{equation*}
$W$ je invarianten za $\A$ in $\A^*$. Torej sta zo"zitvi $\A$ in $\A^*$ na $W$ endomorfizma $W$ in $\A_W \in \LL(W)$ je normalen endomorfizem na $W$, t.j.:
\begin{equation*}
(\A^*)_W = (\A_W)^*
\end{equation*}
Velja
\begin{equation*}
\underbrace{(\FF v_1)}_{\dim = 1} \oplus \underbrace{(\FF v_1)^\perp}_{\dim = n-1} = \underbrace{V}_{\dim = n}
\end{equation*}
Po indukcijski predpostavki se da $\A_W$ diagonalizirati v ONB vektorskega prostora $W$, t.j.:
\begin{equation*}
\{ v_2, \ldots, v_n \}
\end{equation*}
tvorijo ONB $W$ in
\begin{equation*}
\A_W v_j = \lambda_j v_j \qquad j = 2, \ldots, n
\end{equation*}
Od tod sledi
\begin{equation*}
\A v_j = \A_W v_j = \lambda_j v_j \qquad j = 2, \ldots, n
\end{equation*}
Od prej vemo $\A v_1 = \lambda_1 v_1$. Ker je $W = (\FF v_1)^\perp$ velja
\begin{equation*}
v_j \in W = (\FF v_1)^\perp \Rightarrow \langle v_j, v_1 \rangle = 0 \qquad \forall j \geq 2
\end{equation*}
Torej je
\begin{equation*}
\{ v_1, \ldots, v_n \}
\end{equation*}
ONB iz lastnih vektorjev endomorfizma $\A$.

\subsubsection{Matri"cna verzija}
\textsc{Definicija:} Naj bo $A \in \FF^{n \times n} = \LL(\FF^n)$ in $\FF^n$ s standardnim skalarnim produktom. Pravimo, da je $A$ \emph{normalna}, kadar je kot endomorfizem $A$ normalen, t.j.: $A$ je normalna natanko takrat, kadar velja
\begin{equation*}
A A^H = A^H A
\end{equation*}
\textbf{Opomba:} Vsi izreki za normalne endomorfizme dr"zijo za normalne matrike.

"Ce je $A$ normalen in $A \in \CC^{n \times n}$, se da $A$ diagonalizirati v ONB $\CC^n$. "Ce je $A \in \RR^{n\times n}$ in ima $\Delta_A(\lambda)$ vse ni"cle realne, se da $A$ diagonalizirati v ONB $\RR^n$.

Naj bo $A \in \CC^{n \times n}$. Potem obstaja obrnljiva matrika $P \in \CC^{n \times n}$, da velja
\begin{equation*}
P^{-1}AP = \diag(\lambda_1, \ldots, \lambda_n)
\end{equation*}
kjer so $\lambda_1, \ldots, \lambda_n$ lastne vrednosti $A$. Vemo da so stolpci matrike $P$ lastni vektorji $A$ in ker je $A$ normalna, je
\begin{equation*}
\left\{ P^{(1)}, \ldots, P^{(n)} \right\}
\end{equation*}
ortonormirana baza $\CC^n$, t.j.:
\begin{equation*}
\left\langle P^{(i)}, P^{(j)} \right\rangle = \delta_{ij}
\end{equation*}
kjer je $\langle \cdot, \cdot \rangle$ standardni skalarni produkt.

Naj bosta $x, y \in \CC^n$. Potem velja
\begin{equation*}
\langle x, y \rangle = \sum_{j=1}^n x_j \overline{y_j} = y^H x
\end{equation*}
kjer sta
\begin{align*}
y^H = \begin{bmatrix}\overline{y_1}, & \ldots & \overline{y_n}\end{bmatrix} && x = \begin{bmatrix}
x_1 \\
\vdots \\
x_n
\end{bmatrix}
\end{align*}
Torej velja
\begin{equation*}
\left( P^{(j)} \right)^H P^{(i)} = \delta_{ij}
\end{equation*}
od koder sledi
\begin{equation*}
P^H P = I
\end{equation*}
Potem velja
\begin{equation*}
P^H P = I \iff \left\{ P^{(1)}, \ldots, P^{(n)} \right\} \text{ je ONB $\CC^n$}
\end{equation*}

\textsc{Definicija:} Pravimo, da je $P$ \emph{unitarna matrika}, kadar velja sklep:
\begin{equation*}
P^H P = I \iff \left\{ P^{(1)}, \ldots, P^{(n)} \right\} \text{ je ONB $\CC^n$}
\end{equation*}

"Ce je $P$ unitarna matrika, potem velja
\begin{equation*}
P^H = P^{-1}
\end{equation*}
Torej velja
\begin{equation*}
P P^H = P^H P = I
\end{equation*}
in
\begin{equation*}
P^H AP = \diag (\lambda_1, \ldots, \lambda_n)
\end{equation*}
Pravimo, da je $P^H AP$ \emph{unitarno podobna} $A$. Druga"ce povedano: normalna kompleksna matrika je unitarno podobna diagonalni matriki.

Naj bo $A \in \RR^{n \times n}$ normalna s standardnim skalarnim produktom v $\RR^n$ in naj bodo vse ni"cle $\Delta_A(\lambda)$ relane. Potem obstaja obrnljiva matrika $P \in \RR^{n \times n}$ da velja
\begin{equation*}
P^{-1} AP = \diag(\lambda_1, \ldots, \lambda_n)
\end{equation*}
kjer so $\lambda_1, \ldots, \lambda_n \in \RR$ lastne vrednosti matrike $A$. Vemo, da so stolpci matrike $P$ lastni vektorji $A$ in ker je $A$ normalna, vektorji
\begin{equation*}
\left\{ P^{(1)}, \ldots, P^{(n)} \right\}
\end{equation*}
tvorijo ONB v $\RR^n$. Po podobnem premisleku kot prej velja
\begin{equation*}
P^T P = I \iff \left\{ P^{(1)}, \ldots, P^{(n)} \right\} \text{ tvorijo ONB v $\RR^n$}
\end{equation*}
Pravimo, da je $P$ \emph{ortogonalna} matrika in velja
\begin{equation*}
P P^T = P^T P = I
\end{equation*}
in
\begin{equation*}
P^T = P^{-1}
\end{equation*}
Velja tudi
\begin{equation*}
P^T AP = \diag (\lambda)_1, \ldots, \lambda_n) \in \RR^{n \times n}
\end{equation*}
in pravimo, da je $P^TAP$ \emph{ortogonalno podobna} $A$. Druga"ce povedano: Normalna realna matrika, katere karakteristi"cni polinom ima vse ni"cle realne, je ortogonalno podobna diagonalni matriki.

\subsubsection{Unitarni endomorfizmi}
\textsc{Definicija:} Naj bo $\A \in \LL(V)$. Pravimo, da je $\A$ \emph{unitaren}, kadar velja
\begin{equation*}
\A \A^* = \A^* \A= \I
\end{equation*}
kjer je $\I = id_V$.

Unitarna matrika $P \in \CC^{n \times n}$ je unitaren endomorfizem na $\CC^n$, ortogonalna matrika $Q \in \RR^{n \times n}$ je unitaren endomorfizam na $\RR^n$.

\textsc{Lastnosti:}
\begin{enumerate}
    \item $\A$ je unitaren $\iff \langle \A x, \A y \rangle = \langle x, y \rangle$ \hfill $\forall x, y \in V$
    
    $\A$ ohranja skalarni produkt in pravimo, da je $\A$ \emph{avtomorfizem} v.p.\,$V$ s s.p.
    
    \textsc{Dokaz:}
    \begin{itemize}
        \item[($\Rightarrow$)]
        \begin{equation*}
        \langle \A x, \A y \rangle = \langle \A^* \A x, y \rangle = \langle x, y \rangle
        \end{equation*}
        
        \item[($\Leftarrow$)]
        \begin{equation*}
        \langle \A^* \A x, y \rangle = \langle \A x, \A y \rangle = \langle x, y \rangle = \langle \I x, y \rangle \qquad \forall x, y \in V
        \end{equation*}
        Po Lemi velja
        \begin{equation*}
        \A^* \A = \I \Rightarrow \A^* = \A^{-1} \Rightarrow \A^* \A = \A \A^* = \I
        \end{equation*}
    \end{itemize}

    \item $\A$ ohranja dol"zine, je \emph{izometrija}, t.j.:
    \begin{equation*}
    \| \A x \| = \| x \|
    \end{equation*}
    \textsc{Dokaz:}
    \begin{equation*}
    \| \A x \|^2 = \langle \A x, \A x \rangle = \langle x, x \rangle = \| x \|^2
    \end{equation*}
    
    Velja tudi v obratno smer: $\A$ izometrija $\Rightarrow \A$ je unitarna.
    
    \textsc{Dokaz:}
    \begin{equation*}
    \| \A x \|^2 = \| x \|^2 \iff \langle \A x, \A x \rangle = \langle x, x \rangle
    \end{equation*}
    Po lastnosti (1), je $\A$ unitaren.
    
    \item $\A$ unitaren natanko takrat, kadar $\A$ ONB presika v ONB.
    
    \textsc{Dokaz:}
    \begin{itemize}
        \item[($\Rightarrow$)] Naj bo $\A$ unitaren in $\{v_1, \ldots, v_n \}$ ONB. Potem velja
        \begin{equation*}
        \langle \A v_i, \A v_j \rangle = \langle v_i, v_j \rangle = \delta_{ij}
        \end{equation*}
        Torej so vektorji v mno"zici $\{ \A v_1, \ldots, \A v_n \}$ ortonormirani (in linearno neodvisni), zato tvorijo ortonormirano bazo.
        
        \item[($\Leftarrow$)] Naj bo $\{ v_1, \ldots, v_n \}$ ONB in $\{ \A v_1, \ldots, \A v_n \}$ ONB. Dokazujemo, da je $\A$ unitarna.
        
        Naj bosta $x, y \in V$ in 
        \begin{align*}
        x &= \alpha_1 v_1 + \cdots + \alpha_n v_n \\
        y &= \beta_1 v_1 + \cdots + \beta_n v_n
        \end{align*}
        Potem velja
        \begin{equation*}
        \langle x, y \rangle = \left\langle \sum_{i=1}^n \alpha_i v_i, \sum_{j=1}^n \beta_n v_n \right\rangle = \sum_{i, j = 1}^n \alpha_i \overline{\beta_j} \underbrace{\langle v_i, v_j \rangle}_{\delta_{ij}} = \sum_{i = 1}^n \alpha_i \overline{\beta_i} 
        \end{equation*}
        in
        \begin{multline*}
        \langle \A x, \A y \rangle = \left\langle \A \left( \sum_{i=1}^n \alpha_i v_i \right), \A \left( \sum_{j=1}^n \beta_j v_j \right) \right\rangle = \\
        \left\langle \sum_{i=1}^n \alpha_i \A v_i, \sum_{j=1}^n \beta_j \A v_j \right\rangle = \sum_{i, j = 1}^n \alpha_i \overline{\beta_j} \underbrace{\langle \A v_i, \A v_j \rangle}_{\delta_{ij}} = \sum_{i=1}^n \alpha_i \overline{\beta_i}
        \end{multline*}
        Torej je
        \begin{equation*}
        \langle \A x, \A y \rangle = \langle x, y \rangle \qquad \forall x, y \in V
        \end{equation*}
        in po lastnosti (1) je $\A$ unitaren.
    \end{itemize}
    \hfill $\square$

    \item $A$ unitaren in $\A x = \lambda x \Rightarrow | \lambda | = 1$, t.j.: lastne vrednosti le"zijo na enotski kro"znici v $\CC$.
    
    \textsc{Dokaz:} Uporabimo, da je $\A$ izometrija in dobimo
    \begin{equation*}
    \| x \| = \| \A x \| = \| \lambda x \| = |\lambda| \| x \|
    \end{equation*}
    Torej je $|\lambda| = 1$.
\end{enumerate}
\textsc{Primeri:} zasuki, zrcaljenja v $\RR^2, \RR^3$.

Naj bo $\A \in \FF^{n \times n}$. Potem velja
\begin{itemize}
    \item $\FF = \CC$: $A$ unitarna natanko takrat, kadar $A$ unitaren endomorfizem $\CC^n \to \CC^n$.
    \item $\FF= \RR$: $A$ ortogonalna natanko takrat, kadar $A$ unitaren endomorfizem $\RR^n \to \RR^n$.
\end{itemize}
\textsc{Opomba:} Unitarni endomorfizmi so normalni.

\subsubsection{Sebi adjungirani endomorfizmi}
\textsc{Definicija:} Naj bo $\A \in \LL(V)$. Pravimo, da je $\A$ \emph{sebi adjungiran}, kadar velja
\begin{equation*}
\A = \A^*
\end{equation*}
Za matrike:
\begin{itemize}
    \item $A \in \CC^{n \times n}$ in velja $A^H = A$, pravimo, da je $A$ \emph{hermitska}.
    \item $A \in \RR^{n \times n}$ in velja $A^T = A$, pravimo, da je $A$ \emph{simetri"cna}.
\end{itemize}
\textbf{Opomba:} $\A \in \CC^{n \times n}, A = A^T$, potem je $A$ kompleksna simetri"cna (ni pa nunno sebi adjungirana).

\textsc{Lastnosti:}
\begin{enumerate}
    \item $\A = \A^* \iff \langle \A x, y \rangle = \langle x, \A y \rangle$ \hfill $\forall x, y \in V$.
    
    \textsc{Dokaz:}
    \begin{itemize}
        \item[($\Rightarrow$)]
        \begin{equation*}
        \langle \A x, y \rangle = \langle x, \A^* y \rangle = \langle x, \A y \rangle
        \end{equation*}
        
        \item[($\Leftarrow$)]
        \begin{equation*}
        \langle \A x, y \rangle = \langle x, \A y \rangle = \langle \A^* x, y \rangle \qquad \forall x, y \in V
        \end{equation*}
        Po Lemi velja $\A = \A^*$.
    \end{itemize}

    \item $(\A = \A^* \land \A x = \lambda x \land x \neq 0) \Rightarrow \lambda \in \RR$.
    
    \textsc{Dokaz:}
    \begin{gather*}
    \langle \A x, x \rangle = \langle \lambda x, x \rangle  = \lambda \langle x, x \rangle \\
    \langle \A x, x \rangle = \langle x, \A x \rangle = \langle x, \lambda x \rangle = \overline{\lambda} \langle x, x \rangle \\
    \Rightarrow \overline{\lambda} = \lambda \Rightarrow \lambda \in \RR
    \end{gather*}
    
    \item $\A = \A^* \Rightarrow \Delta_A(\lambda)$ ima vse ni"cle realne.
    
    \textsc{Dokaz:}
    \begin{itemize}
        \item $\FF = \CC$: ni"cle $\Delta_\A$ so lastne vrednosti $\A$, zato (3) sledi iz (2).
        \item $\FF = \RR$: Preslikavi $\A$ priredimo matriko $A$ v ONB, $A \in \RR^{n \times n}$ in velja
        \begin{equation*}
        A = A^T = A^H
        \end{equation*}
        Gledamo $\RR^{n \times n}$ kot podmno"zico $\CC^{n \times n}$, torej
        \begin{equation*}
        A \in \CC^{n \times n}, A \in \LL(\CC^n), A = A^H
        \end{equation*}
        $\Rightarrow A$ je sebi adjungiran endomorfizem $\CC^n \to \CC^n$, zato ima $\Delta_A(\lambda)$ vse ni"cle realne. Za endomorfizme vemo
        \begin{equation*}
        \Delta_A(\lambda) = \Delta_\A(\lambda)
        \end{equation*}
    \end{itemize}
\end{enumerate}

\textsc{Izrek:} Sebi adjungiran endomorfizem se da diagonalizirati v ONB. Hermitska matrika je unitarno podobna realni diagonalni matriki. Realna simetri"cna matrika je ortogonalno podobna diagonalni matriki.

\textsc{Dokaz:}
Uporabimo izrek normalnih endomorfizmov in lastnost (3). Za drugi del izreka uporabimo matri"cno verzijo izreka o diagonalizaciji normalnih endomorfizmov.

\subsubsection{Pozitivno semidefinitni endomorfizmi}
\textsc{Definicija:} Naj bo $\A \in \LL(V)$. Pravimo, da je $\A$ \emph{pozitivno semidefiniten}, kadar je $\A = \A^*$ in velja
\begin{equation*}
\langle \A x, x \rangle \geq 0 \qquad \forall x \in V
\end{equation*}
$\A$ je \emph{pozitivno definiten}, kadar je $\A = \A^*$ in velja
\begin{equation*}
\langle \A x, x \rangle > 0 \qquad \forall x \in V \setminus \{ 0 \}
\end{equation*}

\textsc{Lastnosti:}
\begin{enumerate}
    \item Naj bo $\A$ sebi adjungiran. $\A$ je pozitivno semidefiniten natanko takrat, kadar $\spec \A \subset [0, \infty)$ in pozitivno definiten natanko takrat, kadar $\spec \A \subset (0, \infty)$
    
    \textsc{Dokaz:}
    \begin{itemize}
        \item[($\Rightarrow$)] Naj bo $\lambda \in \spec \A$. Potem obstaja $x \neq 0: \A x = \lambda x$. Velja
        \begin{equation*}
        \underbrace{\langle \A x, x \rangle}_{\geq 0} = \langle \lambda x,x  \rangle = \lambda \underbrace{\langle x, x \rangle}_{> 0}
        \end{equation*}
        Sledi $\lambda \geq 0$ za pozitivno semidifiniten $\A$ in $\lambda > 0$ za pozitivno definiten $\A$.
        
        \item[($\Leftarrow$)] Naj bo $\A$ sebi adjungiran in $\spec \A \subset (0, \infty)$ ali $[0, \infty)$. Ker je $\A$ sebi adjungiran, se ga da diagonalizirati v ONB $\{ v_1, \ldots, v_n \}$, kjer so $v_1, \ldots, v_n$ lastni vektorji. Torej velja
        \begin{equation*}
        \A v_j = \lambda_j v_j \qquad \forall j
        \end{equation*}
        in $\lambda_j \in \spec \A$, zato je $\lambda_j > 0$ za vsak $j$ (ali $\lambda_j \geq 0)$.
        
        Naj bo $x \in V \setminus \{ 0 \}$. Potem lahko $x$ razvijemo po bazi
        \begin{equation*}
        x = \sum_{i = 1}^n \alpha_i v_i
        \end{equation*}
        in velja
        \begin{multline*}
        \langle \A x, x \rangle = \left\langle \sum_{i=1}^n \alpha_i \A v_i, \sum_{j = 1}^n \alpha_j v_j \right\rangle = \left\langle \sum_{i=1}^n \alpha_i \lambda_i v_i, \sum_{j=1}^n \alpha_j v_j \right\rangle = \\
        = \sum_{i,j = 1}^n \alpha_i \lambda_i \overline{\alpha_j} \underbrace{\langle v_i, v_j, \rangle}_{\delta_{ij}} = \sum_{i=1}^n \alpha_i \lambda_i \overline{\alpha_i} = \sum_{i=1}^n \lambda_i |\alpha_i|^2
        \end{multline*}
        Velja
        \begin{equation*}
        \langle \A x, x \rangle = \sum_{i=1}^n \lambda_i |\alpha_i|^2 > 0 \qquad \forall x \in V
        \end{equation*}
        "ce $\spec \A \subset (0, \infty)$ in 
        \begin{equation*}
        \langle \A x, x \rangle = \sum_{i=1}^n \lambda_i |\alpha_i|^2 \geq 0 \qquad \forall x \in V
        \end{equation*}
        "ce $\spec \A \subset [0, \infty)$.
    \end{itemize}
    \hfill $\square$
\end{enumerate}

Naj bo $A \in \RR^{n \times n}$. Kdaj je $A$ pozitivno definitna?
\begin{itemize}
    \item $A = A^T$ je potreben pogoj ($A$ kot preslikava sebi adjungiran endomorfizem)
    \item $\langle A x, x \rangle > 0$ \hfill $\forall x \in \RR^n \setminus \{ 0 \}$
    
    Naj bo $x = e_j$ (iz standardne baze). Velja
    \begin{equation*}
    \langle A e_j, e_j \rangle = \langle A^{(j)}, e_j \rangle = a_{jj} > 0
    \end{equation*}
    Potreben pogoj je torej $a_{jj} > 0$ za vsak $j$.
    
    \item Poglejmo si karakteristi"cni polinom
    \begin{align*}
    \Delta_A(\lambda) &= a_0 + a_1 \lambda + \cdots + (-1)^n \lambda^n = \\
    &= (-1)^n (\lambda - \lambda_1) (\lambda - \lambda_2) \cdots (\lambda - \lambda_n)
    \end{align*}
    $A = A^T$ je pozitivno definiten natanko takrat, kadar $\lambda_j > 0$ za $j = 1, \ldots, n$ (vemo za sebi adjungirane endomorfizme).
    \begin{multline*}
    (\lambda - \lambda_1) (\lambda - \lambda_2) \cdots (\lambda - \lambda_n) = \\
    \lambda^n - (\lambda_1 + \cdots + \lambda_n)\lambda^{n-1} + \left( \sum_{i < j} \lambda_i \lambda_j \right)\lambda^{n-2} - \cdots + (-1)^n \lambda_1\cdots \lambda_n
    \end{multline*}
    Ta polinom pomno"zimo z $(-1)^n$ in dobimo $a_0, \ldots, a_n$ izra"zene z $\lambda_1, \ldots, \lambda_n$. Ker $\lambda_1, \ldots, \lambda_n > 0$, "cleni $a_0, a_1, \ldots, a_n$ alternirajo po predznaku, t.j.:
    \begin{equation*}
    a_0 > 0, a_1 < 0, a_2 > 0, a_3 < 0, \ldots
    \end{equation*}
    To lahko zapi"semo kot
    \begin{equation*}
    (-1)^j a_j > 0 \qquad \forall j
    \end{equation*}
    Pogoj je tudi zadosten ($A = A^T$ in karakteristi"cni polinom alternira).
    
    \textsc{Dokaz:} Naj bo $\Delta_A(\lambda) = a_0 + a_1 \lambda + \cdots + a_n\lambda^n$ in $(-1)^j a_j > 0$. za $j = 0, \ldots, n$ in $A = A^T \in \RR^{n \times n}$.
    
    Vemo, da so vse ni"cle $\Delta_A(\lambda)$ realne (ker je $A$ sebi ajdungiran endomorfizem). Naj bo $\alpha \in \RR$, $\alpha \leq 0$. Potem velja
    \begin{equation*}
    \Delta_A(\alpha) = \underbrace{a_0}_{>0} + \underbrace{\overbrace{a_1}^{< 0} \overbrace{\alpha}^{\leq 0}}_{\leq 0} + \underbrace{\overbrace{a_2}^{>0} \overbrace{\alpha^2}^{\geq 0}}_{\leq 0} + \cdots +\underbrace{ a_n \alpha^n}_{\geq 0}
    \end{equation*}
    Torej je $\Delta_A(\alpha) \geq a_0 > 0$, zato $\Delta_A(\lambda)$ nime ni"cel $\alpha \leq 0$. Torej so vse ni"cle $\Delta_A(\lambda)$ ve"cje od 0, zato je $A$ pozitivno definitna.
    
    \item Naj bo $A \in \RR^{n \times n}$ oblike $A = [a_{ij}]_{i,j=1, \ldots, n}$. Definiramo
    \begin{equation*}
    A_k = [a_{ij}]_{i,j = 1, \ldots, k} \in \RR^{k \times k}, \quad k = 1, \ldots, n
    \end{equation*}
    in velja
    \begin{equation*}
    A_n = A
    \end{equation*}
    \dashuline{$A$ pozitivno definitna $\Rightarrow A_k$ pozitivno definitna za vsak $k$}
    
    Naj bo $x \in \RR^k \setminus \{ 0 \}$. Velja
    \begin{equation*}
    \langle A_k x, x \rangle = \langle A \hat{x}, \hat{x} \rangle > 0
    \end{equation*}
    kjer je
    \begin{equation*}
    \hat{x} = \begin{bmatrix}
    x \\
    0 \\
    \vdots \\
    0
    \end{bmatrix}
    \end{equation*}
    (ni"cel je $n - k$ in $\hat{x} \neq 0$, ker $x \neq 0$).
    
    "Ce je $A$ pozitivno definitna, je $\det A = a_0 > 0$, torej je 
    \begin{equation*}
    \det A_k > 0 \qquad k = 1, \ldots, n
    \end{equation*}
    
    \textsc{Izrek:} Realna simetri"cna $n \times n$ matrika $A$ je pozitivno definitna natanko takrat, kadar je $\det A_k > 0$ za $k = 1, \ldots, n$.
\end{itemize}

\subsubsection{Bilinearni in kvadratni funkcionali}
Naj bo $B: \RR^n \times \RR^n \to \RR$ \emph{bilinearen} funkcional, ki slika s predpisom
\begin{equation*}
(x, y) \mapsto B(x, y)
\end{equation*}
Za $x = \sum_{i=1}^n x_i e_i$ in $y = \sum_{j=1}^n y_j e_j$, kjer je $\{ e_1, \ldots, e_n \}$ standardna baza $\RR^n$ velja
\begin{multline*}
B(x, y) = B\left( \sum_{i=1}^n x_i e_i, \sum_{j=1}^n y_j e_j \right) = \sum_{i, j = 1}^n B(x_i e_i, y_j e_j) = \\
= \sum_{i,j=1}^n x_i y_i \underbrace{B(e_i, e_j)}_{a_{ij}} = \sum_{i, j = 1}^n a_{ij} x_i y_j
\end{multline*}
Za $A = [a_{ij}]_{i,j=1, \ldots, n} \in \RR^{n \times n}$ velja
\begin{multline*}
\langle x, A y \rangle = \left\langle \sum_i x_i e_i, A\left(\sum_j y_j e_j \right) \right\rangle = \left\langle \sum_i x_i e_i, \sum_j y_j A e_j \right\rangle = \\
= \sum_{i,j} x_i y_j \langle e_i, A e_j \rangle = \sum_{i, j} x_i y_j \underbrace{\left\langle e_i, A^{(j)} \right\rangle}_{a_{ij}} = \sum_{i, j} x_i y_j a_{ij}
\end{multline*}
Sklep:
\begin{equation*}
B(x, y) = \langle x, Ay \rangle = \langle A^T x, y \rangle
\end{equation*}

\textsc{Definicija:} Preslikavi $K: \RR^n \to \RR$ s predpisom $K(x) = B(x, x)$, kjer je $B$ bilinearen funkcional, pravimo \emph{kvadratni funkcional}.

$K$ lahko izrazimo z matriko
\begin{equation*}
K(x) = \langle A x, x \rangle = \sum_{i, j = 1}^n a_{ji} x_i x_j = \sum_{i = 1}^n a_{ii} x_i^2 + \sum_{i < j} (a_{ij} + a_{ji}) x_i x_j
\end{equation*}
V matriki $A$ lahko spreminjamo "clene $a_{ij}$ in $a_{ji}$, kjer $j \neq i$, "ce je vsota $a_{ij} + a_{ji}$ nespremenjena, ne da bi se $K(x)$ spremenil. Torej lahko brez "skode za splo"snost predpostavimo, da je $A$ simetri"cna in velja $A = A^T \Rightarrow a_{ij} = a_{ji}$. Tako lahko prej"snjo en"acbo nadaljujemo in dobimo
\begin{equation*}
K(x) = \sum_{i=1}^n a_{ii} x_i^2 + 2 \sum_{i < j} a_{ij} x_i x_j
\end{equation*}
\textbf{Opomba:} Ker je $A$ simetri"cna, je vseeno ali pi"semo $K(x) = \langle A x, x \rangle$ ali $K(x) = \langle x, A x \rangle$.

\subsubsection*{Diagonalizacija}
Naj bo $A = A^T \in \RR^{n \times n}$. Ker je $A$ sebi adjungirana, obstaja ortogonalna matrika $Q \in \RR^{n \times n}$, da velja
\begin{equation*}
Q^T A Q = \diag (\lambda_1, \ldots, \lambda_n)
\end{equation*}
Naj bo $x \in \RR^n$ in naredimo substitucijo
\begin{equation*}
x = Qy \Rightarrow y = Q^T x
\end{equation*}
Tedaj velja
\begin{equation*}
K_A(x) = \langle A x, x \rangle = \langle A Q y, Qy \rangle = \langle Q^T A T y, y \rangle = \langle D y, y \rangle = K_D(y) = \sum_{i=1}^n \lambda_i y_i^2
\end{equation*}

Recimo, da je $x = Py$ in $P$ obrnljiva, torej $y = P^{-1} x$. Po istem ra"cunu kot prej, dobimo
\begin{equation*}
K_A(x) = K_{P^T AP}(y)
\end{equation*}
Ker je $A$ sebi adjungirana, vemo da obstaja ortogonalna matrika $Q \in \RR^{n \times n}$, da velja
\begin{equation*}
D = Q^T A Q
\end{equation*}
kjer je $D$ diagonalna matrika. Naj bo $R$ simetri"cna metrika. Potem velja
\begin{equation*}
R^T D R = \underbrace{R^T Q^T}_{P^T} A \underbrace{QR}_P = P^T AP
\end{equation*}
Naj bo $R$ diagonalna. Potem sta $D$ in $R$ oblik
\begin{align*}
D = \begin{bmatrix}
\lambda_1 && \\
& \ddots & \\
&& \lambda_n
\end{bmatrix} &&
R = \begin{bmatrix}
r_1 && \\
& \ddots & \\
&& r_n
\end{bmatrix}
\end{align*}
in velja
\begin{equation*}
R^T DR = DR^2 = \diag \left( \lambda_1 r_1^2, \ldots, \lambda_n r_n^2 \right)
\end{equation*}
Brez "skode za splo"snost lahko predpostavimo slede"ce
\begin{align*}
\lambda_1, \ldots, \lambda_p &> 0 \\
\lambda_{p+1},  \ldots, \lambda_{p+q} &< 0 \\
\lambda_j &= 0 \qquad j > p + q
\end{align*}
Tedaj si lahko izberemo take $r_i$, da velja
\begin{gather*}
\lambda_i r_i^2 = 1 \qquad i = 1, \ldots, p \Rightarrow r_i = \dfrac{1}{\sqrt{\lambda_i}} \\
\lambda_i r_i^2 = -1 \qquad i = p+1, \ldots, p+1 \Rightarrow r_i = \dfrac{1}{\sqrt{-\lambda_i}} \\
i > p + q \qquad r_i = 1
\end{gather*}
Torej je
\begin{equation*}
R =\diag \left( \underbrace{\dfrac{1}{\sqrt{\lambda_1}}, \ldots, \dfrac{1}{\sqrt{\lambda_p}}}_p, \underbrace{\dfrac{1}{\sqrt{-\lambda_{p+1}}}, \ldots, \dfrac{1}{\sqrt{-\lambda_{p+q}}}}_q, 1, \ldots, 1 \right)
\end{equation*}
Ker je $R$ obrnljiva, je $P = QR$ obrnljiva. Torej velja
\begin{equation*}
P^T AP = R^T DR = \diag (\underbrace{1, \ldots, 1}_p, \underbrace{-1, \ldots, -1}_q, 0, \ldots, 0)
\end{equation*}
kjer je $P = QR$.

\textsc{Definicija:} $B \in \RR^{n \times n}$ je \emph{kongluentna} matriki $A \in \RR^{n \times n}$, kadar obstaja taka obrnljiva matrika $P \in \RR^{n \times n}$, da je 
\begin{equation*}
B = P^T AP
\end{equation*}

\textsc{Izrek} (Sylvester): Vsaka realan simetri"cna matrika je kongluentna matridki oblike
\begin{equation*}
\diag (\underbrace{1, \ldots, 1}_p, \underbrace{-1, \ldots, -1}_q, 0, \ldots, 0)
\end{equation*}
kjer je $p$ "stevilo pozitivnih lastnih vrednosti, $q$ pa "stevilo negativnih lastnih vrednosti.

\textsc{Posledica:}
\begin{equation*}
K(x_1, \ldots, x_n) = \sum_{i, j =1}^n a_{ij} x_i x_j = y_1^2 + \cdots + y_p^2 - y_{p+1}^2 - \cdots - y_{p+q}^2
\end{equation*}

Do enakega rezultata lahko pridemo na Lagrangeev na"cin:
\begin{equation*}
K(x_1, \ldots, x_n) = a_{11} x^2 + 2 a_{12} x_1 x_2 + \cdots + 2 a_{1n} x_1 x_n + K_1(x_2, \ldots, x_n)
\end{equation*}
\begin{enumerate}
    \item $a_{11} \neq 0$:
    \begin{equation*}
    = \dfrac{1}{a_{11}} (a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n)^2 + K_2(x_2, \ldots, x_n)
    \end{equation*}
    in ta postopek nadaljujemo.
    
    \item $a_{ii} = 0 \forall i$: npr. $n = 2$ in
    \begin{equation*}
    A = \begin{bmatrix}
    0 & \frac{1}{2} \\
    \frac{1}{2} & 0
    \end{bmatrix}
    \end{equation*}
    Potem dobimo
    \begin{equation*}
    K(x_1, x_2) = x_1 x_2 = \dfrac{1}{4} (x_1 + x_2)^2 - \dfrac{1}{4} (x_1 - x_2)^2 = y_1^2 - y_2^2
    \end{equation*}
    kjer je
    \begin{align*}
    y_1 = \dfrac{x_1 + x_2}{2} && y_2 = \dfrac{x_1 - x_2}{2}
    \end{align*}
    
    V splo"snem obstaja $a_{ij} \neq 0$ za $i \neq j$ in na podoben na"cin kot zgoraj preoblikujemo $a_{ij} (x_i x_j)$ v $a_{ij} (y_1^2 - y_2^2)$, nato lahko nadaljujemo z metodo (1).
\end{enumerate}


